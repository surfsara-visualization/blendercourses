{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/","text":"Advanced materials \u00b6 In this exercise you will use the Blender Shader Editor on the familiar iso-surface of a CT scan of a fish from the basic course and try to make a visualization by using an advanced node setup. After that you will make a render of the moon with the high resolution textures of NASA with adaptive subdivision. The fish (EXERCISE) \u00b6 When you opened the exercise blend file advanced_materials_assignment.blend you'll see the white fish iso-surface above a plane white plane. We are going to pimp this scene with advanced materials. Shader editor materials - Coloring the scene \u00b6 First we will add materials and give each object a different color. First activate the Rendered shading to see what kind of materials we are actually applying by pressing Z in the 3D Viewport panel and selecting Rendered from the radial pie-menu. Select the fishskin object and add a new material by clicking the New button in the middle of the top bar of the Shader Editor panel. Now we see a graph appearing with 2 nodes a Principled BSDF -node and a Material output -node also in the side panel you will see the familiar material settings. Change the Base Color to an appropriate color of a fish. Repeat step 2 and 3 for each 3D object in the scene (see Outliner ) and give them a color of your choice. Texture mapping - Placing the fish on a picknick table \u00b6 Now that the scene has some color we can start applying some realistic colors and texture to the ground plane or should we say table? We will do that by adding wood textures to the ground plane and connecting those textures to their appropriate parameters of the Principle BSDF. Select the groundplane 3D object. Add a Image texture -node to the Shader Editor graph of the groundplane with Shift-A > Texture > Image Texture . Connect the Color output of this node to the Base color input of the Principled BSDF -node. Now the groundplane doesn't look anything like a picknick table, its pink. This pink color comes from the fact that an image is missing from the Image Texture -node. Open an image by pressing the Open -button on the Image Texture -node, this will open a file browser window. Now select the blue_painted_planks_diff_4k.png image from the data/wood_textures/ directory and press Open Image . Now we have our first image mapped on an object! Although you might have noticed that the fish is really small or rather the planks are very big. We are gonna solve that by scaling the texture coordinates. Before we can do that we first need to add the texture coordinates to the graph with Shift-A > Input > Texture Coordinates and connect the UV output to the Vector input of the Image Texture -node. Nothing changed because we didn't apply the scaling yet. Now add a Mapping node with Shift-A > Vector > Mapping and drag it on top of the edge between the Texture Coordinate -node and the Image Texture -node and let it go. As you can see it is automatically connected in between the nodes. Now on the Mapping -node change the Scale parameter x , y and z to 2 . As you can see that reduced the planks to a smaller and better size. Tip! : With the Node Wrangler Blender add-on you can just select a texture node and press CTRL+T to automatically add the Texture Coordinate and Mapping node. Node Wrangler can be added with: Menu-bar Edit > Preferences > Add-ons tab > Type 'Node Wranger' in search > check Node Wrangler add-on to activate . Now we'll roughen the planks a bit with a Roughness map , a texture that will be use to change the Roughness parameter of the Principled BSDF. Select the previously added Image Texture -node and press SHIFT-D and place the new duplicated node underneath the other Image Texture -node. Connect its Vector input to the Vector output of the Mapping -node just like the other Image Texture -node and connect the Color output to the Roughness input of the Principled BSDF -node. As you can see became shiny, which wood is not (rotate the view around the object in the 3D Viewport to see the plane from different angles). This is because we haven't changed the texture yet. In this new Image Texture -node Open the blue_painted_planks_rough_4k.png from data/wood_textures . Now it is still a bit too shiny for wood. This is because the output is interpreted as an sRGB value. We need to change the Color Space parameter of this Image Texture -node to Non-color . Now the ground plane has the right rough look like wood. The look of the wood is still very \"flat\" (the light still bounces of it at a straight angle), this is because we didn't add a normal map to the material yet. This normal map will accentuate all the nooks and crannies naturally present in wood which normally catch light to. As the previous Image Texture -node we again need to make a new one by duplicating (see step 8 ). Again the Mapping -node Vector output needs to be connected to the new Image Texture -node Vector input. The Color output however needs to go to a Normal Map -node. Add a Normal Map -node with Shift-A > Vector > Normal Map and connect the Image Texture -node Color output to the Normal Map -node Color input and connect the Normal Map -node Normal output to the Principled BSDF -node Normal input. Again this is also not a color so the Color Space needs to be set to Non-color . Now you have a fully textured wooden ground plane! To see the full effect, rotate the view around it and see the light bounce off the surface based on the different texture types you just applied. Multiple materials one object - Window to the inside of the fish \u00b6 We only see the fish, not the fish bones. In the Blender Basics course we learned how to reveal the bones on the inside by using a Boolean modifier, but we can achieve the same with just materials! Select the fishskin 3D object. If everything in the first couple of assignments the fish should already have one material called Material . For administrative reasons lets rename the material by clicking its name Material in the middle of the top bar of the Shader Editor panel and typing the new name called fishskinmat . Now left next to the rename box you have drop-down menu called Slot 1 when you click this you will see the material slots menu. In our case its only one material called fishskinmat . Now add a new Material slot by clicking the plus icon in this menu. The added material slot is still empty and needs a second material. Add a new material by clicking the New button in the middle of the top bar of the Shader Editor panel. Rename this material to fishskintransparentmat . Now as you can see adjusting any value on the Principled BSDF -node doesn't seem to do anything. This is because there aren't any vertices assigned to this material slot yet (by default all vertices are assigned to the first material slot). To assign vertices we need to be able to select them and this can be done in the Edit Mode of the 3D Viewport -panel. With the fishskin 3D object selected and the focus on the 3D Viewport -panel (hovering over the 3D Viewport panel with your mouse) press TAB . First press 1 to see the vertices and then select a window of vertices on the side of the fish with the Border select tool by pressing B in the 3D Viewport -panel and dragging over the area you want to select. With these vertices selected press the Material slots button, select the fishskintransparentmat -material and press the Assign -button. Now you can see the selected faces in that selection look different! This is because they are assigned to the second material. Now we'll make the fishskintransparentmat actually transparent with a combination of the Transparent BSDF and Principled BSDF through a Mix Shader . That way we can control the amount of transparency! In the Shader editor add a Mix Shader -node with Shift-A > Shader > Mix Shader . Drag this Mix Shader -node over the edge connecting the Principled BSDF -node and the Material Output -node to place it connected in between. Now add a Transparent BSDF with Shift-A > Shader > Transparent BSDF . Connect the BSDF output to the Mix Shader -node Shader input. Now the material is half shaded by the Transparent BSDF -node and half by the Principled BSDF -node. Experiment with the Mix shader -node's fac parameter to see how it changes the transparency of the fishskintransparentmat . Now you have a window looking inside the fish! Now it's time to give the fish some actually fishy colors with the Project from view UV-mapping! Bonus (Only when you have time left): As you can see the bones also contain the swim bladder which looks the same as the bones because the same material is assigned to it. Try to select the swim bladders vertices and assign a different more fitting material to the swim bladder. Project from view UV-mapping - Add actual skin to the fish. \u00b6 To add a real fish texture, or actually a photo from a carp, to the fishskin 3D object you can use the technique called Project from view UV-mapping. For this we introduce a new panel called the UV Editor . Before we go to the UV Editor we need to add a Image Texture -node to the fishskinmat . In the Shader Editor select the fishskinmat (slot 1) from the Material slot menu in the middle left of the top bar of the Shader Editor . Add a Image Texture -node to the material with Shift-A > Texture > Image Texture and connect the Color output to the Principled BSDF -node Base Color input and open the carp.jpg texture from the data/ directory. Next add a Texture Coordinate node with Shift-A > Input > Texture Coordinates and connect the UV output to the Image texture -node Vector input. This fish is now black because the UV coordinates are not defined yet. That is what we will do in the UV Editor . Now that we do not need the Shader editor anymore we can replace it with the UV Editor . In the corner of the panel click the Editor Type-button and select the UV Editor from the list. Before we can start UV-mapping we need to be in Edit mode in the 3D viewport . In the 3D viewport panel press TAB to enter edit mode. Now select all geometry by pressing A . To properly project from view you have to choose the right view to project from. We are gonna map a photo of a carp which has been taken from the side. In order to properly map the photo on the 3D object we also need to look at it from the side. Press BACK-TICK to open the view radial pie-menu and select Right or through the 3D Viewport menu in the header ( View > Viewpoint > Camera ). Now press U to open the UV-mapping -menu and select Project from view . Now you can see the UV coordinates are mapped in the UV Editor but they are not properly scaled to fit the photo of the carp. Make sure that everything is still selected and then within the UV Editor press S and scale the UV-coordinates until they aligns with the photo of the carp. Scaling it alone is not enough. The UV-coordinates need to be moved a bit, use G to grab the UV-coordinates and translate them to better match the photo. As you might have noticed it is not possible to completely match the photo without deforming the UV-coordinates. Before we start deforming parts of the UV-coordinates you need to activate Proportional editing by pressing the Proportional editing button in the top bar of the UV Editor . This proportional editing moves all UV-coordinates in the adjacent defined radius along with the currently selected UV-coordinates. Now select a UV-coordinate in the UV Editor that needs to be moved and press G . While grabbing, scroll with you mouse wheel to decrease or increase the Proportional editing radius and move your mouse to see the effect. Now with this Proportional editing try to match the UV-coordinates to the photo of the carp as good as possible. Tip! : Whenever you are editing the UV-map in the UV editor it can be difficult to see how the texture is mapped on the 3D-object because of the visibility of all vertices, edges and faces because of the activated Edit mode . You can toggle between Edit mode and Object mode in the 3D Viewport panel to have a better look at the mapped texture. The moon (EXERCISE) \u00b6 The moon exercise doesn't have a prepared blend file because you are gonna make it all by yourself! So open a new blend file and start to make the moon. The basic scene - Sphere, sun and the darkness of space \u00b6 To create the moon we first need to prepare a very simple scene. First off we need to remove the Default cube (the cube that comes with a new blend file which only function is to be removed :'( ). Add a UV Sphere instead with Shift-A > Mesh > UV sphere . Set the UV Sphere 's shading to smooth through the 3D Viewport menu in at the top of the 3D Viewport ( Object > Shade Smooth ). Select the default Light object in the Outliner and change it to a Sun light in the Light -tab in the Properties -panel on the right. Now change the shading in the 3D viewport to Rendered by pressing Z and then select Rendered . This rendered view is by default set to Eevee , to change that to Cycles for more realistic lighting go to the Render Properties -tab in the Properties -panel and change the Render Engine to Cycles . As you can see the sun is now way too bright. Lower the Strength of the sun from 1000 to 10 in the Light -tab in the Properties -panel. No need to have the power of a 1000 suns. Now that we have the sun we need to disable the World -lighting (the grey ambient light) since we only need the sun as a direct light source like it is in space. Go to the World properties -tab in the Properties -panel and set the Color in the Surface -section all the way to black. Now we have the basic scene of a sphere in space, now we are gonna make it look like the moon by adding textures. Applying a material and texturing the moon - That's one small step... \u00b6 Before we can edit the material we need to open the Shader Editor . For this we need to slightly modify the interface. Grab the edge between the 3D viewport -panel and the Timeline -panel by hovering above the edge until you see resize cursor then click and drag the edge until half of the Blender window. Now click the upper left Editor type dropdown menu (now the Timeline -icon ) and select the Shader Editor . In the Shader Editor add a new material. In this material add 2 Image Texture -nodes, 1 Texture Coordinate -node and 1 Displacement -node ( Shift-A > Vector > Displacement ). Connect the Texture Coordinate -node UV output to both Image Texture -nodes Vector inputs. Connect one of the Image Texture -nodes Color output to the Principled BSDF -node Base Color input and the others Color output to the Displacement -node Height input. Finally connect the Displacement -node Displacement output to the Material output -node Displacement input. Open the data/moon_textures/lroc_color_poles_8k.tif in the Image Texture -node that is connected to the Principled BSDF -node Base Color . Open the data/moon_textures/ldem_16.tif in the Image Texture -node that is connected to the Displacement -node Height input. Then finaly set the Image Texture -node Color Space -parameter of the node with the displacement texture to ** Non-Color . Initially the Displacement -node Scale parameter is set way too high making the moon look horrible. Set this parameter to 0.001 . As you can see it already looks quite like the moon but with some final tweaking you will get even more realism. Adaptive displacement - Revealing the craters! Mooore details! \u00b6 Everything we have seen until now has been rendered in the default EEVEE rendering engine, which is for visualization purposes very powerful, but if you want to add that extra little realism with adaptive displacement you have to use the Cycles rendering engine. Active the Cycles rendering engine with the Render Engine setting in the Rendering properties -tab of the Properties -panel. While we are there, to be able to use adaptive displacement, we need to activate the Cycles experimental feature set. Set the Feature Set to Experimental . This Experimental feature set added an extra section in the current properties panel tab called Subdivision . In this section set Viewport to 2 . Now we need to add a Subdivision modifier that also got a new setting from the Experimental feature set that enables the adaptive displacement . Add a Subdivision modfier in the Modifier properties -tab of the Properties -panel. Enable the Adaptive Subdivision setting in this modifier. Until now you only saw some slight differences because there is only one setting that has to be changed to make all of this worth it. Change the Displacement setting to Displacement Only in the Properties -panel > Material properties -tab > Settings -section > Surface -subsection. Now zoom in and toggle to the Edit mode and back, which re-triggers the adaptive subdivision computations, and see the craters in their full glory. Bonus : For an artists rendition of the moon change the Displacement -node Scale parameter to a higher value and see how the craters get more noticeable (although less realistic).","title":"Advanced materials"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#advanced-materials","text":"In this exercise you will use the Blender Shader Editor on the familiar iso-surface of a CT scan of a fish from the basic course and try to make a visualization by using an advanced node setup. After that you will make a render of the moon with the high resolution textures of NASA with adaptive subdivision.","title":"Advanced materials"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#the-fish-exercise","text":"When you opened the exercise blend file advanced_materials_assignment.blend you'll see the white fish iso-surface above a plane white plane. We are going to pimp this scene with advanced materials.","title":"The fish (EXERCISE)"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#shader-editor-materials-coloring-the-scene","text":"First we will add materials and give each object a different color. First activate the Rendered shading to see what kind of materials we are actually applying by pressing Z in the 3D Viewport panel and selecting Rendered from the radial pie-menu. Select the fishskin object and add a new material by clicking the New button in the middle of the top bar of the Shader Editor panel. Now we see a graph appearing with 2 nodes a Principled BSDF -node and a Material output -node also in the side panel you will see the familiar material settings. Change the Base Color to an appropriate color of a fish. Repeat step 2 and 3 for each 3D object in the scene (see Outliner ) and give them a color of your choice.","title":"Shader editor materials - Coloring the scene"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#texture-mapping-placing-the-fish-on-a-picknick-table","text":"Now that the scene has some color we can start applying some realistic colors and texture to the ground plane or should we say table? We will do that by adding wood textures to the ground plane and connecting those textures to their appropriate parameters of the Principle BSDF. Select the groundplane 3D object. Add a Image texture -node to the Shader Editor graph of the groundplane with Shift-A > Texture > Image Texture . Connect the Color output of this node to the Base color input of the Principled BSDF -node. Now the groundplane doesn't look anything like a picknick table, its pink. This pink color comes from the fact that an image is missing from the Image Texture -node. Open an image by pressing the Open -button on the Image Texture -node, this will open a file browser window. Now select the blue_painted_planks_diff_4k.png image from the data/wood_textures/ directory and press Open Image . Now we have our first image mapped on an object! Although you might have noticed that the fish is really small or rather the planks are very big. We are gonna solve that by scaling the texture coordinates. Before we can do that we first need to add the texture coordinates to the graph with Shift-A > Input > Texture Coordinates and connect the UV output to the Vector input of the Image Texture -node. Nothing changed because we didn't apply the scaling yet. Now add a Mapping node with Shift-A > Vector > Mapping and drag it on top of the edge between the Texture Coordinate -node and the Image Texture -node and let it go. As you can see it is automatically connected in between the nodes. Now on the Mapping -node change the Scale parameter x , y and z to 2 . As you can see that reduced the planks to a smaller and better size. Tip! : With the Node Wrangler Blender add-on you can just select a texture node and press CTRL+T to automatically add the Texture Coordinate and Mapping node. Node Wrangler can be added with: Menu-bar Edit > Preferences > Add-ons tab > Type 'Node Wranger' in search > check Node Wrangler add-on to activate . Now we'll roughen the planks a bit with a Roughness map , a texture that will be use to change the Roughness parameter of the Principled BSDF. Select the previously added Image Texture -node and press SHIFT-D and place the new duplicated node underneath the other Image Texture -node. Connect its Vector input to the Vector output of the Mapping -node just like the other Image Texture -node and connect the Color output to the Roughness input of the Principled BSDF -node. As you can see became shiny, which wood is not (rotate the view around the object in the 3D Viewport to see the plane from different angles). This is because we haven't changed the texture yet. In this new Image Texture -node Open the blue_painted_planks_rough_4k.png from data/wood_textures . Now it is still a bit too shiny for wood. This is because the output is interpreted as an sRGB value. We need to change the Color Space parameter of this Image Texture -node to Non-color . Now the ground plane has the right rough look like wood. The look of the wood is still very \"flat\" (the light still bounces of it at a straight angle), this is because we didn't add a normal map to the material yet. This normal map will accentuate all the nooks and crannies naturally present in wood which normally catch light to. As the previous Image Texture -node we again need to make a new one by duplicating (see step 8 ). Again the Mapping -node Vector output needs to be connected to the new Image Texture -node Vector input. The Color output however needs to go to a Normal Map -node. Add a Normal Map -node with Shift-A > Vector > Normal Map and connect the Image Texture -node Color output to the Normal Map -node Color input and connect the Normal Map -node Normal output to the Principled BSDF -node Normal input. Again this is also not a color so the Color Space needs to be set to Non-color . Now you have a fully textured wooden ground plane! To see the full effect, rotate the view around it and see the light bounce off the surface based on the different texture types you just applied.","title":"Texture mapping - Placing the fish on a picknick table"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#multiple-materials-one-object-window-to-the-inside-of-the-fish","text":"We only see the fish, not the fish bones. In the Blender Basics course we learned how to reveal the bones on the inside by using a Boolean modifier, but we can achieve the same with just materials! Select the fishskin 3D object. If everything in the first couple of assignments the fish should already have one material called Material . For administrative reasons lets rename the material by clicking its name Material in the middle of the top bar of the Shader Editor panel and typing the new name called fishskinmat . Now left next to the rename box you have drop-down menu called Slot 1 when you click this you will see the material slots menu. In our case its only one material called fishskinmat . Now add a new Material slot by clicking the plus icon in this menu. The added material slot is still empty and needs a second material. Add a new material by clicking the New button in the middle of the top bar of the Shader Editor panel. Rename this material to fishskintransparentmat . Now as you can see adjusting any value on the Principled BSDF -node doesn't seem to do anything. This is because there aren't any vertices assigned to this material slot yet (by default all vertices are assigned to the first material slot). To assign vertices we need to be able to select them and this can be done in the Edit Mode of the 3D Viewport -panel. With the fishskin 3D object selected and the focus on the 3D Viewport -panel (hovering over the 3D Viewport panel with your mouse) press TAB . First press 1 to see the vertices and then select a window of vertices on the side of the fish with the Border select tool by pressing B in the 3D Viewport -panel and dragging over the area you want to select. With these vertices selected press the Material slots button, select the fishskintransparentmat -material and press the Assign -button. Now you can see the selected faces in that selection look different! This is because they are assigned to the second material. Now we'll make the fishskintransparentmat actually transparent with a combination of the Transparent BSDF and Principled BSDF through a Mix Shader . That way we can control the amount of transparency! In the Shader editor add a Mix Shader -node with Shift-A > Shader > Mix Shader . Drag this Mix Shader -node over the edge connecting the Principled BSDF -node and the Material Output -node to place it connected in between. Now add a Transparent BSDF with Shift-A > Shader > Transparent BSDF . Connect the BSDF output to the Mix Shader -node Shader input. Now the material is half shaded by the Transparent BSDF -node and half by the Principled BSDF -node. Experiment with the Mix shader -node's fac parameter to see how it changes the transparency of the fishskintransparentmat . Now you have a window looking inside the fish! Now it's time to give the fish some actually fishy colors with the Project from view UV-mapping! Bonus (Only when you have time left): As you can see the bones also contain the swim bladder which looks the same as the bones because the same material is assigned to it. Try to select the swim bladders vertices and assign a different more fitting material to the swim bladder.","title":"Multiple materials one object - Window to the inside of the fish"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#project-from-view-uv-mapping-add-actual-skin-to-the-fish","text":"To add a real fish texture, or actually a photo from a carp, to the fishskin 3D object you can use the technique called Project from view UV-mapping. For this we introduce a new panel called the UV Editor . Before we go to the UV Editor we need to add a Image Texture -node to the fishskinmat . In the Shader Editor select the fishskinmat (slot 1) from the Material slot menu in the middle left of the top bar of the Shader Editor . Add a Image Texture -node to the material with Shift-A > Texture > Image Texture and connect the Color output to the Principled BSDF -node Base Color input and open the carp.jpg texture from the data/ directory. Next add a Texture Coordinate node with Shift-A > Input > Texture Coordinates and connect the UV output to the Image texture -node Vector input. This fish is now black because the UV coordinates are not defined yet. That is what we will do in the UV Editor . Now that we do not need the Shader editor anymore we can replace it with the UV Editor . In the corner of the panel click the Editor Type-button and select the UV Editor from the list. Before we can start UV-mapping we need to be in Edit mode in the 3D viewport . In the 3D viewport panel press TAB to enter edit mode. Now select all geometry by pressing A . To properly project from view you have to choose the right view to project from. We are gonna map a photo of a carp which has been taken from the side. In order to properly map the photo on the 3D object we also need to look at it from the side. Press BACK-TICK to open the view radial pie-menu and select Right or through the 3D Viewport menu in the header ( View > Viewpoint > Camera ). Now press U to open the UV-mapping -menu and select Project from view . Now you can see the UV coordinates are mapped in the UV Editor but they are not properly scaled to fit the photo of the carp. Make sure that everything is still selected and then within the UV Editor press S and scale the UV-coordinates until they aligns with the photo of the carp. Scaling it alone is not enough. The UV-coordinates need to be moved a bit, use G to grab the UV-coordinates and translate them to better match the photo. As you might have noticed it is not possible to completely match the photo without deforming the UV-coordinates. Before we start deforming parts of the UV-coordinates you need to activate Proportional editing by pressing the Proportional editing button in the top bar of the UV Editor . This proportional editing moves all UV-coordinates in the adjacent defined radius along with the currently selected UV-coordinates. Now select a UV-coordinate in the UV Editor that needs to be moved and press G . While grabbing, scroll with you mouse wheel to decrease or increase the Proportional editing radius and move your mouse to see the effect. Now with this Proportional editing try to match the UV-coordinates to the photo of the carp as good as possible. Tip! : Whenever you are editing the UV-map in the UV editor it can be difficult to see how the texture is mapped on the 3D-object because of the visibility of all vertices, edges and faces because of the activated Edit mode . You can toggle between Edit mode and Object mode in the 3D Viewport panel to have a better look at the mapped texture.","title":"Project from view UV-mapping - Add actual skin to the fish."},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#the-moon-exercise","text":"The moon exercise doesn't have a prepared blend file because you are gonna make it all by yourself! So open a new blend file and start to make the moon.","title":"The moon (EXERCISE)"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#the-basic-scene-sphere-sun-and-the-darkness-of-space","text":"To create the moon we first need to prepare a very simple scene. First off we need to remove the Default cube (the cube that comes with a new blend file which only function is to be removed :'( ). Add a UV Sphere instead with Shift-A > Mesh > UV sphere . Set the UV Sphere 's shading to smooth through the 3D Viewport menu in at the top of the 3D Viewport ( Object > Shade Smooth ). Select the default Light object in the Outliner and change it to a Sun light in the Light -tab in the Properties -panel on the right. Now change the shading in the 3D viewport to Rendered by pressing Z and then select Rendered . This rendered view is by default set to Eevee , to change that to Cycles for more realistic lighting go to the Render Properties -tab in the Properties -panel and change the Render Engine to Cycles . As you can see the sun is now way too bright. Lower the Strength of the sun from 1000 to 10 in the Light -tab in the Properties -panel. No need to have the power of a 1000 suns. Now that we have the sun we need to disable the World -lighting (the grey ambient light) since we only need the sun as a direct light source like it is in space. Go to the World properties -tab in the Properties -panel and set the Color in the Surface -section all the way to black. Now we have the basic scene of a sphere in space, now we are gonna make it look like the moon by adding textures.","title":"The basic scene - Sphere, sun and the darkness of space"},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#applying-a-material-and-texturing-the-moon-thats-one-small-step","text":"Before we can edit the material we need to open the Shader Editor . For this we need to slightly modify the interface. Grab the edge between the 3D viewport -panel and the Timeline -panel by hovering above the edge until you see resize cursor then click and drag the edge until half of the Blender window. Now click the upper left Editor type dropdown menu (now the Timeline -icon ) and select the Shader Editor . In the Shader Editor add a new material. In this material add 2 Image Texture -nodes, 1 Texture Coordinate -node and 1 Displacement -node ( Shift-A > Vector > Displacement ). Connect the Texture Coordinate -node UV output to both Image Texture -nodes Vector inputs. Connect one of the Image Texture -nodes Color output to the Principled BSDF -node Base Color input and the others Color output to the Displacement -node Height input. Finally connect the Displacement -node Displacement output to the Material output -node Displacement input. Open the data/moon_textures/lroc_color_poles_8k.tif in the Image Texture -node that is connected to the Principled BSDF -node Base Color . Open the data/moon_textures/ldem_16.tif in the Image Texture -node that is connected to the Displacement -node Height input. Then finaly set the Image Texture -node Color Space -parameter of the node with the displacement texture to ** Non-Color . Initially the Displacement -node Scale parameter is set way too high making the moon look horrible. Set this parameter to 0.001 . As you can see it already looks quite like the moon but with some final tweaking you will get even more realism.","title":"Applying a material and texturing the moon - That's one small step..."},{"location":"modules/advanced/advanced_materials/advanced_materials_assignment/#adaptive-displacement-revealing-the-craters-mooore-details","text":"Everything we have seen until now has been rendered in the default EEVEE rendering engine, which is for visualization purposes very powerful, but if you want to add that extra little realism with adaptive displacement you have to use the Cycles rendering engine. Active the Cycles rendering engine with the Render Engine setting in the Rendering properties -tab of the Properties -panel. While we are there, to be able to use adaptive displacement, we need to activate the Cycles experimental feature set. Set the Feature Set to Experimental . This Experimental feature set added an extra section in the current properties panel tab called Subdivision . In this section set Viewport to 2 . Now we need to add a Subdivision modifier that also got a new setting from the Experimental feature set that enables the adaptive displacement . Add a Subdivision modfier in the Modifier properties -tab of the Properties -panel. Enable the Adaptive Subdivision setting in this modifier. Until now you only saw some slight differences because there is only one setting that has to be changed to make all of this worth it. Change the Displacement setting to Displacement Only in the Properties -panel > Material properties -tab > Settings -section > Surface -subsection. Now zoom in and toggle to the Edit mode and back, which re-triggers the adaptive subdivision computations, and see the craters in their full glory. Bonus : For an artists rendition of the moon change the Displacement -node Scale parameter to a higher value and see how the craters get more noticeable (although less realistic).","title":"Adaptive displacement - Revealing the craters! Mooore details!"},{"location":"modules/advanced/advanced_materials/introduction/","text":"Introduction \u00b6 This chapter will introduce the Shader Editor and UV Editor of Blender which lets you create advanced materials to improve the look of your visualizations. The Shader editor and UV editor go hand in hand, with the UV-editor (and 3D viewport) you'll learn how to UV-unwrap your meshes and manipulate the UV-coordinates and with the Shader editor you'll project procedural or image textures based on the created UV-coordinates. You'll learn how to apply PBR (Physically based rendering) style textures and where to find them, to make your objects look photo real. And lastly a commonly used experimental feature called Adaptive Subdivision will be combined with vertex displacement to create some great looking micro-displacement details on the surfaces of your objects. Before you start with the exercises the following video will give you the theoretical and practical background to make these exercises. In this video there are some Blender walk-throughs, if you want to follow along you can use the walk-through files in the ./walkthroughs/advanced_materials directory. After you watched the video about simple mesh-editing you are ready for the exercises!","title":"Introduction"},{"location":"modules/advanced/advanced_materials/introduction/#introduction","text":"This chapter will introduce the Shader Editor and UV Editor of Blender which lets you create advanced materials to improve the look of your visualizations. The Shader editor and UV editor go hand in hand, with the UV-editor (and 3D viewport) you'll learn how to UV-unwrap your meshes and manipulate the UV-coordinates and with the Shader editor you'll project procedural or image textures based on the created UV-coordinates. You'll learn how to apply PBR (Physically based rendering) style textures and where to find them, to make your objects look photo real. And lastly a commonly used experimental feature called Adaptive Subdivision will be combined with vertex displacement to create some great looking micro-displacement details on the surfaces of your objects. Before you start with the exercises the following video will give you the theoretical and practical background to make these exercises. In this video there are some Blender walk-throughs, if you want to follow along you can use the walk-through files in the ./walkthroughs/advanced_materials directory. After you watched the video about simple mesh-editing you are ready for the exercises!","title":"Introduction"},{"location":"modules/advanced/advanced_materials/node-wrangler/","text":"Node-wrangler reference \u00b6 The node-wrangler brings a wide variety of new features and hot-keys to automate steps within the Shader Editor to make life easier. In the walk-through only 2 features where shown, the 'Shader viewer' ( Ctrl+Shift+LMB ) and 'Add Texture Setup' ( Ctrl+T ), 2 very useful hot-keys but this is only the tip of the iceberg. To see the full set of features/hotkeys that node-wrangler provides you need to go to Menu bar 'Edit' > Preferences... > Tab 'Add-ons' > Search for 'Node wrangler' > Show Hotkey List (see image below). For additional information on what each individual feature does please refer to the official documentation . Warning The hotkeys in the official documentation are not updated yet to 2.8+ therefor please refer only for the information of each feature and use the \"Show Hotkey List\" for the current hotkeys.","title":"Node-wrangler reference"},{"location":"modules/advanced/advanced_materials/node-wrangler/#node-wrangler-reference","text":"The node-wrangler brings a wide variety of new features and hot-keys to automate steps within the Shader Editor to make life easier. In the walk-through only 2 features where shown, the 'Shader viewer' ( Ctrl+Shift+LMB ) and 'Add Texture Setup' ( Ctrl+T ), 2 very useful hot-keys but this is only the tip of the iceberg. To see the full set of features/hotkeys that node-wrangler provides you need to go to Menu bar 'Edit' > Preferences... > Tab 'Add-ons' > Search for 'Node wrangler' > Show Hotkey List (see image below). For additional information on what each individual feature does please refer to the official documentation . Warning The hotkeys in the official documentation are not updated yet to 2.8+ therefor please refer only for the information of each feature and use the \"Show Hotkey List\" for the current hotkeys.","title":"Node-wrangler reference"},{"location":"modules/advanced/advanced_materials/vertex_colors/","text":"Visualizing vertex colors with the Attribute node \u00b6 In the basics course we already introduced the use of vertex colors with the Material -tab in the Properties -panel. What happens under the hood is that you basically add an Attribute -node to the node-network and attached its Color -output to the Base Color -input of the Principled BSDF shader -node (see image below). The blend file for the image above, vertex-color.blend , can be found among the walk-through files in the ./walkthroughs/advanced_materials directory.","title":"Visualizing vertex colors with the Attribute node"},{"location":"modules/advanced/advanced_materials/vertex_colors/#visualizing-vertex-colors-with-the-attribute-node","text":"In the basics course we already introduced the use of vertex colors with the Material -tab in the Properties -panel. What happens under the hood is that you basically add an Attribute -node to the node-network and attached its Color -output to the Base Color -input of the Principled BSDF shader -node (see image below). The blend file for the image above, vertex-color.blend , can be found among the walk-through files in the ./walkthroughs/advanced_materials directory.","title":"Visualizing vertex colors with the Attribute node"},{"location":"modules/advanced/animation/2_assignment_cars/","text":"(EXERCISE) \"Cars\": the movie \u00b6 In this exercise you can do some more complex keyframe animation by having multiple objects move to create a city full of driving cars. You will need basic keyframing skills and use of the Graph Editor. Load cars.blend This scene has a very simple city with some building and some cars. An animation of 250 frames has been set up in the file, starting at frame 1, ending at frame 250. Tip All the geometry of the buildings is in the so-called collection \"Collection 2\". You can hide all these objects by clicking the eye icon right of \"Collection 2\" in the outliner. Change to the first frame in the animation with Shift-Left . Note that you can see the current frame you're working in by the blue vertical line in the Timeline at the bottom. Also, in the 3D view there's a piece of text in the upper-left that reads (1) Scene Collection | Plane : the current frame is listed between the parentheses. In the scene there's two cars behind each other. Select the front car of the two. Enter a keyframe for the car's location and rotation: press I followed by picking LocRot Change to the last frame in the animation with Shift-Right Move the car to the end of the road it's on, along the Y axis Enter another LocRot keyframe with I Check the car movement by playing back the animation with Space , or by changing the time in the Timeline editor with Shift-RMB The car's speed currently is not constant: it speeds up near the beginning of the animation and slows down starting somewhere halfway. We can edit the curve for the Y location channel in the Graph Editor to influence this behaviour. In the Graph Editor on the left of the screen show all the location and rotation values being animated for the selected car by using the little triangle left of the name Object Transforms . Below the Object Transforms you should now see the 6 channels for which you created keyframes in steps 4 and 7: X, Y and Z Location, and X, Y and Z Euler Rotation. Click the eye icon next to Object Transforms to hide all the channels. Then click the eye next to Y Location to only show the graph for the Y location. Note that you can use the Home key to zoom to the full extent of the graph. You should now see a curved line in green with two orange filled circles at the times of the beginning and end of the animation, i.e. frames 1 and 250. Attached to the squares are \"handles\" (the lines that end in open circles) that influence the shape of the curve. Select the open circular endpoints of the handles and move them around. See what this does for the shape of the curve and the subsequent behaviour of the car in the animation. The two curve points are selectable with Shift-LMB , but also, for example, border select ( B key). This works just like you normally select objects. Deleting keyframes can then be done with X . Select both curve points with A , Press V to bring up the Keyframe Handle type. This menu allows you to change how the curve is shaped based on the position of the handles. Select Vector . Notice how the curve's shape changes. See what happens when you move the handle endpoints. Press V again and choose Free . Again change the handle endpoints. Try out how the different curve shapes you can produce influence the car behaviour. Now let's animate another car: the one at the start of the road with the bend in it. Animate the second to move over the bended road all the way to the end. Bonus \u00b6 Make the cars drive over the road, choosing yourself which cars goes in what direction, how fast, which turns are made, etc. But don't make cars go through each other and have them wait if needed. Add a camera that shows the busy streets in action :)","title":"(EXERCISE) \"Cars\": the movie"},{"location":"modules/advanced/animation/2_assignment_cars/#exercise-cars-the-movie","text":"In this exercise you can do some more complex keyframe animation by having multiple objects move to create a city full of driving cars. You will need basic keyframing skills and use of the Graph Editor. Load cars.blend This scene has a very simple city with some building and some cars. An animation of 250 frames has been set up in the file, starting at frame 1, ending at frame 250. Tip All the geometry of the buildings is in the so-called collection \"Collection 2\". You can hide all these objects by clicking the eye icon right of \"Collection 2\" in the outliner. Change to the first frame in the animation with Shift-Left . Note that you can see the current frame you're working in by the blue vertical line in the Timeline at the bottom. Also, in the 3D view there's a piece of text in the upper-left that reads (1) Scene Collection | Plane : the current frame is listed between the parentheses. In the scene there's two cars behind each other. Select the front car of the two. Enter a keyframe for the car's location and rotation: press I followed by picking LocRot Change to the last frame in the animation with Shift-Right Move the car to the end of the road it's on, along the Y axis Enter another LocRot keyframe with I Check the car movement by playing back the animation with Space , or by changing the time in the Timeline editor with Shift-RMB The car's speed currently is not constant: it speeds up near the beginning of the animation and slows down starting somewhere halfway. We can edit the curve for the Y location channel in the Graph Editor to influence this behaviour. In the Graph Editor on the left of the screen show all the location and rotation values being animated for the selected car by using the little triangle left of the name Object Transforms . Below the Object Transforms you should now see the 6 channels for which you created keyframes in steps 4 and 7: X, Y and Z Location, and X, Y and Z Euler Rotation. Click the eye icon next to Object Transforms to hide all the channels. Then click the eye next to Y Location to only show the graph for the Y location. Note that you can use the Home key to zoom to the full extent of the graph. You should now see a curved line in green with two orange filled circles at the times of the beginning and end of the animation, i.e. frames 1 and 250. Attached to the squares are \"handles\" (the lines that end in open circles) that influence the shape of the curve. Select the open circular endpoints of the handles and move them around. See what this does for the shape of the curve and the subsequent behaviour of the car in the animation. The two curve points are selectable with Shift-LMB , but also, for example, border select ( B key). This works just like you normally select objects. Deleting keyframes can then be done with X . Select both curve points with A , Press V to bring up the Keyframe Handle type. This menu allows you to change how the curve is shaped based on the position of the handles. Select Vector . Notice how the curve's shape changes. See what happens when you move the handle endpoints. Press V again and choose Free . Again change the handle endpoints. Try out how the different curve shapes you can produce influence the car behaviour. Now let's animate another car: the one at the start of the road with the bend in it. Animate the second to move over the bended road all the way to the end.","title":"(EXERCISE) \"Cars\": the movie"},{"location":"modules/advanced/animation/2_assignment_cars/#bonus","text":"Make the cars drive over the road, choosing yourself which cars goes in what direction, how fast, which turns are made, etc. But don't make cars go through each other and have them wait if needed. Add a camera that shows the busy streets in action :)","title":"Bonus"},{"location":"modules/advanced/animation/3_assignment_flipbook/","text":"(EXERCISE) Flipbook animation \u00b6 Get more familiar with the flipbook approach, in which a meshes is animated over time by switching a single object's mesh data each frame. Extract dambreak.tar.gz in the same directory as animated_ply_imports.blend Load animated_ply_imports.blend This blend file contains not only a 3D scene, but also some Python scripts we use to set up the flipbook animation. The first step is to load all the timesteps in the dataset using one of the scripts. This might take a bit of time, depending on the speed of your system. Tip By default, only the first 100 steps are loaded. You can increase the number of files to the full 300 if you like by updating the variable N in both the import script and the animation handler script. Execute the script that imports the PLY files for the time steps. To do this step make sure the script called \"1. import ply files\" is shown in the text editor panel. Then press the button in the top bar to run the script. The cursor changes to a numbered black square indicating the percentage of loading that has been completed. In case you get the idea something is wrong check the console output in the terminal where you started Blender. After all PLY files are loaded execute the script that installs the frame change handler. This script is called \"2. register anim handler\". Make sure the text editor is switched to this script and press the play button. Verify that the flipbook animation works with Space and/or moving the time slider in the Timeline with Shift-RMB . The playback speed will depend on your system's performance, but also on the framerate setting. Change the Frame Rate value (in the Output properties tab at the right side of the screen, icon ) to different values to see how your system handles it. Is 60 fps feasible? Use your skills with keyframe animation to do one of the following things (or both if you feel like it ;-)): 8a. Have a camera follow the moving water in some cool way 8b. Place a surfer on the moving wave of water. You can import the PLY model silver_surfer_by_melic.ply to use as 3D model. You can load it in Blender with File > Import > Stanford (.ply) .","title":"(EXERCISE) Flipbook animation"},{"location":"modules/advanced/animation/3_assignment_flipbook/#exercise-flipbook-animation","text":"Get more familiar with the flipbook approach, in which a meshes is animated over time by switching a single object's mesh data each frame. Extract dambreak.tar.gz in the same directory as animated_ply_imports.blend Load animated_ply_imports.blend This blend file contains not only a 3D scene, but also some Python scripts we use to set up the flipbook animation. The first step is to load all the timesteps in the dataset using one of the scripts. This might take a bit of time, depending on the speed of your system. Tip By default, only the first 100 steps are loaded. You can increase the number of files to the full 300 if you like by updating the variable N in both the import script and the animation handler script. Execute the script that imports the PLY files for the time steps. To do this step make sure the script called \"1. import ply files\" is shown in the text editor panel. Then press the button in the top bar to run the script. The cursor changes to a numbered black square indicating the percentage of loading that has been completed. In case you get the idea something is wrong check the console output in the terminal where you started Blender. After all PLY files are loaded execute the script that installs the frame change handler. This script is called \"2. register anim handler\". Make sure the text editor is switched to this script and press the play button. Verify that the flipbook animation works with Space and/or moving the time slider in the Timeline with Shift-RMB . The playback speed will depend on your system's performance, but also on the framerate setting. Change the Frame Rate value (in the Output properties tab at the right side of the screen, icon ) to different values to see how your system handles it. Is 60 fps feasible? Use your skills with keyframe animation to do one of the following things (or both if you feel like it ;-)): 8a. Have a camera follow the moving water in some cool way 8b. Place a surfer on the moving wave of water. You can import the PLY model silver_surfer_by_melic.ply to use as 3D model. You can load it in Blender with File > Import > Stanford (.ply) .","title":"(EXERCISE) Flipbook animation"},{"location":"modules/advanced/animation/introduction/","text":"Introduction \u00b6 The basic of (keyframe) animation in Blender were ready discussed in the Basics course, but if you need to refresh your memory then you can use this video:","title":"Introduction"},{"location":"modules/advanced/animation/introduction/#introduction","text":"The basic of (keyframe) animation in Blender were ready discussed in the Basics course, but if you need to refresh your memory then you can use this video:","title":"Introduction"},{"location":"modules/advanced/animation/shape_keys/","text":"Shape keys \u00b6 Overview \u00b6 Shape keys can be used for a very specific type of animation: to morph one mesh into another over time, or to blend multiple meshes together into one result. This can be used, for example, to show the time-evolution of some object or the highlight differences between two meshes. Although this is a fairly specific use case shape keys aren't too difficult too understand and use, hence we include this section. There are some limitations to using shape keys: The two meshes must have the same number of vertices Preferably the two meshes should have the same topology (i.e. the way in which the vertices are connected to form polygons). If the topology doesn't match then strange results during morphing can occur. The above is a fairly annoying limitation, but there is no easy way around it in Blender, unfortunately. XXX movie (EXERCISE) Poor Bunny \u00b6 Load bunny_shape_keys.blend This scene contains the Stanford Bunny and a completely flattened version of the Bunny Verify that these meshes have the same number of vertices. Do a visual comparison in wireframe mode ( Z > Wireframe ) We'll now add some shape keys: Select the regular Bunny Add a shape key under Shape Keys in the Mesh properties using the + button. The new shape keys will be called Basis Add a second shape key, it will be called Key 1 and have a default influence of 0 Select the Key 1 shape key and enter mesh edit mode in the 3D view with TAB and make sure you're in vertex mode by pressing 1 Select parts of the Bunny mesh and transform them as you like. The changes should be clearly visible. Exit mesh edit mode with TAB . You should notice that the mesh returns to its normal shape. Change the influence value of Key 1 to see what happens to the resulting mesh. You can either click on it and enter a number, of click and drag the value. Let's add another shape key: Add a third shape key, it will be called Key 2 . Select Key 2 and apply a second set of mesh changes in edit mode Once again exit edit mode Play around with the influence values of both shape keys, as well as the checkboxes next to the influence values. Checking the difference between relative and absolute shape keys: Uncheck the Relative checkbox to switch to absolute shape keys. Notice that the influence values have now disappeared. Change the Evolution Time value to understand how the morphing of the meshes is done now Using another mesh to define a shape key: Delete shape keys Key 1 and Key 2 using the - button and change back to relative shape keys by checking the Relative checkbox. Select the flattened mesh and the Shift-click the Bunny mesh. Open the shape key menu using the downwards arrow below the + and - buttons. Select Join as Shapes There should now be a new shape key called flattened mesh . Vary the influence of the flattened mesh shape key to see the Bunny melt. Delete the flattened mesh object in the Outliner. Does the shape key morphing to melt the Bunny still work? Looking closer at the behaviour of the mesh morphing: Try to reason why the head of the Bunny is the last part to melt. Zoom in a bit to see if you can spot the twisting motion that mesh makes as it melts. Try to transform the mesh in the melted shape key in such as way as to minimize the twist. Or toy around with other mesh transforms to see what morphs come out","title":"Shape keys"},{"location":"modules/advanced/animation/shape_keys/#shape-keys","text":"","title":"Shape keys"},{"location":"modules/advanced/animation/shape_keys/#overview","text":"Shape keys can be used for a very specific type of animation: to morph one mesh into another over time, or to blend multiple meshes together into one result. This can be used, for example, to show the time-evolution of some object or the highlight differences between two meshes. Although this is a fairly specific use case shape keys aren't too difficult too understand and use, hence we include this section. There are some limitations to using shape keys: The two meshes must have the same number of vertices Preferably the two meshes should have the same topology (i.e. the way in which the vertices are connected to form polygons). If the topology doesn't match then strange results during morphing can occur. The above is a fairly annoying limitation, but there is no easy way around it in Blender, unfortunately. XXX movie","title":"Overview"},{"location":"modules/advanced/animation/shape_keys/#exercise-poor-bunny","text":"Load bunny_shape_keys.blend This scene contains the Stanford Bunny and a completely flattened version of the Bunny Verify that these meshes have the same number of vertices. Do a visual comparison in wireframe mode ( Z > Wireframe ) We'll now add some shape keys: Select the regular Bunny Add a shape key under Shape Keys in the Mesh properties using the + button. The new shape keys will be called Basis Add a second shape key, it will be called Key 1 and have a default influence of 0 Select the Key 1 shape key and enter mesh edit mode in the 3D view with TAB and make sure you're in vertex mode by pressing 1 Select parts of the Bunny mesh and transform them as you like. The changes should be clearly visible. Exit mesh edit mode with TAB . You should notice that the mesh returns to its normal shape. Change the influence value of Key 1 to see what happens to the resulting mesh. You can either click on it and enter a number, of click and drag the value. Let's add another shape key: Add a third shape key, it will be called Key 2 . Select Key 2 and apply a second set of mesh changes in edit mode Once again exit edit mode Play around with the influence values of both shape keys, as well as the checkboxes next to the influence values. Checking the difference between relative and absolute shape keys: Uncheck the Relative checkbox to switch to absolute shape keys. Notice that the influence values have now disappeared. Change the Evolution Time value to understand how the morphing of the meshes is done now Using another mesh to define a shape key: Delete shape keys Key 1 and Key 2 using the - button and change back to relative shape keys by checking the Relative checkbox. Select the flattened mesh and the Shift-click the Bunny mesh. Open the shape key menu using the downwards arrow below the + and - buttons. Select Join as Shapes There should now be a new shape key called flattened mesh . Vary the influence of the flattened mesh shape key to see the Bunny melt. Delete the flattened mesh object in the Outliner. Does the shape key morphing to melt the Bunny still work? Looking closer at the behaviour of the mesh morphing: Try to reason why the head of the Bunny is the last part to melt. Zoom in a bit to see if you can spot the twisting motion that mesh makes as it melts. Try to transform the mesh in the melted shape key in such as way as to minimize the twist. Or toy around with other mesh transforms to see what morphs come out","title":"(EXERCISE) Poor Bunny"},{"location":"modules/advanced/final_project/final_project/","text":"Final project: making a visualization of your own data \u00b6 We would like you to spend the remainder of your time in this course on doing this little project. We have two options for you to choose from. The first and recommended one is making a visualization of your own (research) data. The second option is that you work on a visualization of data we have prepared. Do not forget that if you are stuck to join us on Discord or in a feedback webinar so we can help. See the Course overview for more information. If you made a nice visualization and still have time left in the course, why not make an animation? Option 1: your own data \u00b6 So far you have learned how to make meshes and vertex colors in Blender using Python. So, think about if you can visualize your data using these techniques. You need to think about what you need to do to transform your data into a form that can be used to generate vertices, faces and vertex colors. And how do you want to visualize your data values? Can you visualize them through the Cartesian coordinates of the vertices and faces and maybe some colors? Do you need to use vertex coloring? Or do you need something else? Note that volumetric data will be difficult in Blender and you may need to think of some tricks. Option 2: visualize a computer model of a proto-planetary disk \u00b6 Although we highly recommend you to work on your own data, if you have none to use, you can use the following data to work on. Here we give a brief introduction to the data. What is a proto-planetary disk \u00b6 A proto-planetary disk is a disk-like structure around a newly born star. This disk is filled with dust (solid-state particles with a diameter in the order of 1 micrometer) and gas. In the course of time this dust and gas can coalesce into planets. In this option we will look at a computer model of the dust in such a disk. The model calculates the temperature and density of the dust in the disk, taking the radiation and gravity of the star into account. The calculations of the software (called MCMax ) are done iteratively using Monte Carlo techniques. Packages of photons are emitted by the star in random directions and their wavelength sampled from the radiation distribution of the star (by default a blackbody). Using the absorption, scattering and emission properties of the dust grains in the disk, the scattering, absorption and re-emission of the photons are calculated throughout the disk. This is used to calculate a temperature structure in the disk. This temperature is then used to adapt the starting density structure of the disk after which a new pass is done by tracking a next set of photons and adapting the density subsequently. This is repeated until convergence is reached. The code uses a two dimensional (adaptable) grid in the radial and theta direction. The disk is assumed to be cylindrically symmetric around the polar axis (z-axis, see Fig. 1). The grid cell size is lowered in regions where the density becomes high. Figure 1: definition of coordinates How to start visualizing such a proto-planetary disk \u00b6 You could create a 3D model of the disk at constant density and display the temperature as colors on the surface of the model. You could use this to make nice renders and animations to show the temperature structure of the disk. For this we need to pre-process the data from the model to get the spatial coordinates of the disk at a constant density. These coordinates then need to be converted into Cartesian coordinates of vertices and faces before creating the geometry in Blender. You can then add the temperatures to the faces using vertex coloring and by adding the needed shaders to the model. How the model data is structured \u00b6 You can download the data here . An example output file of modeling code MCMax is shown below. # Format number 5 # NR, NT, NGRAINS, NGRAINS2 100 100 1 1 # Spherical radius grid [cm] (middle of cell) 7479900216981.22 7479900572789.07 [...] # Theta grid [rad, from pole] (middle of cell) 9.233559849414326E-003 2.365344804038962E-002 [...] # Density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] # Temperature array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1933.54960366819 1917.22966277529 [...] # Composition array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.00000000000000 1.00000000000000 [...] # Gas density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-048 1.001753516582521E-048 [...] # Density0 array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] The file is structured in a way the scientist thought best at the time using the tools at hand. For us it is important to notice the NR and NT , which stands for number of radial and theta points respectively (NGRAINS is related to the number of different types of dust grains in the disk and you can ignore this). Further, the output file then lists the radius points and after that the theta points. Subsequently temperature and density values are listed by iterating over the radius and then the theta indices. The units of all the values in the MCMax output are: R[cm], Theta[radians], Density[gr/cm^3], Temperature[K]. The data from the MCMax code is in spherical coordinates, while the system in Blender works with Cartesian coordinates. The theta in the output is defined as the angle with the z-axis (See Fig. 1). How it could look \u00b6 To help you get an idea of what the data of the proto-planetary disk might look like, check this video we made:","title":"Final project: making a visualization of your own data"},{"location":"modules/advanced/final_project/final_project/#final-project-making-a-visualization-of-your-own-data","text":"We would like you to spend the remainder of your time in this course on doing this little project. We have two options for you to choose from. The first and recommended one is making a visualization of your own (research) data. The second option is that you work on a visualization of data we have prepared. Do not forget that if you are stuck to join us on Discord or in a feedback webinar so we can help. See the Course overview for more information. If you made a nice visualization and still have time left in the course, why not make an animation?","title":"Final project: making a visualization of your own data"},{"location":"modules/advanced/final_project/final_project/#option-1-your-own-data","text":"So far you have learned how to make meshes and vertex colors in Blender using Python. So, think about if you can visualize your data using these techniques. You need to think about what you need to do to transform your data into a form that can be used to generate vertices, faces and vertex colors. And how do you want to visualize your data values? Can you visualize them through the Cartesian coordinates of the vertices and faces and maybe some colors? Do you need to use vertex coloring? Or do you need something else? Note that volumetric data will be difficult in Blender and you may need to think of some tricks.","title":"Option 1: your own data"},{"location":"modules/advanced/final_project/final_project/#option-2-visualize-a-computer-model-of-a-proto-planetary-disk","text":"Although we highly recommend you to work on your own data, if you have none to use, you can use the following data to work on. Here we give a brief introduction to the data.","title":"Option 2: visualize a computer model of a proto-planetary disk"},{"location":"modules/advanced/final_project/final_project/#what-is-a-proto-planetary-disk","text":"A proto-planetary disk is a disk-like structure around a newly born star. This disk is filled with dust (solid-state particles with a diameter in the order of 1 micrometer) and gas. In the course of time this dust and gas can coalesce into planets. In this option we will look at a computer model of the dust in such a disk. The model calculates the temperature and density of the dust in the disk, taking the radiation and gravity of the star into account. The calculations of the software (called MCMax ) are done iteratively using Monte Carlo techniques. Packages of photons are emitted by the star in random directions and their wavelength sampled from the radiation distribution of the star (by default a blackbody). Using the absorption, scattering and emission properties of the dust grains in the disk, the scattering, absorption and re-emission of the photons are calculated throughout the disk. This is used to calculate a temperature structure in the disk. This temperature is then used to adapt the starting density structure of the disk after which a new pass is done by tracking a next set of photons and adapting the density subsequently. This is repeated until convergence is reached. The code uses a two dimensional (adaptable) grid in the radial and theta direction. The disk is assumed to be cylindrically symmetric around the polar axis (z-axis, see Fig. 1). The grid cell size is lowered in regions where the density becomes high. Figure 1: definition of coordinates","title":"What is a proto-planetary disk"},{"location":"modules/advanced/final_project/final_project/#how-to-start-visualizing-such-a-proto-planetary-disk","text":"You could create a 3D model of the disk at constant density and display the temperature as colors on the surface of the model. You could use this to make nice renders and animations to show the temperature structure of the disk. For this we need to pre-process the data from the model to get the spatial coordinates of the disk at a constant density. These coordinates then need to be converted into Cartesian coordinates of vertices and faces before creating the geometry in Blender. You can then add the temperatures to the faces using vertex coloring and by adding the needed shaders to the model.","title":"How to start visualizing such a proto-planetary disk"},{"location":"modules/advanced/final_project/final_project/#how-the-model-data-is-structured","text":"You can download the data here . An example output file of modeling code MCMax is shown below. # Format number 5 # NR, NT, NGRAINS, NGRAINS2 100 100 1 1 # Spherical radius grid [cm] (middle of cell) 7479900216981.22 7479900572789.07 [...] # Theta grid [rad, from pole] (middle of cell) 9.233559849414326E-003 2.365344804038962E-002 [...] # Density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] # Temperature array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1933.54960366819 1917.22966277529 [...] # Composition array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.00000000000000 1.00000000000000 [...] # Gas density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-048 1.001753516582521E-048 [...] # Density0 array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] The file is structured in a way the scientist thought best at the time using the tools at hand. For us it is important to notice the NR and NT , which stands for number of radial and theta points respectively (NGRAINS is related to the number of different types of dust grains in the disk and you can ignore this). Further, the output file then lists the radius points and after that the theta points. Subsequently temperature and density values are listed by iterating over the radius and then the theta indices. The units of all the values in the MCMax output are: R[cm], Theta[radians], Density[gr/cm^3], Temperature[K]. The data from the MCMax code is in spherical coordinates, while the system in Blender works with Cartesian coordinates. The theta in the output is defined as the angle with the z-axis (See Fig. 1).","title":"How the model data is structured"},{"location":"modules/advanced/final_project/final_project/#how-it-could-look","text":"To help you get an idea of what the data of the proto-planetary disk might look like, check this video we made:","title":"How it could look"},{"location":"modules/advanced/mesh_editing/introduction/","text":"Introduction \u00b6 Warning This chapter is fresh off the mill and does not have any slides or a walkthrough yet, but with the knowledge of the basics course you might be able to follow the assignments. This chapter will give you an introduction on the Edit mode of the 3D viewport where you will learn how to patch up your imported meshes/visualizations and even learn how to generate your own 3D shapes.","title":"Introduction"},{"location":"modules/advanced/mesh_editing/introduction/#introduction","text":"Warning This chapter is fresh off the mill and does not have any slides or a walkthrough yet, but with the knowledge of the basics course you might be able to follow the assignments. This chapter will give you an introduction on the Edit mode of the 3D viewport where you will learn how to patch up your imported meshes/visualizations and even learn how to generate your own 3D shapes.","title":"Introduction"},{"location":"modules/advanced/mesh_editing/mesh_editing_assignment/","text":"(EXERCISE) Advanced Mesh Editing \u00b6 This assignment will be a brief introduction on the Edit mode in the 3D viewport . Once you opened the exercise blend file sme_assignment.blend you'll see the familiar fish iso-surface above a plane. Getting familiar with the Edit mode \u00b6 To edit the mesh we first need to go the Edit mode with the fish. Select the fish and enter the Edit mode by pressing Tab . Depending on the speed of the system you're working on edit mode might be entered instantly or might take 1/2 second. In general, for larger meshes switching to edit may take longer. Now you will be able to see all the vertices, edges and faces that make up the 3D model. You will now try to select and move around some vertices, edges and/or faces. Change the Mesh Select Mode to Vertex by pressing 1 (or click the left icon in at the 3D view header). Before you start selecting, de-select all all current selected vertices by pressing Alt-A or double 'A' rapidly. Now try to select a single vertex by clicking on it with the LMB , or multiple with Shift-LMB . You might have to zoom in a bit to separate the vertices enough. Another method is to use the selection tools: Box selection by pressing B and dragging a box around the vertices you want to select. Hold Shift to de-select. Circle selection by pressing C and left-clicking and dragging with the mouse over the vertices you want to select. To increase the size of the Circle selection tool simply scroll with your mouse Wheel . With MMB and dragging you can de-select vertices. Press Enter to exit circle select mode (or with RMB ). Once you selected your vertices you can transform them the same way you can do with objects by pressing the hotkeys G for translation, R for rotation, and S for scaling, etc. Probably now you did the vertex editing the fish looks a bit scrabbled. One way to clean it up is, of course, using Ctrl-Z to undo it. Another way is simply deleting the vertices by using the Delete popup menu X > Vertices . Try to remove part of the fish skin to it leaves a hole in the mesh which will reveal a part of the inside of the fish. Tip! : If your fish has been \"meshed-up\" beyond repair you can always revert it to the last saved state with: File > Revert > Confirm . Filling the holes \u00b6 An imported mesh from a 3D visualization program can sometimes contain unwanted holes or separations in parts of the mesh, these can also be fixed in the edit mode. Conveniently the fish in the exercise file was already poked full of holes so you can fix these. In between : To better inspect if there are any holes left you can switch back and forth between the Object mode and Edit mode because in the Object mode they are easier to see. First, make sure the whole mesh is selected by pressing a and then remove the small holes (the size of one triangle/quad) by pressing F3 in the 3D viewport in Edit mode and type in fill holes and press enter or click on it with LMB (this might take some time). Now this already cleaned up a lot of the holes in the geometry! Through inspection you might notices there are some bigger wholes that were not filled yet because they were skipped by the previous step since they were to large. To fill these they first need to be selected by first de-selecting everything with alt-a and then press F3 and type in non manifold and press enter or click on it with LMB . This selected the big holes but also other non- manifold geometry. To select only one of the holes hold CTRL+SHIFT and drag with LMB over one of the holes. This de-selects everything excepts what was in the drag-box. Now this selected whole can easily be fixed by pressing f . Repeat step 2 to 4 for the other 2 holes. Tip! : The fill with f fills the hole with an n-gon, a face with more then 4 vertices. These can sometimes create shading artifacts in your final render. Another way to fill these holes is to use grid-fill ( ctrl+f ), this tries to fill the whole with a grid of quad shaped faces. This however might not always work for numerous reasons (uneven amount of vertices, closed loops etc) which can be fixed with additional mesh editing but the easy route would be to fill it with an n-gon face. Separating skin from bones) \u00b6 Now that you got a little familiar with mesh editing you can try to separate the skin from the bones by using mesh separation. While still in edit mode (press Tab if not), try to select all the outside skin with the select linked selection by hovering the mouse cursor over the geometry and pressing L . This will only select a connected part of the skin so continue this step until you think you selected all the outside skin. Note that it is difficult to do this perfectly, as some of the insides of the fish are sometimes also selectable. Unfortunately, this occurs frequently with this type of sensor-based 3D data. Once you think all the skin is selected you can press P and select Selection to separate the selected surfaces from the main mesh into another mesh object. This new mesh will be added to the Outliner with the name fish.001 . In the Outliner double-click LMB on the mesh object fish.001 to rename it to fishskin . Do the same for the fish mesh object and rename it to fishbones . If you now select the fishskin mesh object and hide it by clicking the little icon in the Outliner will reveal the insides of the fish. Tips! : - To reverse the separation of the mesh into bone and skin you can select both the mesh objects in Object mode and press Ctrl-J to join them back together into a single mesh. - Sometimes X-ray mode, toggled with Alt-Z can be useful when editing a complex mesh, as it makes all geometry in a mesh partly transparent (BONUS) Make your own annotation arrow \u00b6 Since the content of this course is mostly geared towards imported geometry or scripted geometry, you might not directly think about manually created geometry. This bonus exercise however will show you that it is relatively easy to create your own geometry in Blender. Lets start your manual mesh creation with an annotation arrow! In the 3D viewport make sure you are in Object mode and add a new cylinder with Shift-A > Mesh > Cylinder . Press / to isolate the mesh so that there are no distractions. This can be reversed again by pressing / . Press Tab to go into Edit mode . Grab the selected geometry by pressing g and press z to move it along the z-axis only and press 1 to move it 1 unit up so that the origin is at the bottom. De-select all the geometry with Alt-A and press 1 to set the select mode to Vertex and select all the bottom vertices (with LMB-drag over the vertices or with the b Box-select). Press s to scale them to a tiny point and press LMB to confirm. Now select the top vertices the same way you did with the bottom vertices, make sure that none of the bottom vertices are selected. Press i to inset the faces and move your mouse until you are satisfied with the width of the arrow shaft. Press e to extrude the selection and move the mouse up until you are satisfied with the length of the arrow shaft. Now press Tab and admire your newly created arrow! The arrow might now be a bit too big compared to the fish so scale the arrow down with s , move it to a point of interest with g and rotate the arrow to your liking with r (which is made relatively easy because we made it so that the origin is at the point) Since the introduction of the Edit mode and switching back and forth between it and the Object mode you do need to make sure in which mode you are before adding new geometry or before using one of the transform operations (grab, scale and rotate). Otherwise you might add geometry to an already existing object instead of adding a new 3D object or you might move, scale or rotate 3D object geometry in the Edit mode and inadvertently change the origin of the object. This can be confusing sometimes but you'll get used to it!","title":"(EXERCISE) Advanced Mesh Editing"},{"location":"modules/advanced/mesh_editing/mesh_editing_assignment/#exercise-advanced-mesh-editing","text":"This assignment will be a brief introduction on the Edit mode in the 3D viewport . Once you opened the exercise blend file sme_assignment.blend you'll see the familiar fish iso-surface above a plane.","title":"(EXERCISE) Advanced Mesh Editing"},{"location":"modules/advanced/mesh_editing/mesh_editing_assignment/#getting-familiar-with-the-edit-mode","text":"To edit the mesh we first need to go the Edit mode with the fish. Select the fish and enter the Edit mode by pressing Tab . Depending on the speed of the system you're working on edit mode might be entered instantly or might take 1/2 second. In general, for larger meshes switching to edit may take longer. Now you will be able to see all the vertices, edges and faces that make up the 3D model. You will now try to select and move around some vertices, edges and/or faces. Change the Mesh Select Mode to Vertex by pressing 1 (or click the left icon in at the 3D view header). Before you start selecting, de-select all all current selected vertices by pressing Alt-A or double 'A' rapidly. Now try to select a single vertex by clicking on it with the LMB , or multiple with Shift-LMB . You might have to zoom in a bit to separate the vertices enough. Another method is to use the selection tools: Box selection by pressing B and dragging a box around the vertices you want to select. Hold Shift to de-select. Circle selection by pressing C and left-clicking and dragging with the mouse over the vertices you want to select. To increase the size of the Circle selection tool simply scroll with your mouse Wheel . With MMB and dragging you can de-select vertices. Press Enter to exit circle select mode (or with RMB ). Once you selected your vertices you can transform them the same way you can do with objects by pressing the hotkeys G for translation, R for rotation, and S for scaling, etc. Probably now you did the vertex editing the fish looks a bit scrabbled. One way to clean it up is, of course, using Ctrl-Z to undo it. Another way is simply deleting the vertices by using the Delete popup menu X > Vertices . Try to remove part of the fish skin to it leaves a hole in the mesh which will reveal a part of the inside of the fish. Tip! : If your fish has been \"meshed-up\" beyond repair you can always revert it to the last saved state with: File > Revert > Confirm .","title":"Getting familiar with the Edit mode"},{"location":"modules/advanced/mesh_editing/mesh_editing_assignment/#filling-the-holes","text":"An imported mesh from a 3D visualization program can sometimes contain unwanted holes or separations in parts of the mesh, these can also be fixed in the edit mode. Conveniently the fish in the exercise file was already poked full of holes so you can fix these. In between : To better inspect if there are any holes left you can switch back and forth between the Object mode and Edit mode because in the Object mode they are easier to see. First, make sure the whole mesh is selected by pressing a and then remove the small holes (the size of one triangle/quad) by pressing F3 in the 3D viewport in Edit mode and type in fill holes and press enter or click on it with LMB (this might take some time). Now this already cleaned up a lot of the holes in the geometry! Through inspection you might notices there are some bigger wholes that were not filled yet because they were skipped by the previous step since they were to large. To fill these they first need to be selected by first de-selecting everything with alt-a and then press F3 and type in non manifold and press enter or click on it with LMB . This selected the big holes but also other non- manifold geometry. To select only one of the holes hold CTRL+SHIFT and drag with LMB over one of the holes. This de-selects everything excepts what was in the drag-box. Now this selected whole can easily be fixed by pressing f . Repeat step 2 to 4 for the other 2 holes. Tip! : The fill with f fills the hole with an n-gon, a face with more then 4 vertices. These can sometimes create shading artifacts in your final render. Another way to fill these holes is to use grid-fill ( ctrl+f ), this tries to fill the whole with a grid of quad shaped faces. This however might not always work for numerous reasons (uneven amount of vertices, closed loops etc) which can be fixed with additional mesh editing but the easy route would be to fill it with an n-gon face.","title":"Filling the holes"},{"location":"modules/advanced/mesh_editing/mesh_editing_assignment/#separating-skin-from-bones","text":"Now that you got a little familiar with mesh editing you can try to separate the skin from the bones by using mesh separation. While still in edit mode (press Tab if not), try to select all the outside skin with the select linked selection by hovering the mouse cursor over the geometry and pressing L . This will only select a connected part of the skin so continue this step until you think you selected all the outside skin. Note that it is difficult to do this perfectly, as some of the insides of the fish are sometimes also selectable. Unfortunately, this occurs frequently with this type of sensor-based 3D data. Once you think all the skin is selected you can press P and select Selection to separate the selected surfaces from the main mesh into another mesh object. This new mesh will be added to the Outliner with the name fish.001 . In the Outliner double-click LMB on the mesh object fish.001 to rename it to fishskin . Do the same for the fish mesh object and rename it to fishbones . If you now select the fishskin mesh object and hide it by clicking the little icon in the Outliner will reveal the insides of the fish. Tips! : - To reverse the separation of the mesh into bone and skin you can select both the mesh objects in Object mode and press Ctrl-J to join them back together into a single mesh. - Sometimes X-ray mode, toggled with Alt-Z can be useful when editing a complex mesh, as it makes all geometry in a mesh partly transparent","title":"Separating skin from bones)"},{"location":"modules/advanced/mesh_editing/mesh_editing_assignment/#bonus-make-your-own-annotation-arrow","text":"Since the content of this course is mostly geared towards imported geometry or scripted geometry, you might not directly think about manually created geometry. This bonus exercise however will show you that it is relatively easy to create your own geometry in Blender. Lets start your manual mesh creation with an annotation arrow! In the 3D viewport make sure you are in Object mode and add a new cylinder with Shift-A > Mesh > Cylinder . Press / to isolate the mesh so that there are no distractions. This can be reversed again by pressing / . Press Tab to go into Edit mode . Grab the selected geometry by pressing g and press z to move it along the z-axis only and press 1 to move it 1 unit up so that the origin is at the bottom. De-select all the geometry with Alt-A and press 1 to set the select mode to Vertex and select all the bottom vertices (with LMB-drag over the vertices or with the b Box-select). Press s to scale them to a tiny point and press LMB to confirm. Now select the top vertices the same way you did with the bottom vertices, make sure that none of the bottom vertices are selected. Press i to inset the faces and move your mouse until you are satisfied with the width of the arrow shaft. Press e to extrude the selection and move the mouse up until you are satisfied with the length of the arrow shaft. Now press Tab and admire your newly created arrow! The arrow might now be a bit too big compared to the fish so scale the arrow down with s , move it to a point of interest with g and rotate the arrow to your liking with r (which is made relatively easy because we made it so that the origin is at the point) Since the introduction of the Edit mode and switching back and forth between it and the Object mode you do need to make sure in which mode you are before adding new geometry or before using one of the transform operations (grab, scale and rotate). Otherwise you might add geometry to an already existing object instead of adding a new 3D object or you might move, scale or rotate 3D object geometry in the Edit mode and inadvertently change the origin of the object. This can be confusing sometimes but you'll get used to it!","title":"(BONUS) Make your own annotation arrow"},{"location":"modules/advanced/python_scripting/1_api_basics/","text":"Blender API basics \u00b6 Introduction \u00b6 Blender contains a Python interpreter that, at startup, runs scripts to construct the interface and run internal tools. The user can run scripts directly on this interpreter and also access modules provided by Blender like bpy and mathutils . The bpy module gives access to Blender's data, functions and classes. In this section we will focus on using the Python API for automation, custom data import and manipulating geometry, but this is not all that is possible with the API, of course. The official API manual states the following items are possible within the Python API: Edit any data the user interface can (Scenes, Meshes, Particles etc.). Modify user preferences, key-maps and themes. Run tools with own settings. Create user interface elements such as menus, headers and panels. Create new tools. Create interactive tools. Create new rendering engines that integrate with Blender. Subscribe to changes to data and it's properties. Define new settings in existing Blender data. Draw in the 3D view using Python. Before we continue, we list some bits of information and some tricks that are good to know. Blender uses Python 3.x since Blender 2.5; some online documentation still assumes 2.x. You can access the online API documentation from within Blender with Help > Python API Reference Starting Blender from the console will allow you to see important outputs channels (warnings, exceptions, print() statements, etc). See the next section how to do this. The Python Console area in Blender is great for testing Python one-liners. It also has auto-completion so you can inspect the API quickly. Example code shown with >>> lines is assumed to be running in the Python Console. Note The Python Console is something different than the console we refer to below. The former is an area within the Blender user interface in which you can enter and execute Python commands, while the latter is a terminal window or DOS box. In Blender you can hover over almost any button, option, menu, etc and after a second a tool-tip is shown. This tool-tip shows information on how to use this element in the Python API. Right clicking on almost any button, option, menu, etc in Blender gives you the option to 1) directly go to the API documentation with Online Manual or 2) Copy Data Path . Option 2 copies Python API properties related to that element to your clipboard to paste into your script. Note however, that not always the full path is copied, but only the last part. In the upcoming sections we will first look at how to run Python scripts in Blender. Then we look at how to access Blenders data through scripts and we follow this up with creating geometry, vertex colors and materials in the last section. Starting Blender from the command line \u00b6 It is important, when scripting, to start Blender from a command line interface (macOS and Linux). Warnings, messages and print() statements will output into the console. How to start Blender from the command line depends on your operating system. For macOS it would be like this: /Applications/Blender.app/Contents/MacOS/Blender For Linux it would be something like: $ <blender installation directory>/blender In Windows you can use Window => Toggle System Console to open the console from the Blender interface, so you don't need to start Blender from the command line More information on where the Blender executable is located on your system and where Blender directories of interest are located see this manual page . (EXERCISE 1) Starting Blender from the console \u00b6 Find the Blender executable on your machine. Open Blender through the console. Delete the cube in the default project of Blender, what output is shown in the console? Run scripts within the Blender interface \u00b6 When scripting inside Blender it is convenient to use the Scripting workspace (Fig. 1: see the arrow). It gives you a Python Console (Fig 1: A) and a Text Editor (Fig 1: B). Running scripts within Blender you have a two main options: Interactive Python Console in the Blender interface (Fig. 1: A) Use the built-in Text Editor (Fig. 1: B) The Python Console is nice for exploring the API using auto-complete ( TAB in 2.82+, Ctrl-Space in older versions) to see what is available. The keyboard shortcuts are a bit different than you might be used to in other text editors. See this section in the Blender manual for an overview of menu options and shortcut keys. Blender also has its own built-in editor which you can use (Fig. 1: B) and directly execute the script by pressing the button in the top bar. If you want to use your own editor to edit your scripts you can do this by opening the script in both the Blender Text Editor and your own editor. To refresh the Blender Text Editor use Text > Reload or Alt R (or Option R on the Mac). You can also make a script that you open in the Blender Text Editor that executes an external script you edit in your own editor. See for example the script in Fig. 1: B. Figure 1: The Scripting workspace in Blender Run scripts from the command-line \u00b6 You can also run Python scripts in Blender directly from the command-line interface. An example of executing a script ( -P ) without opening the Blender GUI ( -b , for background) on a Mac would be: blender -b -P script.py Or if you want to render the first frame ( -f 1 ) from an example test.blend file. The output will go to the directory of the blender file ( -o //... ) and it will generate a PNG image file ( -F PNG ). blender -b test.blend -o //render_ -F PNG -f 1 More information on command line arguments is here . Load modules in Blender \u00b6 You can add startup scripts to your Blender installation. These scripts can then be easily imported into your script. These scripts can be placd here: scripts\u2028/startup/ in the Blender directory (for example on a Mac: /Applications/Blender.app/Contents/Resources/2.81/scripts\u2028/startup/ ). For scripts you want to import for just one project or Blender file you can use the normal Python method of editing sys.path : import sys sys . path . append ( \"/some_directory/\" ) import python_module Tip The official binaries of Blender from blender.org include the numpy Python module, so import numpy should work out of the box","title":"Blender API basics"},{"location":"modules/advanced/python_scripting/1_api_basics/#blender-api-basics","text":"","title":"Blender API basics"},{"location":"modules/advanced/python_scripting/1_api_basics/#introduction","text":"Blender contains a Python interpreter that, at startup, runs scripts to construct the interface and run internal tools. The user can run scripts directly on this interpreter and also access modules provided by Blender like bpy and mathutils . The bpy module gives access to Blender's data, functions and classes. In this section we will focus on using the Python API for automation, custom data import and manipulating geometry, but this is not all that is possible with the API, of course. The official API manual states the following items are possible within the Python API: Edit any data the user interface can (Scenes, Meshes, Particles etc.). Modify user preferences, key-maps and themes. Run tools with own settings. Create user interface elements such as menus, headers and panels. Create new tools. Create interactive tools. Create new rendering engines that integrate with Blender. Subscribe to changes to data and it's properties. Define new settings in existing Blender data. Draw in the 3D view using Python. Before we continue, we list some bits of information and some tricks that are good to know. Blender uses Python 3.x since Blender 2.5; some online documentation still assumes 2.x. You can access the online API documentation from within Blender with Help > Python API Reference Starting Blender from the console will allow you to see important outputs channels (warnings, exceptions, print() statements, etc). See the next section how to do this. The Python Console area in Blender is great for testing Python one-liners. It also has auto-completion so you can inspect the API quickly. Example code shown with >>> lines is assumed to be running in the Python Console. Note The Python Console is something different than the console we refer to below. The former is an area within the Blender user interface in which you can enter and execute Python commands, while the latter is a terminal window or DOS box. In Blender you can hover over almost any button, option, menu, etc and after a second a tool-tip is shown. This tool-tip shows information on how to use this element in the Python API. Right clicking on almost any button, option, menu, etc in Blender gives you the option to 1) directly go to the API documentation with Online Manual or 2) Copy Data Path . Option 2 copies Python API properties related to that element to your clipboard to paste into your script. Note however, that not always the full path is copied, but only the last part. In the upcoming sections we will first look at how to run Python scripts in Blender. Then we look at how to access Blenders data through scripts and we follow this up with creating geometry, vertex colors and materials in the last section.","title":"Introduction"},{"location":"modules/advanced/python_scripting/1_api_basics/#starting-blender-from-the-command-line","text":"It is important, when scripting, to start Blender from a command line interface (macOS and Linux). Warnings, messages and print() statements will output into the console. How to start Blender from the command line depends on your operating system. For macOS it would be like this: /Applications/Blender.app/Contents/MacOS/Blender For Linux it would be something like: $ <blender installation directory>/blender In Windows you can use Window => Toggle System Console to open the console from the Blender interface, so you don't need to start Blender from the command line More information on where the Blender executable is located on your system and where Blender directories of interest are located see this manual page .","title":"Starting Blender from the command line"},{"location":"modules/advanced/python_scripting/1_api_basics/#exercise-1-starting-blender-from-the-console","text":"Find the Blender executable on your machine. Open Blender through the console. Delete the cube in the default project of Blender, what output is shown in the console?","title":"(EXERCISE 1) Starting Blender from the console"},{"location":"modules/advanced/python_scripting/1_api_basics/#run-scripts-within-the-blender-interface","text":"When scripting inside Blender it is convenient to use the Scripting workspace (Fig. 1: see the arrow). It gives you a Python Console (Fig 1: A) and a Text Editor (Fig 1: B). Running scripts within Blender you have a two main options: Interactive Python Console in the Blender interface (Fig. 1: A) Use the built-in Text Editor (Fig. 1: B) The Python Console is nice for exploring the API using auto-complete ( TAB in 2.82+, Ctrl-Space in older versions) to see what is available. The keyboard shortcuts are a bit different than you might be used to in other text editors. See this section in the Blender manual for an overview of menu options and shortcut keys. Blender also has its own built-in editor which you can use (Fig. 1: B) and directly execute the script by pressing the button in the top bar. If you want to use your own editor to edit your scripts you can do this by opening the script in both the Blender Text Editor and your own editor. To refresh the Blender Text Editor use Text > Reload or Alt R (or Option R on the Mac). You can also make a script that you open in the Blender Text Editor that executes an external script you edit in your own editor. See for example the script in Fig. 1: B. Figure 1: The Scripting workspace in Blender","title":"Run scripts within the Blender interface"},{"location":"modules/advanced/python_scripting/1_api_basics/#run-scripts-from-the-command-line","text":"You can also run Python scripts in Blender directly from the command-line interface. An example of executing a script ( -P ) without opening the Blender GUI ( -b , for background) on a Mac would be: blender -b -P script.py Or if you want to render the first frame ( -f 1 ) from an example test.blend file. The output will go to the directory of the blender file ( -o //... ) and it will generate a PNG image file ( -F PNG ). blender -b test.blend -o //render_ -F PNG -f 1 More information on command line arguments is here .","title":"Run scripts from the command-line"},{"location":"modules/advanced/python_scripting/1_api_basics/#load-modules-in-blender","text":"You can add startup scripts to your Blender installation. These scripts can then be easily imported into your script. These scripts can be placd here: scripts\u2028/startup/ in the Blender directory (for example on a Mac: /Applications/Blender.app/Contents/Resources/2.81/scripts\u2028/startup/ ). For scripts you want to import for just one project or Blender file you can use the normal Python method of editing sys.path : import sys sys . path . append ( \"/some_directory/\" ) import python_module Tip The official binaries of Blender from blender.org include the numpy Python module, so import numpy should work out of the box","title":"Load modules in Blender"},{"location":"modules/advanced/python_scripting/2_accessing_data/","text":"Accessing Blender data \u00b6 Using bpy.data \u00b6 All data in a Blender file can be accessed through bpy.data . This contains for example all objects ( bpy.data.objects ), all meshes ( bpy.data.meshes ), all scenes ( bpy.data.scenes ) and all materials ( bpy.data.materials ). The data is stored in a data-type called bpy_collection whose members (data blocks) can be accessed with both an index as well as a string (this in contrary to regular Python dictionaries). For example. bpy.data.objects[\"Cube\"] and bpy.data.objects[1] will be equivalent if Cube is the second object in the collection. Attributes of data blocks (e.g an object, collection or material) can be accessed with a period. For example: >>> bpy . data . objects [ 0 ] . name 'Camera' Two examples of changing attributes (note that some operations only work if Blender is in the right mode): bpy . data . objects [ \"Cube\" ] . location . z += 1 # this works in both edit and object mode bpy . data . objects [ \"Cube\" ] . data . vertices [ 0 ] . co . z += 10 # this works only in object mode Tips Use the Python Console in Blender and the auto-complete functionality to see what attributes bpy.data has. The Info Editor in Blender shows the python commands being executed when you do operations manually in Blender (See Fig. 2.) Hovering over buttons and input boxes in Blender shows how to access the underlying values through the Python API. Figure 2: The Info Editor is a nice way to see what python commands are executed when you use Blender. In this figure we see that we deleted the initial cube, made a UV Sphere and translated it. Some notes on bpy.context and bpy.ops \u00b6 In this section we want to briefly introduce how you can access the so-called context and use operators in the Blender Python API. bpy.context stores information about a user's selections and the context Blender is in. For example, if you want to check which mode is currently active in Blender you can check the value of bpy.context.mode . Now if you want to change the mode, you can use an operator. Operators are tools that are usually accessed through the user interface with buttons and menus. You can access these operators with Python through bpy.ops . If we would like to change the mode we can do this using an operator, e.g. bpy.ops.object.mode_set(mode='OBJECT') Of course switching to, say, edit mode, depends on which objects are selected, which can be checked with bpy.context.selected_objects . But keep in mind that many of the variables in the context are read-only, altering bpy.context.selected_objects directly is not possible. Instead, you can select an object with the select_set() method of the object, e.g. bpy.data.objects['Cube'].select_set(True) . (EXERCISE 2) Running a script and rendering from the console \u00b6 Write an external script that removes the Cube object that is part of the default scene 1 Then, from the command line and without opening the Blender GUI execute this script and render the first frame. Let it output a PNG image file in the directory of the blender file. Was the cube indeed removed from the rendered image? Extra question: is the cube removed from the blender file? Although you might have altered your startup scene to not have the cube \u21a9","title":"Accessing Blender data"},{"location":"modules/advanced/python_scripting/2_accessing_data/#accessing-blender-data","text":"","title":"Accessing Blender data"},{"location":"modules/advanced/python_scripting/2_accessing_data/#using-bpydata","text":"All data in a Blender file can be accessed through bpy.data . This contains for example all objects ( bpy.data.objects ), all meshes ( bpy.data.meshes ), all scenes ( bpy.data.scenes ) and all materials ( bpy.data.materials ). The data is stored in a data-type called bpy_collection whose members (data blocks) can be accessed with both an index as well as a string (this in contrary to regular Python dictionaries). For example. bpy.data.objects[\"Cube\"] and bpy.data.objects[1] will be equivalent if Cube is the second object in the collection. Attributes of data blocks (e.g an object, collection or material) can be accessed with a period. For example: >>> bpy . data . objects [ 0 ] . name 'Camera' Two examples of changing attributes (note that some operations only work if Blender is in the right mode): bpy . data . objects [ \"Cube\" ] . location . z += 1 # this works in both edit and object mode bpy . data . objects [ \"Cube\" ] . data . vertices [ 0 ] . co . z += 10 # this works only in object mode Tips Use the Python Console in Blender and the auto-complete functionality to see what attributes bpy.data has. The Info Editor in Blender shows the python commands being executed when you do operations manually in Blender (See Fig. 2.) Hovering over buttons and input boxes in Blender shows how to access the underlying values through the Python API. Figure 2: The Info Editor is a nice way to see what python commands are executed when you use Blender. In this figure we see that we deleted the initial cube, made a UV Sphere and translated it.","title":"Using bpy.data"},{"location":"modules/advanced/python_scripting/2_accessing_data/#some-notes-on-bpycontext-and-bpyops","text":"In this section we want to briefly introduce how you can access the so-called context and use operators in the Blender Python API. bpy.context stores information about a user's selections and the context Blender is in. For example, if you want to check which mode is currently active in Blender you can check the value of bpy.context.mode . Now if you want to change the mode, you can use an operator. Operators are tools that are usually accessed through the user interface with buttons and menus. You can access these operators with Python through bpy.ops . If we would like to change the mode we can do this using an operator, e.g. bpy.ops.object.mode_set(mode='OBJECT') Of course switching to, say, edit mode, depends on which objects are selected, which can be checked with bpy.context.selected_objects . But keep in mind that many of the variables in the context are read-only, altering bpy.context.selected_objects directly is not possible. Instead, you can select an object with the select_set() method of the object, e.g. bpy.data.objects['Cube'].select_set(True) .","title":"Some notes on bpy.context and bpy.ops"},{"location":"modules/advanced/python_scripting/2_accessing_data/#exercise-2-running-a-script-and-rendering-from-the-console","text":"Write an external script that removes the Cube object that is part of the default scene 1 Then, from the command line and without opening the Blender GUI execute this script and render the first frame. Let it output a PNG image file in the directory of the blender file. Was the cube indeed removed from the rendered image? Extra question: is the cube removed from the blender file? Although you might have altered your startup scene to not have the cube \u21a9","title":"(EXERCISE 2) Running a script and rendering from the console"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/","text":"Creating geometry, colors and materials \u00b6 Creating an object with a mesh \u00b6 If we want to create a new mesh we can do this by calling the new function like this: mesh = bpy . data . meshes . new ( \"newMesh\" ) This will create the mesh but it is not linked to an object (it will not show in the Outliner ). So we make a new object and link the object to the mesh: obj = bpy . data . objects . new ( \"newObject\" , mesh ) We can actually verify this worked correctly by checking the value of obj.data : >>> obj.data bpy.data.meshes['newMesh'] If you check the Outliner in the user interface you will see both the object newObject and the mesh newMesh linked to it. Now we have an empty mesh, linked to an object. We will now construct a simple piece geometry to show how this is done in Blender. Vertices are defined by their x, y and z values like this: verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) ] Edges are defined as a tuple holding two indices pointing to two vertices in the verts list. So (0,1) refers to a line from vertex (0,0,0) (index 0 in verts ) to (0,2,0) (index 1 in verts ) in this example. We make the following edges: edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ) ] To make faces we need three or more vertices. Per face you make a tuple of three or more indices pointing to three vertices in the verts list. For example the face (0,1,2) is a face made up from the vertices (0,0,0), (0,2,0) and (0,1,2), which are at index 0, 1 and 2 in the verts list. For now lets make one face: faces = [ ( 0 , 1 , 2 ) ] We now use a function from the Python API to make a mesh from our verts, edges and faces: mesh . from_pydata ( verts , edges , faces ) Now the mesh and the object are created, but it does not yet show in the 3D viewport or the Outliner . This is because we still need to link the new object to an existing collection and in so doing to a scene. bpy . data . collections [ 0 ] . objects . link ( obj ) To summarize here is the full code to generate this geometry: import bpy # Create a new mesh ob_name = \"triangle\" mesh = bpy . data . meshes . new ( ob_name + \"_mesh\" ) # Create a new object with the mesh ob = bpy . data . objects . new ( ob_name , mesh ) # Define some geometry verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) ] edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ) ] # These are indices pointing to elements in the list verts faces = [ ( 0 , 1 , 2 ) ] # These are indices pointing to elements in the list verts # Add it to the mesh mesh . from_pydata ( verts , edges , faces ) # Link the object to the first collection bpy . data . collections [ 0 ] . objects . link ( ob ) Tips Note that in general you do not need to explicitly specify edges, as these will be generated automatically based on the faces specified. It's only when you want to have edges that are not connected to faces that you need to specify them explicitly. All objects in Blender (and object data of the same type, i.e. all meshes) are enforced to have unique names. When using the Python API this is no different. So if you create an object with bpy.data.objects.new(\"obj\", mesh) and there already is an object named \"obj\" the name of the new object will be automatically set to something else. This can become important if you generate many objects (say in a loop) but still want to be able to refer to them later by name. (EXERCISE 3) A filled disk from scratch \u00b6 In the text above we created a triangle, now as an exercise let's create a spherical disk. First create a ring of vertices, then create edges and a face. Adding vertex colors to a mesh \u00b6 Vertex coloring is a way to color a mesh without using textures or uv-mapping. It works by assigning for every face that a vertex is a member of a color to that vertex. So a vertex can have different colors for each of the different faces it is in. Let's say we have a mesh, named \"triangle_mesh\": mesh = bpy.data.meshes['triangle_mesh'] , the vertex colors for this mesh will be stored in mesh.vertex_colors . If the mesh does not have a vertex color layer yet, you can make a new one with: mesh.vertex_colors.new(name='vert_colors') . Now we have a color layer to work with: color_layer = mesh.vertex_colors['vert_colors'] . (EXERCISE 4) Making triangles and make a vertex color layer \u00b6 Let's take the triangle we made in section 4.1, but let's add another triangle to it, attached to the first. The code would look like this: import bpy # Create a new mesh ob_name = \"triangle\" mesh = bpy . data . meshes . new ( ob_name + \"_mesh\" ) # Create a new object with the mesh ob = bpy . data . objects . new ( ob_name , mesh ) # Define some geometry verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) , ( 0 , 3 , 2 ) ] edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ), ( 1 , 3 ), ( 3 , 2 ) ] # These are indices pointing to elements in the list verts faces = [ ( 0 , 1 , 2 ), ( 1 , 3 , 2 ) ] # These are indices pointing to elements in the list verts # Add it to the mesh mesh . from_pydata ( verts , edges , faces ) # Link the object to the first collection bpy . data . collections [ 0 ] . objects . link ( ob ) Now make a vertex color layer for your triangles. Then inspect how many entries are in color_layer = mesh.vertex_colors['vert_colors'] . Why are they the same or different from the total number of vertices in the mesh? In exercise 4 we saw that color_layer.data contains six entries while we only have four vertices in the mesh. This is because a vertex has a color for every face it is in. So vertex (0,2,0) and (0,1,2) are each in two faces, while the other two vertices are only in one face. So the former vertices have two entries in the color layer, one for each face they are in, the latter only one color entry. The link between vertex indices in a mesh and those in the vertex color layer can be deduced from the polygons in mesh.polygons . Let's take one polygon from the triangles, lets say the first ( poly = mesh.polygons[0] ). Now, for one vertex in the polygon, poly.vertices gives you the index of the vertex in the mesh and poly.loop_indices gives you the index of the vertex in color_layer.data . See Fig. 3. Figure 3: Sketch of the two triangles from Exercise 4. For the vertices are shown the coordinates (in black italic (x, x, x)), indices of the vertex in its mesh (green, outside of the face) and the indices in the loop_indices of the polygon (red, italic and inside the faces.) Once you have set colors for your vertices you need to set up the shader of the object 1 . For this go to the Shading workspace. Create a Vertex Color node and connect it to a Principled BSDF (connect Color output to Base Color input). And then make a Material Output and connect the Principled BSDF to the Surface input of the Material Output . See Fig. 4. Figure 4: Shader setup for vertex colors Exercise 5: coloring your triangles \u00b6 Let's take the two connected triangles of exercise 4. We will color them in two different ways, using vertex coloring and Python scripting. a) Make the first triangle (face (0,1,2)) green and the second (face (1,3,2)) red. b) Now color vertex (0,0,0) and (0,3,2) red and (0,2,0) and (0,1,2) green. Adding a material \u00b6 You can also add materials through the Python API. As an example to show how you could do this, let's add a material to the triangle from exercise 4 in the last section. Materials are stored in bpy.data.material and we can make a new material: # Make material triangle_material_name = \"triangle_mat\" mat = bpy . data . materials . new ( triangle_material_name ) The nodes and the node tree are stored in the material 1 . mat . use_nodes = True nodes = mat . node_tree . nodes Before we start making nodes we remove the automatically generated nodes. nodes . clear () We will make two nodes, one Principled BSDF shader and an output node. We can make the shader by making a new node. shader = nodes . new ( type = 'ShaderNodeBsdfPrincipled' ) How a node type is called you can search up in Blender in the following way. Go to the Shading workspace and open the add menu in the Shader Editor . Now go to Shader and hover over Principled BSDF until an information pop-up appears. In the pop-up you can find how the node type is called. See Fig. 5. Figure 5: The type name of a node can be found by navigating to the Add menu and hovering over the node of your interest If you also want to organize the nodes in the Shader Editor you can place the node like this: shader . location = 0 , 300 # Location in the node window We can set the inputs of the Principled BSDF shader to a default_value. shader . inputs [ 'Base Color' ] . default_value = ( 1 , 0 , 0 , 1 ) We can now also make an output node and place it in the Shader Editor . node_output = nodes . new ( type = 'ShaderNodeOutputMaterial' ) node_output . location = 400 , 300 Links between nodes can be made using the links in the node_tree. A new link will take outputs and inputs from the nodes you want to link. links = mat . node_tree . links links . new ( shader . outputs [ 0 ], node_output . inputs [ 0 ]) Now we only need to add the material to the mesh containing the spherical disk. mesh . materials . append ( mat ) In summary, the total code for making the material is: # Make material triangle_material_name = \"triangle_mat\" mat = bpy . data . materials . new ( triangle_material_name ) mat . use_nodes = True nodes = mat . node_tree . nodes # Clear default nodes nodes . clear () shader = nodes . new ( type = 'ShaderNodeBsdfPrincipled' ) shader . location = 0 , 300 # Location in the node window shader . inputs [ 'Base Color' ] . default_value = ( 1 , 0 , 0 , 1 ) # Create an output for the shader node_output = nodes . new ( type = 'ShaderNodeOutputMaterial' ) node_output . location = 400 , 300 links = mat . node_tree . links links . new ( shader . outputs [ 'BSDF' ], node_output . inputs [ 'Surface' ]) mesh . materials . append ( mat ) Although we make minimal use of shading in this chapter, you might not be familiar with shading and materials in Blender. Here is a great introduction of how to use materials in Blender. \u21a9 \u21a9","title":"Creating geometry, colors and materials"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#creating-geometry-colors-and-materials","text":"","title":"Creating geometry, colors and materials"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#creating-an-object-with-a-mesh","text":"If we want to create a new mesh we can do this by calling the new function like this: mesh = bpy . data . meshes . new ( \"newMesh\" ) This will create the mesh but it is not linked to an object (it will not show in the Outliner ). So we make a new object and link the object to the mesh: obj = bpy . data . objects . new ( \"newObject\" , mesh ) We can actually verify this worked correctly by checking the value of obj.data : >>> obj.data bpy.data.meshes['newMesh'] If you check the Outliner in the user interface you will see both the object newObject and the mesh newMesh linked to it. Now we have an empty mesh, linked to an object. We will now construct a simple piece geometry to show how this is done in Blender. Vertices are defined by their x, y and z values like this: verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) ] Edges are defined as a tuple holding two indices pointing to two vertices in the verts list. So (0,1) refers to a line from vertex (0,0,0) (index 0 in verts ) to (0,2,0) (index 1 in verts ) in this example. We make the following edges: edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ) ] To make faces we need three or more vertices. Per face you make a tuple of three or more indices pointing to three vertices in the verts list. For example the face (0,1,2) is a face made up from the vertices (0,0,0), (0,2,0) and (0,1,2), which are at index 0, 1 and 2 in the verts list. For now lets make one face: faces = [ ( 0 , 1 , 2 ) ] We now use a function from the Python API to make a mesh from our verts, edges and faces: mesh . from_pydata ( verts , edges , faces ) Now the mesh and the object are created, but it does not yet show in the 3D viewport or the Outliner . This is because we still need to link the new object to an existing collection and in so doing to a scene. bpy . data . collections [ 0 ] . objects . link ( obj ) To summarize here is the full code to generate this geometry: import bpy # Create a new mesh ob_name = \"triangle\" mesh = bpy . data . meshes . new ( ob_name + \"_mesh\" ) # Create a new object with the mesh ob = bpy . data . objects . new ( ob_name , mesh ) # Define some geometry verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) ] edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ) ] # These are indices pointing to elements in the list verts faces = [ ( 0 , 1 , 2 ) ] # These are indices pointing to elements in the list verts # Add it to the mesh mesh . from_pydata ( verts , edges , faces ) # Link the object to the first collection bpy . data . collections [ 0 ] . objects . link ( ob ) Tips Note that in general you do not need to explicitly specify edges, as these will be generated automatically based on the faces specified. It's only when you want to have edges that are not connected to faces that you need to specify them explicitly. All objects in Blender (and object data of the same type, i.e. all meshes) are enforced to have unique names. When using the Python API this is no different. So if you create an object with bpy.data.objects.new(\"obj\", mesh) and there already is an object named \"obj\" the name of the new object will be automatically set to something else. This can become important if you generate many objects (say in a loop) but still want to be able to refer to them later by name.","title":"Creating an object with a mesh"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#exercise-3-a-filled-disk-from-scratch","text":"In the text above we created a triangle, now as an exercise let's create a spherical disk. First create a ring of vertices, then create edges and a face.","title":"(EXERCISE 3) A filled disk from scratch"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#adding-vertex-colors-to-a-mesh","text":"Vertex coloring is a way to color a mesh without using textures or uv-mapping. It works by assigning for every face that a vertex is a member of a color to that vertex. So a vertex can have different colors for each of the different faces it is in. Let's say we have a mesh, named \"triangle_mesh\": mesh = bpy.data.meshes['triangle_mesh'] , the vertex colors for this mesh will be stored in mesh.vertex_colors . If the mesh does not have a vertex color layer yet, you can make a new one with: mesh.vertex_colors.new(name='vert_colors') . Now we have a color layer to work with: color_layer = mesh.vertex_colors['vert_colors'] .","title":"Adding vertex colors to a mesh"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#exercise-4-making-triangles-and-make-a-vertex-color-layer","text":"Let's take the triangle we made in section 4.1, but let's add another triangle to it, attached to the first. The code would look like this: import bpy # Create a new mesh ob_name = \"triangle\" mesh = bpy . data . meshes . new ( ob_name + \"_mesh\" ) # Create a new object with the mesh ob = bpy . data . objects . new ( ob_name , mesh ) # Define some geometry verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) , ( 0 , 3 , 2 ) ] edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ), ( 1 , 3 ), ( 3 , 2 ) ] # These are indices pointing to elements in the list verts faces = [ ( 0 , 1 , 2 ), ( 1 , 3 , 2 ) ] # These are indices pointing to elements in the list verts # Add it to the mesh mesh . from_pydata ( verts , edges , faces ) # Link the object to the first collection bpy . data . collections [ 0 ] . objects . link ( ob ) Now make a vertex color layer for your triangles. Then inspect how many entries are in color_layer = mesh.vertex_colors['vert_colors'] . Why are they the same or different from the total number of vertices in the mesh? In exercise 4 we saw that color_layer.data contains six entries while we only have four vertices in the mesh. This is because a vertex has a color for every face it is in. So vertex (0,2,0) and (0,1,2) are each in two faces, while the other two vertices are only in one face. So the former vertices have two entries in the color layer, one for each face they are in, the latter only one color entry. The link between vertex indices in a mesh and those in the vertex color layer can be deduced from the polygons in mesh.polygons . Let's take one polygon from the triangles, lets say the first ( poly = mesh.polygons[0] ). Now, for one vertex in the polygon, poly.vertices gives you the index of the vertex in the mesh and poly.loop_indices gives you the index of the vertex in color_layer.data . See Fig. 3. Figure 3: Sketch of the two triangles from Exercise 4. For the vertices are shown the coordinates (in black italic (x, x, x)), indices of the vertex in its mesh (green, outside of the face) and the indices in the loop_indices of the polygon (red, italic and inside the faces.) Once you have set colors for your vertices you need to set up the shader of the object 1 . For this go to the Shading workspace. Create a Vertex Color node and connect it to a Principled BSDF (connect Color output to Base Color input). And then make a Material Output and connect the Principled BSDF to the Surface input of the Material Output . See Fig. 4. Figure 4: Shader setup for vertex colors","title":"(EXERCISE 4) Making triangles and make a vertex color layer"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#exercise-5-coloring-your-triangles","text":"Let's take the two connected triangles of exercise 4. We will color them in two different ways, using vertex coloring and Python scripting. a) Make the first triangle (face (0,1,2)) green and the second (face (1,3,2)) red. b) Now color vertex (0,0,0) and (0,3,2) red and (0,2,0) and (0,1,2) green.","title":"Exercise 5: coloring your triangles"},{"location":"modules/advanced/python_scripting/3_geometry_colors_and_materials/#adding-a-material","text":"You can also add materials through the Python API. As an example to show how you could do this, let's add a material to the triangle from exercise 4 in the last section. Materials are stored in bpy.data.material and we can make a new material: # Make material triangle_material_name = \"triangle_mat\" mat = bpy . data . materials . new ( triangle_material_name ) The nodes and the node tree are stored in the material 1 . mat . use_nodes = True nodes = mat . node_tree . nodes Before we start making nodes we remove the automatically generated nodes. nodes . clear () We will make two nodes, one Principled BSDF shader and an output node. We can make the shader by making a new node. shader = nodes . new ( type = 'ShaderNodeBsdfPrincipled' ) How a node type is called you can search up in Blender in the following way. Go to the Shading workspace and open the add menu in the Shader Editor . Now go to Shader and hover over Principled BSDF until an information pop-up appears. In the pop-up you can find how the node type is called. See Fig. 5. Figure 5: The type name of a node can be found by navigating to the Add menu and hovering over the node of your interest If you also want to organize the nodes in the Shader Editor you can place the node like this: shader . location = 0 , 300 # Location in the node window We can set the inputs of the Principled BSDF shader to a default_value. shader . inputs [ 'Base Color' ] . default_value = ( 1 , 0 , 0 , 1 ) We can now also make an output node and place it in the Shader Editor . node_output = nodes . new ( type = 'ShaderNodeOutputMaterial' ) node_output . location = 400 , 300 Links between nodes can be made using the links in the node_tree. A new link will take outputs and inputs from the nodes you want to link. links = mat . node_tree . links links . new ( shader . outputs [ 0 ], node_output . inputs [ 0 ]) Now we only need to add the material to the mesh containing the spherical disk. mesh . materials . append ( mat ) In summary, the total code for making the material is: # Make material triangle_material_name = \"triangle_mat\" mat = bpy . data . materials . new ( triangle_material_name ) mat . use_nodes = True nodes = mat . node_tree . nodes # Clear default nodes nodes . clear () shader = nodes . new ( type = 'ShaderNodeBsdfPrincipled' ) shader . location = 0 , 300 # Location in the node window shader . inputs [ 'Base Color' ] . default_value = ( 1 , 0 , 0 , 1 ) # Create an output for the shader node_output = nodes . new ( type = 'ShaderNodeOutputMaterial' ) node_output . location = 400 , 300 links = mat . node_tree . links links . new ( shader . outputs [ 'BSDF' ], node_output . inputs [ 'Surface' ]) mesh . materials . append ( mat ) Although we make minimal use of shading in this chapter, you might not be familiar with shading and materials in Blender. Here is a great introduction of how to use materials in Blender. \u21a9 \u21a9","title":"Adding a material"},{"location":"modules/advanced/python_scripting/4_volumetric_data/","text":"Visualizing volumetric data \u00b6 In this section we will show a simple example of how to visualize custom volumetric data with Blender and Python. The current support in Blender for volumetric data is directly tied to the OpenVDB file format. In fact, the only way to create a volume object is to load an OpenVDB file. This is a file format and data structure that originated from the motion-picture industry, where it is often used to show clouds, smoke and fire in computer graphics like movies and games. Here's an example of such a volumetric rendering: Gasoline explosion. Free example from Embergen. The reason OpenVDB is used for many uses of volumetric data in computer graphics is that is allows sparse volumes to be stored efficiently, while also providing easy querying of the data, for example during rendering. OpenVDB is also a bit more than just a file format, as the OpenVDB library also supports more advanced operations. From the OpenVDB website: OpenVDB is an Academy Award-winning C++ library comprising a hierarchical data structure and a suite of tools for the efficient manipulation of sparse, time-varying, volumetric data discretized on three-dimensional grids. It is based on VDB, which was developed by Ken Museth at DreamWorks Animation, and it offers an effectively infinite 3D index space, compact storage, fast data access, and a collection of algorithms specifically optimized for the data structure for common tasks such as filtering, CSG, compositing, numerical simulation, sampling, and voxelization from other geometric representations. For more documentation on OpenVDB see here . Some example OpenVDB files can be found here , under Sample Models. Example \u00b6 OpenVDB models are mostly generated with specialized software like Houdini and Embergen . Volumetric data in general is also used for scientific visualizations, for example in ParaView , but support for OpenVDB is still lacking somewhat. In this section we will explain how OpenVDB files can be made from scratch. For example for when you have you own volumetric data in your own data format and you want to visualize or animate this in Blender. To convert your data to a OpenVDB format we will use the Python package pyopenvdb . First we will create data in Python and write it to a OpenVDB file using OpenVDB and the Python package pyopenvdb . Installation of pyopenvdb \u00b6 Installing the Python module to access the openVDB functionality can be very easy or more difficult depending on your operating system. See the installation instructions on the pyopenvdb website . Tip If you cannot get it to work that way, we made a simple Docker container you can use to run it, see here for the github repository. Making a VDB file with pyopenvdb \u00b6 Let us make a simple volumetric cube using pyopenvdb . To start we first load pyopenvdb and numpy: import numpy as np import pyopenvdb as vdb And we make a zero filled array of size 400x400x400: dimension = 400 array = np.zeros((dimension, dimension, dimension)) We then fill a cube sized portion of the array with the value 1: for i in range(dimension): for j in range(dimension): for k in range(dimension): if i < 200 and i >=100 and \\ j < 200 and j >=100 and \\ k < 200 and k >=100: array[i,j,k] = 1.0 Now we come to the openvdb part, where we first need to make a grid. In this case we make a float grid (there are more grids and besides a float grid BoolGrid and Vec3SGrid are also standardly available). grid = vdb.FloatGrid() We now copy the values in the array into the grid: grid.copyFromArray(array) The last important thing we need to do before we save it to file is to name the grid. You will use this name later when using the grid in Blender. grid.name = \"cube\" The last thing left to do is to save the grid to file: vdb.write('cube.vdb', grids=[grid]) Loading a VDB file into Blender \u00b6 Open a new Blender file and if its there, remove the starting cube. In the 3D viewport choose Add => Volume => Import OpenVDB or use the shortcut Shift-A . Locate the cube.vdb file we just made through the script. You will most likely not see anything yet, so scale the cube down using the shortcut s until you can see the outline of the cube. Now if you change the Viewport shading in the top right of the 3D viewport to Render preview (see Fig. 1, #1), you will not see anything beside the outline since we still need to make a shader for the model. Figure 1: definition of coordinates Change to the Shading workspace (see Fig. 1, #2) and in the Shader editor click on new to make a new material (see Fig. 1, #3). You see Blender makes a Principled volume and Material output node. To make the cube appear we need to change one thing and for this we need to know the name of the grid in the VDB file. From the Python script we know this is cube , but you can also figure out the grids and their names in a VDB file from within Blender. In the Properties panel go to Object Data Properties tab (see Fig. 1, #4). Here under Grids you can see the names of the grids in the VDB file. For now, in the Principled Volume node, add the name of the grid ( cube ) into the field next to Density Attribute (see Fig. 1, #5). This tells the node to use the values in the grid for the scattering density of the voxels. (EXERCISE) Coloring the cube \u00b6 Now make a cube similar to the one we just made, but color it blue on one side and red on the other (See Fig. 2). First alter the Python script to include a second grid in the VDB file. In this second grid set one side of the cube to value 1 and the other to zero. Use an Attribute node (do not forget to add the grid name to the Name: field in the attribute node) to feed the second grid into a ColorRamp node (and choose the colors you want). Now feed the ColorRamp into the Color field of the Principled Volume . Do not forget to set the original grid in the Density Attribute . Does it come out right? Maybe you need to play a bit with settings, like set the Density to 1. You might also need to play with the lighting. If you still have the original light in your scene, try increasing its Power and location. Now also see how it looks in Cycles compared to Eevee . Figure 2: Colored cube","title":"Visualizing volumetric data"},{"location":"modules/advanced/python_scripting/4_volumetric_data/#visualizing-volumetric-data","text":"In this section we will show a simple example of how to visualize custom volumetric data with Blender and Python. The current support in Blender for volumetric data is directly tied to the OpenVDB file format. In fact, the only way to create a volume object is to load an OpenVDB file. This is a file format and data structure that originated from the motion-picture industry, where it is often used to show clouds, smoke and fire in computer graphics like movies and games. Here's an example of such a volumetric rendering: Gasoline explosion. Free example from Embergen. The reason OpenVDB is used for many uses of volumetric data in computer graphics is that is allows sparse volumes to be stored efficiently, while also providing easy querying of the data, for example during rendering. OpenVDB is also a bit more than just a file format, as the OpenVDB library also supports more advanced operations. From the OpenVDB website: OpenVDB is an Academy Award-winning C++ library comprising a hierarchical data structure and a suite of tools for the efficient manipulation of sparse, time-varying, volumetric data discretized on three-dimensional grids. It is based on VDB, which was developed by Ken Museth at DreamWorks Animation, and it offers an effectively infinite 3D index space, compact storage, fast data access, and a collection of algorithms specifically optimized for the data structure for common tasks such as filtering, CSG, compositing, numerical simulation, sampling, and voxelization from other geometric representations. For more documentation on OpenVDB see here . Some example OpenVDB files can be found here , under Sample Models.","title":"Visualizing volumetric data"},{"location":"modules/advanced/python_scripting/4_volumetric_data/#example","text":"OpenVDB models are mostly generated with specialized software like Houdini and Embergen . Volumetric data in general is also used for scientific visualizations, for example in ParaView , but support for OpenVDB is still lacking somewhat. In this section we will explain how OpenVDB files can be made from scratch. For example for when you have you own volumetric data in your own data format and you want to visualize or animate this in Blender. To convert your data to a OpenVDB format we will use the Python package pyopenvdb . First we will create data in Python and write it to a OpenVDB file using OpenVDB and the Python package pyopenvdb .","title":"Example"},{"location":"modules/advanced/python_scripting/4_volumetric_data/#installation-of-pyopenvdb","text":"Installing the Python module to access the openVDB functionality can be very easy or more difficult depending on your operating system. See the installation instructions on the pyopenvdb website . Tip If you cannot get it to work that way, we made a simple Docker container you can use to run it, see here for the github repository.","title":"Installation of pyopenvdb"},{"location":"modules/advanced/python_scripting/4_volumetric_data/#making-a-vdb-file-with-pyopenvdb","text":"Let us make a simple volumetric cube using pyopenvdb . To start we first load pyopenvdb and numpy: import numpy as np import pyopenvdb as vdb And we make a zero filled array of size 400x400x400: dimension = 400 array = np.zeros((dimension, dimension, dimension)) We then fill a cube sized portion of the array with the value 1: for i in range(dimension): for j in range(dimension): for k in range(dimension): if i < 200 and i >=100 and \\ j < 200 and j >=100 and \\ k < 200 and k >=100: array[i,j,k] = 1.0 Now we come to the openvdb part, where we first need to make a grid. In this case we make a float grid (there are more grids and besides a float grid BoolGrid and Vec3SGrid are also standardly available). grid = vdb.FloatGrid() We now copy the values in the array into the grid: grid.copyFromArray(array) The last important thing we need to do before we save it to file is to name the grid. You will use this name later when using the grid in Blender. grid.name = \"cube\" The last thing left to do is to save the grid to file: vdb.write('cube.vdb', grids=[grid])","title":"Making a VDB file with pyopenvdb"},{"location":"modules/advanced/python_scripting/4_volumetric_data/#loading-a-vdb-file-into-blender","text":"Open a new Blender file and if its there, remove the starting cube. In the 3D viewport choose Add => Volume => Import OpenVDB or use the shortcut Shift-A . Locate the cube.vdb file we just made through the script. You will most likely not see anything yet, so scale the cube down using the shortcut s until you can see the outline of the cube. Now if you change the Viewport shading in the top right of the 3D viewport to Render preview (see Fig. 1, #1), you will not see anything beside the outline since we still need to make a shader for the model. Figure 1: definition of coordinates Change to the Shading workspace (see Fig. 1, #2) and in the Shader editor click on new to make a new material (see Fig. 1, #3). You see Blender makes a Principled volume and Material output node. To make the cube appear we need to change one thing and for this we need to know the name of the grid in the VDB file. From the Python script we know this is cube , but you can also figure out the grids and their names in a VDB file from within Blender. In the Properties panel go to Object Data Properties tab (see Fig. 1, #4). Here under Grids you can see the names of the grids in the VDB file. For now, in the Principled Volume node, add the name of the grid ( cube ) into the field next to Density Attribute (see Fig. 1, #5). This tells the node to use the values in the grid for the scattering density of the voxels.","title":"Loading a VDB file into Blender"},{"location":"modules/advanced/python_scripting/4_volumetric_data/#exercise-coloring-the-cube","text":"Now make a cube similar to the one we just made, but color it blue on one side and red on the other (See Fig. 2). First alter the Python script to include a second grid in the VDB file. In this second grid set one side of the cube to value 1 and the other to zero. Use an Attribute node (do not forget to add the grid name to the Name: field in the attribute node) to feed the second grid into a ColorRamp node (and choose the colors you want). Now feed the ColorRamp into the Color field of the Principled Volume . Do not forget to set the original grid in the Density Attribute . Does it come out right? Maybe you need to play a bit with settings, like set the Density to 1. You might also need to play with the lighting. If you still have the original light in your scene, try increasing its Power and location. Now also see how it looks in Cycles compared to Eevee . Figure 2: Colored cube","title":"(EXERCISE) Coloring the cube"},{"location":"modules/advanced/python_scripting/api_summary/","text":"The Blender API in detail \u00b6 Introduction \u00b6 The Blender Python API mostly consists of a thin layer on top of the underlying Blender C/C++ data structures and methods. The underlying C/C++ code is used to automatically generate the Python API during the build process of the Blender executable, which means the API is always up-to-date with respect to the underlying code. The API isn't the only part of Blender that uses Python. Large parts of the user interface, the import/export scripts and all addons are written in Python. It is therefore relatively easy to extend Blender with, say, new UI dialogs or an importer. This is one of the strengths of the Blender Python API. Warning Since the API provides access to Blender internals at a very low level you can screw up the Blender state quite easily, causing unexpected behaviour, data corruption or even crashes. In the worst case you can end up with a file that will no longer load in Blender at all, although that's rare. So when working with Python scripting save your session to file often, preferably in a number of incremental versions. In cases where you suspect Blender's internal state has been corrupted you can save the current file, restart Blender and then reopen the file to help ensure you start from a known-good state. API modules \u00b6 The Blender Python API is comprised of several modules, with bpy being the main one. But there's also useful routines in mathutils , bmesh and a few others. Tip The API documentation on these modules can be easily accessed from within Blender using Help > Python API Reference . By default none of the API modules, not even bpy , is loaded in the environment where a script file runs, so you need to import the ones you need explicitly. The Python Console does import quite a few things by defaults and also sets some useful variables, like C to access bpy.context and D to access bpy.data with less typing: PYTHON INTERACTIVE CONSOLE 3.9 . 4 ( default , Apr 20 2021 , 15 : 51 : 38 ) [ GCC 10.2 . 0 ] Builtin Modules : bpy , bpy . data , bpy . ops , bpy . props , bpy . types , bpy . context , bpy . utils , bgl , blf , mathutils Convenience Imports : from mathutils import * ; from math import * Convenience Variables : C = bpy . context , D = bpy . data >>> >>> D . objects . values () [ bpy . data . objects [ 'Camera' ], bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Light' ]] Developer settings \u00b6 When developing Python scripts in Blender it can be useful to enable a few extra settings: The Python Tooltips under Interface > Display > Python Tooltips . When enabled a tooltip will show the corresponding Python command or a path to the data for a UI element. The Developer Extras under Interface > Display > Developer Extras . When enabled this provides multiple things: The 3D viewport overlay for a mesh in edit mode will now have an extra setting Indices to show the low-level indices of selected vertices/edges/faces. This can be very useful when debugging Python code that works on mesh geometry. The right-click menu for a UI item, such as a button or menu entry, will now also contain an entry called Online Python Reference linking to the relevant Python documentation page. It will enable Operator Search , which will add entries to the F3 search menu for operators. These will be listed after the regular menu entries in the search results. It adds a new menu option Help > Operator Cheat Sheet that will create a new text area called OperatorList.txt , which contains all available operators (see below ) and their default parameters. This list can give you a quick overview of the available operators, with the API documentation providing all the details. As mentioned in the video in the introductory chapter the Info area can be useful if you want to inspect which Python calls Blender performs for certain operations. This certainly will not provide all the details in all cases, but can give some insight. You can either switch to the default Scripting workspace to check the Info area, or use the normal UI area operations to add/change an area to an Info area. Data-blocks \u00b6 The different types of data in Blender are stored in data-blocks . For example, there's Mesh, Object, Texture and Shader data-blocks, but there's quite a few more . One of the clever bits in the way Blender is programmed is that data-blocks contain enough information about their content (i.e. meta-data) to make them readable by both older and newer versions of Blender than the one they were written with. This meta-data system also allows the Python API for accessing those data-blocks to get generated without much manual development. Data-blocks are available through Python per type under bpy.data , e.g. bpy.data.objects or bpy.data.meshes . The type of a data-block is the corresponding class under bpy.types , e.g. >>> type ( bpy . data . objects [ 'Cube' ]) < class ' bpy_types . Object '> >>> bpy . types . Object < class ' bpy_types . Object '> Each type of data-block has its own set of attributes and methods, particular to that type. Learning the Blender Python API involves getting to know the details of the data-block types you want to work with and how they interact. Blender keeps track of which data-blocks are no longer being referenced to decide when a data-block does not need to be saved (so-called garbage collection). Usually you don't need to explicitly interact with this system, but it is good to be aware that it is there, see this section below for more details. Unique data-block names \u00b6 Per type of data all the data-blocks need to have a unique name . This is enforced automatically by Blender when a data-block is created by appending a number to make the name unique. For example: >>> bpy . data . meshes . new ( 'my object' ) bpy . data . meshes [ 'my object' ] >>> bpy . data . meshes . new ( 'my object' ) bpy . data . meshes [ 'my object.001' ] >>> bpy . data . meshes . new ( 'my object' ) bpy . data . meshes [ 'my object.002' ] This usually isn't an issue, but just something to be aware of when working with referencing objects by name, as the name of a data-block you created might actually be something different than you expect. Objects and object data \u00b6 When we use the word Object in these pages we mean one of the object types that can be present in a 3D scene, e.g. camera, mesh, light, etc. Such objects are of type bpy.types.Object and all have general properties related to their presence in the 3D scene. For example, their name, 3D transformation, visibility flags, parent, etc. But a Light object needs to specify different properties than, say, a Camera object and these per-type properties are stored as object data . The object data can be accessed through the data attribute of an Object: # Both lights and cameras are Objects >>> type ( bpy . data . objects [ 'Light' ]) < class ' bpy_types . Object '> >>> type ( bpy . data . objects [ 'Camera' ]) < class ' bpy_types . Object '> # But their object data are of different types >>> type ( bpy . data . objects [ 'Camera' ] . data ) < class ' bpy . types . Camera '> >>> type ( bpy . data . objects [ 'Light' ] . data ) < class ' bpy . types . PointLight '> # And have different attributes, relevant to that type >>> dir ( bpy . data . objects [ 'Camera' ] . data ) [ ... , 'angle' , ... , 'clip_start' , ... , 'dof' , ... ] >>> dir ( bpy . data . objects [ 'Light' ] . data ) [ ... , 'color' , ... , 'distance' , 'energy' , ... , 'falloff_type' , ... ] Sometimes you want to iterate over all objects in a scene, but only perform some operation on a specific type of object. You can use the type attribute for checking an object's type: >>> bpy . data . objects [ 'Camera' ] . type 'CAMERA' >>> bpy . data . objects [ 'Light' ] . type 'LIGHT' Native Blender data structures \u00b6 When working with the Python API will you frequently use internal Blender types that appear similar to regular Python types, like lists and dictionaries. However, the Blender types are not real native Python types and behave differently in certain aspects. For example, the different collections of scene elements (such as objects or meshes) that are available under bpy.data are of type bpy_prop_collection . This type is a combination of a Python list and a dictionary, sometimes called an ordered dictionary, as it allows indexing by both array position and key: >>> type ( bpy . data . objects ) < class ' bpy_prop_collection '> # Some of its methods match those of native Python data types >>> dir ( bpy . data . objects ) [ '__bool__' , '__contains__' , '__delattr__' , '__delitem__' , '__doc__' , '__doc__' , '__getattribute__' , '__getitem__' , '__iter__' , '__len__' , '__module__' , '__setattr__' , '__setitem__' , '__slots__' , 'bl_rna' , 'find' , 'foreach_get' , 'foreach_set' , 'get' , 'items' , 'keys' , 'new' , 'remove' , 'rna_type' , 'tag' , 'values' ] # Index by position >>> bpy . data . objects [ 0 ] bpy . data . objects [ 'Camera' ] # Index by key >>> bpy . data . objects [ 'Camera' ] bpy . data . objects [ 'Camera' ] # (key, value) pairs >>> bpy . data . objects . items () [( 'Camera' , bpy . data . objects [ 'Camera' ]), ( 'Cube' , bpy . data . objects [ 'Cube' ]), ( 'Light' , bpy . data . objects [ 'Light' ])] Note that the position of an item in the collection, and hence its index, can change during a Blender session. Inspecting values \u00b6 One of the more annoying aspects when working in the Blender Python Console inspecting these kinds of values is that the elements in a bpy_prop_collection (or other Blender types) aren't printed by default, this in contrast to a regular Python dictionary. You need to, for example, cast to a list or call its values() method: # Regular Python dict, prints both keys and values >>> d = dict ( a = 1 , b = 2 , c = 3 ) >>> d { 'a' : 1 , 'b' : 2 , 'c' : 3 } # No items printed >>> bpy . data . objects < bpy_collection [ 3 ], BlendDataObjects > # values() returns a list, so gets printed in detail >>> type ( bpy . data . objects . values ()) < class ' list '> >>> bpy . data . objects . values () [ bpy . data . objects [ 'Camera' ], bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Light' ]] # Difference in list() result: >>> list ( d ) [ 'a' , 'b' , 'c' ] # Returns dict *keys* >>> list ( bpy . data . objects ) [ bpy . data . objects [ 'Camera' ], bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Light' ]] # Returns collection *values* The choice for not printing the values inside a bpy_prop_collection is (most likely) that in many cases the collection will contain large numbers of objects, so printing them all would not be too useful, or might even make the UI non-responsive for a short time. Data organization \u00b6 In certain cases Blender uses a more elaborate data structure in cases where you might except low-level values, like lists. For example, the set of vertices that make up a mesh are only accessible as a collection of MeshVertex objects: >>> m bpy . data . meshes [ 'Cube' ] >>> type ( m . vertices ) < class ' bpy_prop_collection '> >>> len ( m . vertices ) 8 >>> m . vertices [ 0 ] bpy . data . meshes [ 'Cube' ] . vertices [ 0 ] >>> type ( m . vertices [ 0 ]) < class ' bpy . types . MeshVertex '> >>> dir ( m . vertices [ 0 ]) [ '__doc__' , '__module__' , '__slots__' , 'bevel_weight' , 'bl_rna' , 'co' , 'groups' , 'hide' , 'index' , 'normal' , 'rna_type' , 'select' , 'undeformed_co' ] # Vertex coordinate (object space) >>> m . vertices [ 0 ] . co Vector (( 1.0 , 1.0 , 1.0 )) # Vertex normal >>> m . vertices [ 0 ] . normal Vector (( 0.5773491859436035 , 0.5773491859436035 , 0.5773491859436035 )) The reason for this is that there's several types of data associated with a single vertex, which are all centralized in a MeshVertex object. In short, Blender uses a so-called array-of-structs design. The alternative design choice would have been to have separate arrays for vertex coordinates, vertex normals, etc (which would be a struct-of-arrays design). Vertices and matrices \u00b6 The example above also shows that even a vertex coordinate is not accessed as a low-level Python data type, like a tuple, but by the Vector type (which is in the mathutils module). This has the advantage of providing many useful methods for operating on vector values: >>> v = m . vertices [ 0 ] . normal >>> v Vector (( 0.5773491859436035 , 0.5773491859436035 , 0.5773491859436035 )) >>> v . length 0.999998137353116 # Return a new vector that's orthogonal >>> w = v . orthogonal () >>> w Vector (( 0.5773491859436035 , 0.5773491859436035 , - 1.154698371887207 )) # Dot product (should be zero as v and w are orthogonal) >>> v . dot ( w ) 0.0 # Note: v*w is element-wise product, not dot product! >>> v * w Vector (( 0.3333320915699005 , 0.3333320915699005 , - 0.666664183139801 )) # Cross product between two vectors >>> v . cross ( w ) Vector (( - 0.9999963045120239 , 0.9999963045120239 , 0.0 )) # Swizzling (returning vector elements in a different order) >>> w Vector (( 0.5773491859436035 , 0.5773491859436035 , - 1.154698371887207 )) >>> w . zxy Vector (( - 1.154698371887207 , 0.5773491859436035 , 0.5773491859436035 )) The builtin mathutils module contains many useful data types and methods for working with 3D data, including vectors and matrices, but also different methods for working with transformations (like quaternion) and colors spaces. # Transformation matrix for an object with uniform scale 2 and # translation in Z of 3. These values will match with the Transform UI area >>> o bpy . data . objects [ 'Cube' ] >>> o . matrix_world Matrix ((( 2.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 2.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 2.0 , 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # Create a rotation matrix >>> m = Matrix . Rotation ( radians ( 90.0 ), 4 , 'X' ) >>> m Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 7.549790126404332e-08 , - 1.0 , 0.0 ), ( 0.0 , 1.0 , 7.549790126404332e-08 , 0.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) >>> v = Vector (( 1 , 2 , 3 )) # Transform the vector using the matrix. Note the different outcomes # depending on the multiplication order. >>> m @ v Vector (( 1.0 , - 2.999999761581421 , 2.000000238418579 )) >>> v @ m Vector (( 1.0 , 3.000000238418579 , - 1.999999761581421 )) # Also, a 3-vector is assumed to have a fourth element equal to *one* when # multiplying with a matrix: >>> m = Matrix . Translation (( 4 , 5 , 6 )) >>> m Matrix ((( 1.0 , 0.0 , 0.0 , 4.0 ), ( 0.0 , 1.0 , 0.0 , 5.0 ), ( 0.0 , 0.0 , 1.0 , 6.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) >>> m @ Vector (( 1 , 2 , 3 )) Vector (( 5.0 , 7.0 , 9.0 )) >>> m @ Vector (( 1 , 2 , 3 , 0 )) Vector (( 1.0 , 2.0 , 3.0 , 0.0 )) Selections \u00b6 In a lot of cases you want to operate on a set of objects. You can access (read only) the current selection with bpy.context.selected_objects : >>> bpy . context . selected_objects [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Plane' ]] Changing the current selection can be done in several ways. Control over selection state per object can be controlled with the select_get() and select_set() methods: >>> bpy . context . selected_objects [] >>> bpy . data . objects [ 'Camera' ] . select_get () False >>> bpy . data . objects [ 'Camera' ] . select_set ( True ) >>> bpy . context . selected_objects [ bpy . data . objects [ 'Camera' ]] The full selection set can also be changed: # Select all visible objects >>> bpy . ops . object . select_all ( action = 'SELECT' ) # Deselect all objects >>> bpy . ops . object . select_all ( action = 'DESELECT' ) # Toggle the selection state for each object >>> bpy . ops . object . select_all ( action = 'TOGGLE' ) Note that the default mode for bpy.ops.object.select_all() when not specified is TOGGLE . Also note that the selection methods above operate only on objects that are currently visible objects in the scene (in terms of the outliner eye icon), just like for the selection hotkeys (like A ) in the 3D viewport. Often used values and operations \u00b6 Scene \u00b6 Current scene: bpy.context.scene (read-only) Objects \u00b6 Active object: bpy.context.active_object (read-only) Selected objects: bpy.context.selected_objects (read-only) Delete selected objects: bpy.ops.object.delete() Camera \u00b6 Active camera object: Scene.camera (this is the camera object , not camera object data ) Type: Camera.type (\"PERSP\", \"ORTHO\", ...) Focal length: Camera.lens (in mm) Clipping distances: Camera.clip_start , Camera.clip_end Render settings \u00b6 Image resolution: Width: Scene.render.settings.resolution_x Height: Scene.render.settings.resolution_y Percentage: Scene.render.settings.resolution_percentage Output file: Scene.render.filepath Image output type: Scene.render.image_settings.file_format (\"PNG\", \"JPEG\", ...) Number of samples per pixel (Cycles): Scene.cycles.samples Animation \u00b6 Current frame Scene.frame_current Frame range: Scene.frame_start , Scene.frame_end Frame rate: Scene.render.fps Object transformations \u00b6 The matrix_world attribute of an Object contains the object-to-world transform that places the object in the 3D scene: >>> o = bpy . context . active_object >>> o bpy . data . objects [ 'Cube' ] >>> o . matrix_world Matrix ((( 1.3376139402389526 , 0.0 , 0.0 , 0.3065159320831299 ), ( 0.0 , 1.3376139402389526 , 0.0 , 2.2441697120666504 ), ( 0.0 , 0.0 , 1.3376139402389526 , 1.2577730417251587 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) Comparing this matrix with the values set in the Transform panel, you can see the location is stored in the right-most column of the matrix and the scaling along the diagonal. If there was a rotation set on this object some of these values would not be as recognizable anymore. The location, rotation and scale values can also be inspected and set separately: >>> o . location Vector (( 0.3065159320831299 , 2.2441697120666504 , 1.2577730417251587 )) >>> o . rotation_euler Euler (( 0.0 , 0.0 , 0.0 ), 'XYZ' ) >>> o . scale Vector (( 1.3376139402389526 , 1.3376139402389526 , 1.3376139402389526 )) >>> o . location = ( 1 , 2 , 3 ) # Needs value in radians >>> o . rotation_euler . x = radians ( 45 ) >>> o . scale = ( 2 , 1 , 1 ) >>> o . matrix_world Matrix ((( 2.0 , 0.0 , 0.0 , 1.0 ), ( 0.0 , 0.7071067690849304 , - 0.7071067690849304 , 2.0 ), ( 0.0 , 0.7071067690849304 , 0.7071067690849304 , 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) See the section on parenting below for some subtle effects on transformations in cases object parenting is used. Geometry coordinates \u00b6 Mesh geometry in Blender stores vertex coordinates (and other geometric information) in object-space coordinates. But a mesh (or object in general) will usually get transformed to a specific position, scaling and orientation in the scene. As described above the net transform from object-space to world-space coordinates, also called the object-to-world transform, is available through matrix_world . In cases where you need to have access to geometric data in world-space , say vertex coordinates, you need to apply the matrix_world transform manually. For example, given the cube transformed as shown above, with vertex 7 selected (visible bottom-left in the image below): >>> o bpy . data . objects [ 'Cube' ] >>> m = o . data >>> o . matrix_world Matrix ((( 1.3376139402389526 , 0.0 , 0.0 , 0.3065159320831299 ), ( 0.0 , 1.3376139402389526 , 0.0 , 2.2441697120666504 ), ( 0.0 , 0.0 , 1.3376139402389526 , 1.2577730417251587 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # The object-space coordinate of this vertex >>> m . vertices [ 7 ] . co Vector (( - 1.0 , - 1.0 , - 1.0 )) # The world-space coordinate of this vertex, which matches # what the Transform UI shows. Note the Global display mode # select in the UI, if we select Local if will show (-1, -1, -1). >>> o . matrix_world @ m . vertices [ 7 ] . co Vector (( - 1.0310980081558228 , 0.9065557718276978 , - 0.07984089851379395 )) API quirks \u00b6 Working with the Blender Python API has some peculiarities compared to your average Python scripting. These have to do with the way the API is structured, but also how it interacts with the Blender internals. The API manual contains a lengthy page on some gotchas, but here we list some of the common ones. Object modes \u00b6 An object is always in one of several modes. These modes are the same ones you work with in the UI: Object mode, Edit mode, etc. The current mode for an object can be retrieved through the mode property: >>> o = bpy . data . objects [ 'Cube' ] >>> o . mode 'OBJECT' # <enter edit mode with TAB> >>> o . mode 'EDIT' Depending on the current mode of a mesh object certain data might not be up-to-date or even unavailable when accessing it through the Python API , this is especially true when an object is in Edit Mode. This is because the edit mode uses its own copy of the data to let you edit, which is synced with the underlying mesh data when going in and out of edit mode. See here for the relevant section in the API docs. An example continuing with the Cube mesh above: >>> o . mode 'OBJECT' >>> m = o . data >>> m bpy . data . meshes [ 'Cube' ] # Check UV map data >>> len ( m . uv_layers [ 0 ] . data ) 24 # <enter edit mode with TAB> >>> o . mode 'EDIT' # UV map data now empty... >>> len ( m . uv_layers [ 0 ] . data ) 0 In most cases when working on low-level data such as mesh geometry you want the object to be in object mode (or use the bmesh module when you need the object be in edit mode). It's usually a good idea to add a check at the top of your script to verify the current mode is what you expect: o = bpy . context . active_object if o . mode != 'OBJECT' : raise ValueError ( 'Active object needs to be in object mode!' ) There are alternatives for still allowing a mesh to be in edit-mode when accessing its data from a script, see the API docs for details. Interrupting (long-running) scripts \u00b6 During script development you might get in a situation where your code is stuck in a loop, or takes much longer than you like. Interrupting a running script can usually be done by pressing Ctrl-C in the terminal console window : >>> while True : ... pass ... # Uh oh, execution stuck in a loop and the UI will now have become unresponsive # Pressing Ctrl-C in the terminal console window interrupts script execution, # as it raises a KeyboardInterrupt Traceback ( most recent call last ): File \"<blender_console>\" , line 2 , in < module > KeyboardInterrupt Interaction with the Undo system \u00b6 When you undo certain operations Blender might re-create certain data, which might cause existing references to the original data to become invalid. This can be especially noticeable when working interactively in the Python Console. For example, with a cube object as active object in the 3D viewport: # The Cube is the active object >>> bpy . context . active_object bpy . data . objects [ 'Cube' ] # Save a reference to it >>> o = bpy . context . active_object # <Grab the object in the 3D viewport and move it somewhere else> # Object reference still valid >>> o bpy . data . objects [ 'Cube' ] # <Undo the object translation in the 3D viewport> # Object reference has now become invalid >>> o < bpy_struct , Object invalid > # Reason: object referenced under name 'Cube' has changed >>> bpy . data . objects [ 'Cube' ] == o False >>> id ( o ) 140543077302976 >>> id ( bpy . data . objects [ 'Cube' ]) 140543077308608 # Will need to reacquire active object, or consistently use bpy.data.objects['Cube'] >>> o = bpy . context . active_object >>> o bpy . data . objects [ 'Cube' ] Operators \u00b6 A special class of important API routines are the so-called operators . These are usually higher-level operations, such as adding a new cube mesh, deleting the current set of selected objects or running a file importer. As noted above many parts of the Blender UI are set up with Python scripts and in a lot of cases the operations you perform in the UI through menu actions or shortcut keys will simply call the relevant operator from Python to do the actual work. The Info area will show most operators as they get execute, but you can also check when the Python Tooltips are enabled (see above ) what API call is made for a certain UI element. For example, adding a plane mesh through the Add menu will call the operator bpy.ops.mesh.primitive_plane_add() , as the tooltip shows: You can simply call the operator directly from Python to add a plane in exactly the same way as with the menu option: >>> bpy . data . objects . values () [] >>> bpy . ops . mesh . primitive_plane_add () { 'FINISHED' } # A plane mesh is now added to the scene >>> bpy . data . objects . values () [ bpy . data . objects [ 'Plane' ]] Many of the operators take parameters, to influence the results. For example, with bpy.ops.mesh.primitive_plane_add() you can set the initial size and location of the plane (see the API docs for all the parameters): >>> bpy . ops . mesh . primitive_plane_add ( size = 3 , location = ( 1 , 2 , 3 )) { 'FINISHED' } Info Note that operator parameters can only be passed using keyword arguments . Operator context \u00b6 This is all very nice and powerful, but operators have a few inherent properties that can make them tricky to work with. An operator's execution crucially depends on the context in which it is called, where it gets most of the data it needs. As shown above simple parameter values can usually be passed, but values like the objects to operate on are retrieved implicitly. For example, to join a set of mesh objects into a single one you can call the operator bpy.ops.object.join() . But the current context needs to be correctly set for the operator to work: # We have no objects selected >>> bpy . context . selected_objects [] >>> bpy . ops . object . join () Warning : Active object is not a selected mesh { 'CANCELLED' } # After selecting 3 objects >>> bpy . context . selected_objects [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Cube.001' ], bpy . data . objects [ 'Cube.002' ]] # Now it works >>> bpy . ops . object . join () { 'FINISHED' } As can be seen above an operator only returns a value indicating the execution status. When calling the operator in the Python Console as above some extra info is printed. But when calling operators from scripts the status return value is all you have to go on, as the extra message isn't printed when the script is executed. And in some cases the reason an operator fails can be quite unclear: >>> bpy . context . selected_objects [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Camera' ]] >>> bpy . ops . mesh . intersect_boolean () Traceback ( most recent call last ): File \"<blender_console>\" , line 1 , in < module > File \"/usr/share/blender/2.92/scripts/modules/bpy/ops.py\" , line 132 , in __call__ ret = _op_call ( self . idname_py (), None , kw ) RuntimeError : Operator bpy . ops . mesh . intersect_boolean . poll () failed , context is incorrect This merely shows that the so-called poll function failed. The poll function is used by operators to determine if they can execute in the current context, by checking certain preconditions on things like the selected object(s), the type of data or an object mode. In this case the bpy.ops.mesh.intersect_boolean() operator doesn't perform a boolean intersection on multiple meshes, but only on the faces of a single object in edit mode, but you can't tell from the error message (nor does the documentation make that clear): To actually perform a boolean intersection on two objects from a Python script requires us to do what we would be do in the UI: add a Boolean modifier on one of the objects and set its parameters. We could take advantage of the Python Tooltips to see which operator we need: This would suggest that using bpy.ops.modifier_add(type='BOOLEAN') would be what we need, but then setting the required parameters on the modifier (i.e. the object to subtract) would become tricky. So for a boolean operation, and setting object modifiers in general, there's an easier way: >>> o = bpy . data . objects [ 'Cube' ] # Add a modifier on the object and set its parameters >>> mod = o . modifiers . new ( name = 'boolmod' , type = 'BOOLEAN' ) >>> mod . object = bpy . data . objects [ 'Cube.001' ] >>> mod . operation = 'DIFFERENCE' # At this point the modifier is all set up. We hide # the object we subtract to make the boolean result visible. >>> bpy . data . objects [ 'Cube.001' ] . hide_viewport = True Unfortunately, certain operations can only be performed by calling operators. So there's a good chance that you will need to use them at some point when doing Python scripting. Hopefully this section gives some clues as how to work with them. See this section for more details on all the above subtleties and issues relating to working with operators. The bpy.ops documentation also contains useful information on operators, including how to override an operator's implicit context with values you set yourself. Meshes \u00b6 One of the more common scene data types to work with from Python are 3D meshes. Meshes in Blender can contain polygons of an arbitrary number of vertices (so-called N-gons), can contain wire edges and support extra layers of data, such as vertex colors and UV coordinates. We go into a fair amount of detail on how to create and access mesh data, in several ways. As usual, the Blender API docs on the Mesh type contain many more details, but we feel the discussion below is a good summary to get you started for many use cases. Creating a mesh (high-level) \u00b6 As shown earlier the Mesh.from_pydata(vertices, edges, faces) method allows a simple and high-level way of creating a mesh. This method doesn't offer full control over the created mesh and isn't very fast for large meshes, but it can be good enough in a lot of cases. It takes three lists of values, or actually, any Python iterable that matches the expected form: vertices: a sequence of float triples, e.g. [(1.0, 2.0, 3.0), (4, 5, 6), ...] edges: a sequence of integer pairs (vertex indices), that define edges by. If [] is passed edges are inferred from polygons faces: a sequence of one or more polygons, each defined as a sequence of 3 or more vertex indices. E.g. [(0, 1, 2), (1, 2, 3, 4), ...] Note The choice of how the mesh data is passed might incur an overhead in memory usage and processing time, especially when regular Python data structures, like lists, are used. An alternative would be to pass NumPy arrays. For the examples below we assume that no explicit list of edges is passed. Edges will then be created implicitly based on the polygons specified, which is usually what is preferred. We discuss explicitly specifying edges below . An example of creating a simple mesh: # Create a mesh consisting of 3 polygons using 6 vertices vertices = [ ( 0 , 0 , 0 ), ( 2 , 0 , 0 ), ( 2 , 2 , 0.2 ), ( 0 , 2 , 0.2 ), ( 1 , 3 , 1 ), ( 1 , - 1 , - 1 ), ] polygons = [ ( 0 , 1 , 2 , 3 ), # Quad ( 4 , 3 , 2 ), # Triangle ( 0 , 5 , 1 ) # Triangle ] m = bpy . data . meshes . new ( name = 'my mesh' ) m . from_pydata ( vertices , [], polygons ) At this point we have created a new Mesh Python object, which corresponds to Object Data of type Mesh. Object Data cannot be directly added to a scene, but needs to be referenced by a 3D Object: # Create an object referencing the mesh data o = bpy . data . objects . new ( name = 'my mesh' , object_data = m ) # Add the object to the scene bpy . context . scene . collection . objects . link ( o ) The resulting mesh and outliner entry looks like this: Careful: invalid data \u00b6 Note that it is possible to set up a mesh with invalid/inconsistent data when setting the underlying arrays manually, as is the case here. This can cause weird behaviour or even crashes. For example: # 3 vertices vertices = [ ( 0 , 0 , 0 ), ( 1 , 1 , 1 ), ( - 1 , 2 , - 1 ) ] # Invalid vertex index 3 used! polygons = [ ( 0 , 1 , 2 , 3 ) ] m = bpy . data . meshes . new ( name = 'my invalid mesh' ) m . from_pydata ( vertices , [], polygons ) o = bpy . data . objects . new ( name = 'my invalid mesh' , object_data = m ) bpy . context . scene . collection . objects . link ( o ) When executing the above code a new mesh is added to the scene, but it will show as a triangle in the 3D viewport, instead of a quad. And even though that doesn't appear to be unreasonable behaviour in this case Blender will crash if we subsequently enter edit mode on the mesh! So the lesson here is to be careful when specifying geometry using these low-level API calls. This actually applies to all parts of the Blender Python API in general. In this case, to make sure a created mesh has valid data we can use the validate() method on a Mesh . This will check the mesh data and remove any invalid values, e.g. by deleting the polygon using non-existent vertex index 3 above. This might not result in a mesh that matches what you want based on the data, but at least you can detect this situation and handle it without Blender crashing. The validate() method has two issues to be aware of: The method returns True in case the mesh does not validate, i.e. when it has issues. More specifically, it returns True when changes were made to the mesh data to remove invalid values. It will only report on the specific issues found when called with validate(verbose=True) and then will only output to the console. But it is still a good idea to always validate a mesh when creating it manually: ... m = bpy . data . meshes . new ( name = 'my invalid mesh' ) m . from_pydata ( vertices , [], polygons ) if m . validate ( verbose = True ): print ( 'Mesh had issues and has been altered! See console output for details' ) In the example of the invalid mesh data above this results in these message being printed in the console output: ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:351 BKE_mesh_validate_arrays: Edge 0: v2 index out of range, 3 ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:351 BKE_mesh_validate_arrays: Edge 3: v2 index out of range, 3 ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:605 BKE_mesh_validate_arrays: Loop 3 has invalid vert reference (3) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 0 is unused. ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 1 is unused. ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 2 is unused. ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 3 is unused. After validate() returns we can see in this case that invalid data was indeed removed: >>> vertices = [ ( 0 , 0 , 0 ), ( 1 , 1 , 1 ), ( - 1 , 2 , - 1 ) ] >>> polygons = [ ( 0 , 1 , 2 , 3 ) ] >>> m = bpy . data . meshes . new ( name = 'my invalid mesh' ) >>> m . from_pydata ( vertices , [], polygons ) >>> len ( m . polygons ) 1 >>> len ( m . edges ) 4 >>> len ( m . vertices ) 3 >>> m . validate () True >>> len ( m . polygons ) 0 >>> len ( m . edges ) 2 >>> len ( m . vertices ) 3 Creating a mesh (low-level) \u00b6 A second, and more flexible, way of creating a mesh is using low-level calls for setting the necessary data arrays directly on a Mesh object. This is especially useful in combination with NumPy arrays, as this allows the creation of large meshes with relatively high performance and low memory overhead. Meshes in Blender are stored using 4 arrays, as attributes of the bpy.types.Mesh type: vertices : vertex locations, each specified by 3 floats loops : contains the vertex indices used for defining polygons of a mesh, each polygon as a sequence of indices in the vertices array polygons : defines the start index of each polygon as an index in loops , plus the length of each polygon in number of vertices edges : defines the edges of the mesh, using two vertex indices per edge So to create a mesh at this level we need to set up the necessary values for these arrays. Here, we create the same mesh as in the previous section, using NumPy arrays for storing the data. # Vertices (8): x1 y1 z1 x2 y2 z2 ... vertices = numpy . array ([ 0 , 0 , 0 , 2 , 0 , 0 , 2 , 2 , 0.2 , 0 , 2 , 0.2 , 1 , 3 , 1 , 1 , - 1 , - 1 , 0 , - 2 , - 1 , 2 , - 2 , - 1 ], dtype = numpy . float32 ) # # Polygons, defined in loops # # List of vertex indices of all loops combined vertex_index = numpy . array ([ 0 , 1 , 2 , 3 , # Quad 4 , 3 , 2 , # Triangle 0 , 5 , 1 # Triangle ], dtype = numpy . int32 ) # For each polygon the start of its indices in vertex_index loop_start = numpy . array ([ 0 , 4 , 7 ], dtype = numpy . int32 ) # Length of each polygon in number of vertices loop_total = numpy . array ([ 4 , 3 , 3 ], dtype = numpy . int32 ) We additionally also specify texture coordinates and vertex colors. This is something that is not possible with the high-level from_pydata() API shown above. Note that we need to specify these values per vertex per polygon loop . # Texture coordinates per vertex per polygon loop uv_coordinates = numpy . array ([ 0 , 0 , 1 , 0 , 1 , 1 , 0 , 1 , # Quad 0.5 , 1 , 0 , 0 , 1 , 0 , # Triangle 0 , 1 , 0.5 , 0 , 1 , 1 # Triangle ], dtype = numpy . float32 ) # Vertex color (RGBA) per vertex per polygon loop vertex_colors = numpy . array ([ 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 0 , 1 , 1 , ], dtype = numpy . float32 ) Next, we create a new mesh using the above arrays: num_vertices = vertices . shape [ 0 ] // 3 num_vertex_indices = vertex_index . shape [ 0 ] num_loops = loop_start . shape [ 0 ] m = bpy . data . meshes . new ( name = 'my detailed mesh' ) # Vertices m . vertices . add ( num_vertices ) m . vertices . foreach_set ( 'co' , vertices ) # Polygons m . loops . add ( num_vertex_indices ) m . loops . foreach_set ( 'vertex_index' , vertex_index ) m . polygons . add ( num_loops ) m . polygons . foreach_set ( 'loop_start' , loop_start ) m . polygons . foreach_set ( 'loop_total' , loop_total ) # Create UV coordinate layer and set values uv_layer = m . uv_layers . new ( name = 'default' ) uv_layer . data . foreach_set ( 'uv' , uv_coordinates ) # Create vertex color layer and set values vcol_layer = m . vertex_colors . new () vcol_layer . data . foreach_set ( 'color' , vertex_colors ) # Done, update mesh object m . update () # Validate mesh if m . validate ( verbose = True ): print ( 'Mesh data did not validate!' ) # Create an object referencing the mesh data o = bpy . data . objects . new ( name = 'my detailed mesh' , object_data = m ) # Add the object to the scene bpy . context . scene . collection . objects . link ( o ) Note Passing a multi-dimensional NumPy array directly to foreach_set() will not work: >>> vertices = numpy . array ([ ... ( 0 , 0 , 0 ), ( 2 , 0 , 0 ), ( 2 , 2 , 0.2 ), ( 0 , 2 , 0.2 ), ... ( 1 , 3 , 1 ), ( 1 , - 1 , - 1 ), ( 0 , - 2 , - 1 ), ( 2 , - 2 , - 1 ) ... ], 'float32' ) >>> vertices . shape ( 8 , 3 ) >>> m = bpy . data . meshes . new ( name = 'my detailed mesh' ) >>> m . vertices . foreach_set ( 'co' , vertices ) Traceback ( most recent call last ): File \"<blender_console>\" , line 1 , in < module > RuntimeError : internal error setting the array However, passing a flattened array does work: >>> m . vertices . foreach_set ( 'co' , vertices . flatten ()) >>> [ v . co for v in mesh . vertices ] [ Vector (( 0.0 , 0.0 , 0.0 )), Vector (( 2.0 , 0.0 , 0.0 )), Vector (( 2.0 , 2.0 , 0.20000000298023224 )), Vector (( 0.0 , 2.0 , 0.20000000298023224 )), Vector (( 1.0 , 3.0 , 1.0 )), Vector (( 1.0 , - 1.0 , - 1.0 )), Vector (( 0.0 , - 2.0 , - 1.0 )), Vector (( 2.0 , - 2.0 , - 1.0 ))] Specifying edges when creating a mesh \u00b6 In most cases we want to create a mesh consisting of only polygons and in that case don't need to specify edges. For certain mesh objects it can be of interest to also be able to specify edges explicitly, or even to create a mesh that consists only of vertices and edges between them. Edges can be used to add line segments that are not part of polygons. We build upon the example mesh we created above by adding a set of 3 edges: # Create a mesh consisting of 3 polygons using 8 vertices, with 3 extra edges # that are not part of the polygons vertices = [ ( 0 , 0 , 0 ), ( 2 , 0 , 0 ), ( 2 , 2 , 0.2 ), ( 0 , 2 , 0.2 ), ( 1 , 3 , 1 ), ( 1 , - 1 , - 1 ), ( 0 , - 2 , - 1 ), ( 2 , - 2 , - 1 ) ] edges = [ ( 5 , 6 ), ( 6 , 7 ), ( 5 , 7 ) ] polygons = [ ( 0 , 1 , 2 , 3 ), # Quad ( 4 , 3 , 2 ), # Triangle ( 0 , 5 , 1 ) # Triangle ] m = bpy . data . meshes . new ( name = 'my mesh with edges' ) m . from_pydata ( vertices , edges , polygons ) o = bpy . data . objects . new ( name = 'my mesh with edges' , object_data = m ) bpy . context . scene . collection . objects . link ( o ) The resulting mesh and outliner entry looks like this: Note that even though we specified only 3 edges explicitly the polygons in the mesh implicitly define 8 more. These are the edges making up those polygons, with shared edges being present only once. In total this results in 11 edges in the mesh: >>> len ( m . edges ) 11 For the second, low-level, method of mesh creation edges are handled slightly different. Edges can be set explicitly by using Mesh.edges : # Vertices (8): x1 y1 z1 x2 y2 z2 ... vertices = numpy . array ([ 0 , 0 , 0 , 2 , 0 , 0 , 2 , 2 , 0.2 , 0 , 2 , 0.2 , 1 , 3 , 1 , 1 , - 1 , - 1 , 0 , - 2 , - 1 , 2 , - 2 , - 1 ], dtype = numpy . float32 ) # Extra edges (3) not defined implicitly by polygons edges = numpy . array ([ 5 , 6 , 6 , 7 , 5 , 7 ], dtype = numpy . int32 ) # # Polygons, defined in loops # # List of vertex indices of all loops combined vertex_index = numpy . array ([ 0 , 1 , 2 , 3 , # Quad 4 , 3 , 2 , # Triangle 0 , 5 , 1 # Triangle ], dtype = numpy . int32 ) # For each polygon the start of its indices in vertex_index loop_start = numpy . array ([ 0 , 4 , 7 ], dtype = numpy . int32 ) # Length of each polygon in number of vertices loop_total = numpy . array ([ 4 , 3 , 3 ], dtype = numpy . int32 ) num_vertices = vertices . shape [ 0 ] // 3 num_edges = edges . shape [ 0 ] // 2 num_vertex_indices = vertex_index . shape [ 0 ] num_loops = loop_start . shape [ 0 ] m = bpy . data . meshes . new ( name = 'detailed mesh with edges' ) # Vertices m . vertices . add ( num_vertices ) m . vertices . foreach_set ( 'co' , vertices ) # Edges m . edges . add ( num_edges ) m . edges . foreach_set ( 'vertices' , edges ) # Polygons m . loops . add ( num_vertex_indices ) m . loops . foreach_set ( 'vertex_index' , vertex_index ) m . polygons . add ( num_loops ) m . polygons . foreach_set ( 'loop_start' , loop_start ) m . polygons . foreach_set ( 'loop_total' , loop_total ) # Done, update mesh object m . update () # Validate mesh if m . validate ( verbose = True ): print ( 'Mesh data did not validate!' ) Here, we only specify the extra edges and not the polygon edges. But when we try to validate the mesh errors will be reported: ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (0, 1) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (1, 2) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (2, 3) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (3, 0) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 1 needs missing edge (4, 3) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 1 needs missing edge (3, 2) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 1 needs missing edge (2, 4) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 2 needs missing edge (0, 5) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 2 needs missing edge (5, 1) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 2 needs missing edge (1, 0) So the polygon edges, which we did not specify, are being reported. In this case the validate() method will correct this and add the missing edges. But having errors reported for regular polygon edges makes it harder to detect any other issues with the mesh data. So the Mesh.update() method provides the option calc_edges . By default this option is False , but when set to True all edges in the mesh will be recalculated to be consistent with the available vertex indices, polygons and extra edges set. ... # Done, update mesh object and recalculate edges m . update ( calc_edges = True ) Validation now succeeds: >>> m . validate ( verbose = True ) False Accessing mesh data (object mode) \u00b6 Inspecting or using mesh data is straightforward. Here we use one of the meshes created with the low-level methods above and retrieve some of its data. Note that Blender provides a few values derived from the original arrays, such as loop_indices and vertices per polygon, which can be useful for certain operations. m = bpy . data . meshes [ 'my detailed mesh' ] len ( m . vertices ) => 8 len ( m . polygons ) => 3 # 2 triangles + 1 quad = 2*3 + 1*4 = 10 len ( m . loops ) => 10 # 8 implicit edges (for 2 triangles and 1 quad), shared edges only listed once len ( m . edges ) => 8 m . vertices [ 7 ] . co => Vector (( 2.0 , - 2.0 , - 1.0 )) # Coordinate m . vertices [ 7 ] . normal => Vector (( 0.6 .. , - 0.6 .. , - 0.3 .. )) # Normal m . vertices [ 7 ] . select => True # Selected (edit mode) m . polygons [ 2 ] . index => 2 # Useful in 'for p in m.polygons' m . polygons [ 2 ] . loop_start => 7 # First index in loops array m . polygons [ 2 ] . loop_total => 3 # Number of vertices in loop m . polygons [ 2 ] . loop_indices => [ 7 , 8 , 9 ] # Indices in m.loops m . loops [ 7 ] . vertex_index => 0 m . loops [ 8 ] . vertex_index => 5 m . loops [ 9 ] . vertex_index => 1 m . polygons [ 2 ] . vertices => [ 0 , 5 , 1 ] # Actual vertex indices m . polygons [ 2 ] . select => True # Selected (edit mode) m . polygons [ 2 ] . use_smooth => False # Smooth shading enabled # These are automatically computed m . polygons [ 2 ] . area => 1.4142135381698608 m . polygons [ 2 ] . normal => Vector (( 0.0 , - 0.707 ... , 0.707 ... )) m . polygons [ 2 ] . center => Vector (( 1.0 , - 0.333 ... , - 0.333 ... )) m . edges [ 0 ] . vertices => [ 2 , 3 ] # (bpy_prop_array) Vertex colors \u00b6 A mesh can have multiple sets of vertex colors. Each set has a name and for each vertex the associated color (but see below). By default meshes created in Blender do not have a vertex color layer. >>> m bpy . data . meshes [ 'Cube' ] >>> type ( m . vertex_colors ) < class ' bpy_prop_collection '> # Create a new vertex color layer >>> vcol_layer = m . vertex_colors . new ( name = 'My vertex colors' ) >>> vcol_layer bpy . data . meshes [ 'Cube' ] . vertex_colors [ \"My vertex colors\" ] >>> len ( m . vertex_colors ) 1 # Name shown under Object Data -> Vertex Colors >>> vcol_layer . name 'My vertex colors' The vertex colors themselves are accessed through the data member: >>> type ( vcol_layer . data ) < class ' bpy_prop_collection '> >>> len ( vcol_layer . data ) 24 >>> type ( vcol_layer . data [ 0 ] . color ) < class ' bpy_prop_array '> >>> list ( vcol_layer . data [ 0 ] . color ) [ 1.0 , 1.0 , 1.0 , 1.0 ] >>> len ( m . polygons ) 6 >>> len ( m . vertices ) 8 >>> len ( m . loops ) 24 One thing to notice here is that the vertex color array has 24 entries. But the Cube object only has 8 vertices and 6 polygons. The reason the higher number of vertex colors is that Blender stores separate vertex colors per polygon . So the Cube has 6 polygons, each defined using 4 vertices, hence 6*4=24 vertex colors in total (which is the same number as the length of the loops array). This is more flexible than what most 3D file formats allow, which usually only store one color per vertex. During import Blender will duplicate those colors to set the same color for a vertex in all polygons in which it is used. An example of how to take advantage of the added flexibilit is that we can set a random color per cube face by setting each of the 4 vertex colors of a face to the same color: for i in range ( 6 ): r = random () g = random () b = random () for j in range ( 4 ): vcol_layer . data [ 4 * i + j ] . color = ( r , g , b , 1 ) A slightly more Blender-like (and robust) way to write the above code would be to take advantage of the polygon loop indices: for p in m . polygons : r = random () g = random () b = random () for i in p . loop_indices : vcol_layer . data [ i ] . color = ( r , g , b , 1 ) Active set \u00b6 As noted above a mesh can have more than one layer of vertex colors. Among the sets present on a mesh there can be only one that is active. The active vertex color layer set controls, for example, which vertex colors are visible in the 3D viewport and are edited in Vertex Paint mode. When adding a vertex color layer (and similar for UV maps described below) through the UI the active layer is changed to the newly added layer. Also, clicking in the Vertex Color layer UI changes the active layer. Below is a list of 2 vertex color layers on a mesh shown, of which Another layer is the active one. The camera icon right of the vertex color names controls which layer is used during rendering by default (and which is set independently of the active status). But in most cases the shader used on an object will explicitly choose a vertex color layer and so override the setting in the UI list. Controling the active vertex color (or UV map) layer can be done using the active property: >>> m . vertex_colors . active_index 1 >>> m . vertex_colors . active bpy . data . meshes [ 'Cube' ] . vertex_colors [ \"Another layer\" ] >>> m . vertex_colors . active = m . vertex_colors [ 0 ] >>> m . vertex_colors . active bpy . data . meshes [ 'Cube' ] . vertex_colors [ \"Col\" ] UV coordinates \u00b6 UV coordinates follow the same setup as vertex colors, but instead store a 2-tuple of floats per vertex per polygon. Note that just like for vertex colors UV coordinates are also specified per vertex per polygon . Meshes created in Blender will already have a UV map called UVMap : >>> m bpy . data . meshes [ 'Cube' ] >>> len ( m . uv_layers ) 1 >>> m . uv_layers [ 0 ] . name 'UVMap' The actual UV values are once again stored under the data member: >>> uv_map = m . uv_layers [ 0 ] >>> uv_map bpy . data . meshes [ 'Cube' ] . uv_layers [ \"UVMap\" ] >>> type ( uv_map . data ) < class ' bpy_prop_collection '> >>> len ( uv_map . data ) 24 >>> type ( uv_map . data [ 0 ]) < class ' bpy . types . MeshUVLoop '> >>> uv_map . data [ 0 ] . uv Vector (( 0.375 , 0.0 )) In general, UV maps are either set through importing or edited within Blender using the UV Editor, although there can be valid reasons for wanting to control them through the Python API. BMesh \u00b6 There is another method in Blender for creating meshes and accessing their data: the so-called BMesh, which is implemented by the bmesh module and its BMesh class. BMesh is especially interesting when you want to perform more complex geometric operations on an existing mesh, or build up a mesh polygon-by-polygon instead of providing the full mesh in one go as a set of arrays as shown above. Here, we only give a brief overview of BMesh and refer to the API docs for all the details. The differences of BMesh compared to working with the native mesh data structure we showed above: A BMesh holds extra data on mesh connectivity, like the neighbours of a vertex, which can be easily queried for geometric editing. The trade-off is that a BMesh will use more memory to store all this extra data, but that is usually only a limiting factor for very large meshes. It is somewhat slower to create a (large) mesh using a BMesh, as each mesh element (vertex, edge, polygon) takes a Python call to create, plus needs extra calls and Python values to set up. A BMesh cannot be used directly in a scene, it first needs to be converted or copied back to a Mesh (and so mesh data is present twice in memory at some point in time) A large set of high- and low-level geometric operations, such as merging vertices within a given distance, face splitting, edge collapsing or generating a convex hull, is provided in bpy.ops and bmesh.utils . These operations would be tedious and error prone to script manually. Here's a (verbose) example of create a BMesh from scratch that holds a single triangle and edge: import bmesh bm = bmesh . new () # Create 3 vertices v1 = bm . verts . new (( 0 , 0 , 0 )) v2 = bm . verts . new (( 1 , 0 , 1 )) v3 = bm . verts . new (( 0 , 1 , 1 )) v4 = bm . verts . new (( 1 , 1 , 1 )) # Add a triangle bm . faces . new (( v1 , v2 , v3 )) # Add a line edge bm . edges . new (( v3 , v4 )) # Done setting up the BMesh, now copy geometry to a regular Mesh m = bpy . data . meshes . new ( 'mesh' ) bm . to_mesh ( m ) # Release BMesh data, bm will no longer be usable bm . free () # Add regular Mesh as object o = bpy . data . objects . new ( 'mesh' , m ) bpy . context . scene . collection . objects . link ( o ) A BMesh can also be created from an existing Mesh , edited and then copied back to the Mesh : o = bpy . context . active_object m = o . data # Create a new BMesh and copy geometry from the Mesh bm = bmesh . new () bm . from_mesh ( m ) # Edit some geometry bm . verts . ensure_lookup_table () bm . verts [ 4 ] . co . x += 3.14 bm . faces . ensure_lookup_table () bm . faces . remove ( bm . faces [ 0 ]) # Copy back to Mesh bm . to_mesh ( m ) bm . free () If a Mesh is currently in edit mode you can still create a BMesh from it, edit that and the copy the changes back, while keeping the Mesh in edit mode: o = bpy . context . active_object m = o . data assert m . mode == 'EDIT' bm = bmesh . new () # Note the different call, i.e. NOT from_mesh() bm . from_edit_mesh ( m ) # <edit BMesh> # Update edit-mesh of Mesh bm . update_edit_mesh ( m ) bm . free () This can be useful when you're working in edit mode on a mesh and also want to run a script on it that uses BMesh, but don't want to switch in and out of edit-mode to run the script. Note that there are some things to watch out for in synchronizing BMesh state to a Mesh . Some examples of the geometric queries that you can do on a BMesh (see docs for more): bm . verts [ i ] . co # Vertex coordinate as mathutils.Vector bm . verts [ i ] . normal # Vertex normal bm . verts [ i ] . is_boundary # True if vertex is at the mesh boundary bm . verts [ i ] . is_wire # True if vertex is not connected to any faces bm . verts [ i ] . link_edges # Sequence of edges connected to this vertex bm . verts [ i ] . link_faces # Sequence of faces connected to this vertex bm . edges [ i ] . calc_length () # Length of the edge bm . edges [ i ] . is_boundary # True if edge is boundary of a face bm . edges [ i ] . is_wire # True if edge is not connected to any faces bm . edges [ i ] . is_manifold # True if edge is manifold (used in at most 2 faces) v = bm . edges [ i ] . verts [ 0 ] # Get one vertex of this edge bm . edges [ i ] . other_vert ( v ) # Get the other vertex bm . edges [ i ] . link_faces # Sequence of faces connected to this edge bm . faces [ i ] . calc_area () # Face area bm . faces [ i ] . calc_center_median () # Median center bm . faces [ i ] . edges # Sequence of edges defining this face bm . faces [ i ] . verts # Sequence of vertices defining this face bm . faces [ i ] . normal # Face normal Materials \u00b6 As shown in one of the introductory exercises it is possible to use Python to create a node-based shader. In most cases using the node-based editor in the UI is the preferred option due to its interactivity, but for certain cases it can be interesting to use Python. The general workflow for this is to create the necessary shader nodes, connected them through links as needed and then set the material on the relevant mesh. # Create a new material mat = bpy . data . materials . new ( \"my material\" ) # Enable shader nodes on the material mat . use_nodes = True # Remove the default nodes nodes = mat . node_tree . nodes nodes . clear () # Add a Principled BSDF shader node and set its base color shader = nodes . new ( type = 'ShaderNodeBsdfPrincipled' ) shader . location = 0 , 300 shader . inputs [ 'Base Color' ] . default_value = ( 1 , 0 , 0 , 1 ) # Add a Material Output node node_output = nodes . new ( type = 'ShaderNodeOutputMaterial' ) node_output . location = 400 , 300 # Add a link between the nodes links = nodes . links links . new ( shader . outputs [ 'BSDF' ], node_output . inputs [ 'Surface' ]) # Add material to the mesh's material slots mesh . materials . append ( mat ) A node's inputs and outputs can be referenced by name. This can then be used to set values on inputs, or connect outputs to inputs, as shown. For example, for the Principled BSDF node above: >>> shader . inputs . keys () [ 'Base Color' , 'Subsurface' , 'Subsurface Radius' , 'Subsurface Color' , 'Metallic' , 'Specular' , 'Specular Tint' , 'Roughness' , 'Anisotropic' , 'Anisotropic Rotation' , 'Sheen' , 'Sheen Tint' , 'Clearcoat' , 'Clearcoat Roughness' , 'IOR' , 'Transmission' , 'Transmission Roughness' , 'Emission' , 'Emission Strength' , 'Alpha' , 'Normal' , 'Clearcoat Normal' , 'Tangent' ] >>> shader . outputs . keys () [ 'BSDF' ] The location attributes set above are not strictly needed if you're not going to work on the shader network in the Shader Editor in the UI. But they help to make the node network layout somewhat visually pleasing. Material slots \u00b6 The last line in the Python code above adds the created material to the mesh's material slots. An object can have multiple materials assigned to it and each assigned material uses a so-called material slot. Each polygon in a mesh can only use a single material, by specifying the material index (i.e. slot) to use for that polygon. This allows different parts of a mesh to use different shaders. By default all faces in a mesh will reference material slot 0. But here's an example of a cube mesh that uses 3 different materials: Inspecting the underlying material data: # Get the mesh, as the material is linked to the mesh by default >>> o = bpy . data . objects [ 'Cube' ] >>> m = o . data # The material slots used >>> list ( m . materials ) [ bpy . data . materials [ 'red' ], bpy . data . materials [ 'black-white checkered' ], bpy . data . materials [ 'voronoi' ]] # Polygon -> slot index >>> m . polygons [ 0 ] . material_index 2 >>> m . polygons [ 1 ] . material_index 0 >>> m . polygons [ 2 ] . material_index 0 >>> m . polygons [ 3 ] . material_index 0 >>> m . polygons [ 4 ] . material_index 1 >>> m . polygons [ 5 ] . material_index 0 Material indices can be set per polygon, or set as an array in one go: # Material slot index for a single polygon m . polygons [ 0 ] . material_index = 0 # Set all polygon material indices face_materials = [ 0 , 1 , 2 , 2 , 1 , 0 ] m . polygons . foreach_set ( 'material_index' , face_materials ) # Force an update of the mesh, needed in this case m . update () Custom properties \u00b6 Sometimes it can useful to be able to control certain values that you use in a script from the UI. The most flexible, but also most complex, approach would be write an add-on . However, in quite a few cases there's a simpler alternative if all you need to control are simple Python values, like an int, float, string or list. From Python you can set custom properties on pretty much any Blender Python data block (see here for more details) and then access those values from the UI: >>> o bpy . data . objects [ 'Cube' ] >>> o [ 'My prop' ] = 123.4 >>> o [ 'My 2nd prop' ] = ( 1 , 1 , 0.5 ) This works, of course, both ways: adding or editing a value from the UI will update the value(s) available through Python. You can then use these values in a script, for example to control a number of objects to create, set a 3D coordinate, etc. See here for more details and examples. Into the deep end... \u00b6 Here we go deeper into some more exotic topics, but which can be of interest with more advanced Python scripting and complex scene setups. Data-block users and garbage collection \u00b6 Blender uses a system based on reference-counting to decide when data-blocks have become unused and can get purged. In the short video below we show some of the details of this scheme: The video shows the Orphan Data outliner mode, but there are several modes that can be used to get detailed insight into the current state of Blender internals: The Blender File mode gives a high-level overview of a file's contents, including some of the more implicit data block types, such as Workspaces. The Data API mode provides an even more detailed view. It is actually a great way to inspect all the gory details of Blender's internal data structures. It will show all data-blocks by type and their attributes. Some attributes can be even be edited in this outliner mode. The Orphan Data mode shows data blocks that do not have any users and which will not be saved (unless they are marked to have a fake user). Some of the data-blocks you see here might not have been created by you, but are used by Blender internally, for example the Brushes. Although the video only focused on materials, the way data-block lifetime is managed using the user counts is general to all types of data-blocks in Blender. But there are subtle differences in whether a data-block is really deleted or just has a link to it removed: Whenever the term \"unlink\" is used it means that a link to that data-block is removed and its user count decreased, but the data-block itself will still be in memory. An example of this is clicking the X next to a mesh's material in the Material Properties. If the UI uses the term \"delete\" it means the data-block is deleted immediately from memory. Any data-blocks linked from the deleted data-block will have their users count decreased. An example of this is deleting a Camera object in the 3D view: the Camera object's data-block is deleted from memory, but the Camera object data data-block (containing the actual camera settings) is still in memory, which you can check in the Orphan Data mode of the outliner. The usage count of data-blocks can also be queried from Python: # Two cube meshes using the same material >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Cube.001' ]] >>> bpy . data . materials [ 'Material' ] . users 2 # Add a new material, set one of the cubes to use it >>> bpy . data . materials [ 'Material' ] . users 1 >>> bpy . data . materials [ 'Material.001' ] . users 1 # <Delete Cube.001 object in the UI> # Hmmm, still has a user? >>> bpy . data . materials [ 'Material.001' ] . users 1 # The reason is we deleted the Cube.001 *object*, but # the Cube.001 *mesh* is still alive (as its usage count # was merely decremented) and it still references the material >>> bpy . data . objects [ 'Cube.001' ] Traceback ( most recent call last ): File \"<blender_console>\" , line 1 , in < module > KeyError : 'bpy_prop_collection[key]: key \"Cube.001\" not found' >>> bpy . data . meshes [ 'Cube.001' ] bpy . data . meshes [ 'Cube.001' ] >>> bpy . data . meshes [ 'Cube.001' ] . users 0 >>> bpy . data . meshes [ 'Cube.001' ] . materials . values () [ bpy . data . materials [ 'Material' ]] The use_fake_user attribute of a data block controls whether a Fake user is set, similar to the checkbox in the UI. Warning In most cases you probably don't want to manually delete data blocks from a file and only use the normal UI operations for that. But it is possible for cases that need it. Truly purging a data block from Python can be done with the relevant remove() method, e.g. >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Cube' ]] >>> o = bpy . context . active_object >>> o bpy . data . objects [ 'Cube' ] >>> m = o . data >>> m bpy . data . meshes [ 'Cube' ] # Remove the Mesh data-block from the file >>> bpy . data . meshes . remove ( m ) >>> bpy . data . meshes . values () [] >>> bpy . data . objects . values () [] Note that in the case of deleting object data (in this case a Mesh) any Objects referencing that object data also get removed ! A second thing to note is the above code does not actually update the current Blender file on disk. That only happens on an explicit save action (e.g. through the File menu or using the relevant operator from Python). A note on bpy.data , bpy.data.objects , ... \u00b6 We have been using bpy.data.objects in most examples above to access objects in the scene. This is actually not completely clean, as bpy.data.objects holds all objects in the Blender file . Usually, the distinction doesn't matter as you only have one scene, but a Blender file can hold multiple scenes, each with their own set of objects: # A file with two scenes, each with their own set of objects >>> bpy . data . scenes . values () [ bpy . data . scenes [ 'Scene' ], bpy . data . scenes [ 'Scene.001' ]] # Current scene >>> bpy . context . scene bpy . data . scenes [ 'Scene' ] # And its objects >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Bottom cube' ], bpy . data . objects [ 'Top Cube' ]] # <Select different scene> # Different current scene >>> bpy . context . scene bpy . data . scenes [ 'Scene.001' ] # And its objects >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Bottom cube.001' ], bpy . data . objects [ 'Top Cube.001' ]] # All objects in the file >>> bpy . data . objects . values () [ bpy . data . objects [ 'Bottom cube' ], bpy . data . objects [ 'Bottom cube.001' ], bpy . data . objects [ 'Top Cube' ], bpy . data . objects [ 'Top Cube.001' ]] Although objects can also be shared between scenes: # Two scenes >>> bpy . data . scenes . values () [ bpy . data . scenes [ 'Scene' ], bpy . data . scenes [ 'Scene.001' ]] # First scene, cubes are local to scene, torus is shared between scenes >>> bpy . context . scene bpy . data . scenes [ 'Scene' ] >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Torus' ], bpy . data . objects [ 'Bottom cube' ], bpy . data . objects [ 'Top Cube' ]] # Second scene, different cubes, torus is shared >>> bpy . context . scene bpy . data . scenes [ 'Scene.001' ] >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Bottom cube.001' ], bpy . data . objects [ 'Top Cube.001' ], bpy . data . objects [ 'Torus' ]] The point here is that bpy.data.objects , and every other attribute under bpy.data , holds values of the complete Blender file . Per-scene values are available through attributes of a Scene object, e.g. bpy.context.scene.objects . For certain use cases this distinction matters. Parenting \u00b6 An object's parent can be queried or set simply through its parent attribute, which needs to reference another Object (or None ). But when parenting is involved the use of transformation matrices becomes somewhat more complex. Suppose we have two cubes above each other, the top cube transformed to Z=5 and the bottom cube to Z=2: Using the 3D viewport we'll now parent the bottom cube to the top cube ( LMB click bottom cube, Shift-LMB click top cube, Ctrl-P , select Object ) and inspect the values in Python: >>> bpy . data . objects [ 'Bottom cube' ] . parent bpy . data . objects [ 'Top cube' ] # The bottom cube is still located in the scene at Z=2, # even after parenting, as is expected >>> bpy . data . objects [ 'Bottom cube' ] . matrix_world Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 2.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) If an object has a parent its matrix_local attribute will contain the transformation relative to its parent , while matrix_world will contain the resulting net object-to-world transformation. If no parent is set then matrix_local is equal to matrix_world . Let's check the bottom cube's local matrix value: # Correct, it is indeed -3 in Z relative to its parent >>> bpy . data . objects [ 'Bottom cube' ] . matrix_local Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , - 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) As already shown above the parent attribute can be used to inspect and control the parenting relationship: >>> bpy . data . objects [ 'Top cube' ] . parent # None >>> bpy . data . objects [ 'Bottom cube' ] . parent bpy . data . objects [ 'Top cube' ] # Remove parent >>> bpy . data . objects [ 'Bottom cube' ] . parent = None At this point the two cubes are no longer parented and are at Z=2 (\"Bottom cube\") and Z=5 (\"Top cube\") in the scene. But when we restore the parenting relationship from Python something funny happens 1 : # Set parent back to what it was >>> bpy . data . objects [ 'Bottom cube' ] . parent = bpy . data . objects [ 'Top cube' ] The reason for the different position of the cube called \"Bottom cube\" (which is now on top) is that when using the UI to set up a parenting relationship it does more than just setting the parent attribute of the child object. There's also something called the parent-inverse matrix. Let's inspect it and the other matrix transforms we've already seen for the current (unexpected) scene: # Identity matrix, i.e. no transform >>> bpy . data . objects [ 'Bottom cube' ] . matrix_parent_inverse Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 0.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # Hmmm, this places the \"Bottom cube\" 2 in Z *above* its parent at Z=5... >>> bpy . data . objects [ 'Bottom cube' ] . matrix_local Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 2.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # ... so it indeed ends up at Z=7 as we saw (above \"Top cube\") >>> bpy . data . objects [ 'Bottom cube' ] . matrix_world Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 7.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) So what happened here? Apparently the matrix_local matrix changed from its value of Z=-3 as we saw earlier. The answer is that when you set up a parenting relationship using the UI the parent-inverse matrix is set to the inverse of the current parent transformation (as the name suggests) while matrix_local is updated to inverse(parent.matrix_world) @ to_become_child.matrix_world . If we clear the parent value from Python and redo the parenting in the UI we can see this in the resulting transform matrices: >>> bpy . data . objects [ 'Bottom cube' ] . parent = None # <parent \"Bottom cube\" to \"Top cube\" in the UI> # Was identity, is now indeed the inverse of transforming +5 in Z >>> bpy . data . objects [ 'Bottom cube' ] . matrix_parent_inverse Matrix ((( 1.0 , - 0.0 , 0.0 , - 0.0 ), ( - 0.0 , 1.0 , - 0.0 , 0.0 ), ( 0.0 , - 0.0 , 1.0 , - 5.0 ), ( - 0.0 , 0.0 , - 0.0 , 1.0 ))) # Was Z=2, is now 2-5 >>> bpy . data . objects [ 'Bottom cube' ] . matrix_local Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , - 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # Was Z=7 >>> bpy . data . objects [ 'Bottom cube' ] . matrix_world Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 2.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) The reason for this behaviour is that when doing parenting in the 3D viewport you usually do not want the object that you are setting as the child to move. So the parenting matrices are adjusted accordingly when the parenting relationship is set up. But when we simply set parent from Python the matrix_local value is used as is, causing our bottom cube to suddenly move up, as it is used as the transform relative to its parent, while it actually would need a different value to stay in place. There's actually quite a bit more going on with all the different parenting options available from the UI. See this page for more details. The same thing happens when setting the parent in the UI using Object Properties > Relations > Parent \u21a9","title":"The Blender API in detail"},{"location":"modules/advanced/python_scripting/api_summary/#the-blender-api-in-detail","text":"","title":"The Blender API in detail"},{"location":"modules/advanced/python_scripting/api_summary/#introduction","text":"The Blender Python API mostly consists of a thin layer on top of the underlying Blender C/C++ data structures and methods. The underlying C/C++ code is used to automatically generate the Python API during the build process of the Blender executable, which means the API is always up-to-date with respect to the underlying code. The API isn't the only part of Blender that uses Python. Large parts of the user interface, the import/export scripts and all addons are written in Python. It is therefore relatively easy to extend Blender with, say, new UI dialogs or an importer. This is one of the strengths of the Blender Python API. Warning Since the API provides access to Blender internals at a very low level you can screw up the Blender state quite easily, causing unexpected behaviour, data corruption or even crashes. In the worst case you can end up with a file that will no longer load in Blender at all, although that's rare. So when working with Python scripting save your session to file often, preferably in a number of incremental versions. In cases where you suspect Blender's internal state has been corrupted you can save the current file, restart Blender and then reopen the file to help ensure you start from a known-good state.","title":"Introduction"},{"location":"modules/advanced/python_scripting/api_summary/#api-modules","text":"The Blender Python API is comprised of several modules, with bpy being the main one. But there's also useful routines in mathutils , bmesh and a few others. Tip The API documentation on these modules can be easily accessed from within Blender using Help > Python API Reference . By default none of the API modules, not even bpy , is loaded in the environment where a script file runs, so you need to import the ones you need explicitly. The Python Console does import quite a few things by defaults and also sets some useful variables, like C to access bpy.context and D to access bpy.data with less typing: PYTHON INTERACTIVE CONSOLE 3.9 . 4 ( default , Apr 20 2021 , 15 : 51 : 38 ) [ GCC 10.2 . 0 ] Builtin Modules : bpy , bpy . data , bpy . ops , bpy . props , bpy . types , bpy . context , bpy . utils , bgl , blf , mathutils Convenience Imports : from mathutils import * ; from math import * Convenience Variables : C = bpy . context , D = bpy . data >>> >>> D . objects . values () [ bpy . data . objects [ 'Camera' ], bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Light' ]]","title":"API modules"},{"location":"modules/advanced/python_scripting/api_summary/#developer-settings","text":"When developing Python scripts in Blender it can be useful to enable a few extra settings: The Python Tooltips under Interface > Display > Python Tooltips . When enabled a tooltip will show the corresponding Python command or a path to the data for a UI element. The Developer Extras under Interface > Display > Developer Extras . When enabled this provides multiple things: The 3D viewport overlay for a mesh in edit mode will now have an extra setting Indices to show the low-level indices of selected vertices/edges/faces. This can be very useful when debugging Python code that works on mesh geometry. The right-click menu for a UI item, such as a button or menu entry, will now also contain an entry called Online Python Reference linking to the relevant Python documentation page. It will enable Operator Search , which will add entries to the F3 search menu for operators. These will be listed after the regular menu entries in the search results. It adds a new menu option Help > Operator Cheat Sheet that will create a new text area called OperatorList.txt , which contains all available operators (see below ) and their default parameters. This list can give you a quick overview of the available operators, with the API documentation providing all the details. As mentioned in the video in the introductory chapter the Info area can be useful if you want to inspect which Python calls Blender performs for certain operations. This certainly will not provide all the details in all cases, but can give some insight. You can either switch to the default Scripting workspace to check the Info area, or use the normal UI area operations to add/change an area to an Info area.","title":"Developer settings"},{"location":"modules/advanced/python_scripting/api_summary/#data-blocks","text":"The different types of data in Blender are stored in data-blocks . For example, there's Mesh, Object, Texture and Shader data-blocks, but there's quite a few more . One of the clever bits in the way Blender is programmed is that data-blocks contain enough information about their content (i.e. meta-data) to make them readable by both older and newer versions of Blender than the one they were written with. This meta-data system also allows the Python API for accessing those data-blocks to get generated without much manual development. Data-blocks are available through Python per type under bpy.data , e.g. bpy.data.objects or bpy.data.meshes . The type of a data-block is the corresponding class under bpy.types , e.g. >>> type ( bpy . data . objects [ 'Cube' ]) < class ' bpy_types . Object '> >>> bpy . types . Object < class ' bpy_types . Object '> Each type of data-block has its own set of attributes and methods, particular to that type. Learning the Blender Python API involves getting to know the details of the data-block types you want to work with and how they interact. Blender keeps track of which data-blocks are no longer being referenced to decide when a data-block does not need to be saved (so-called garbage collection). Usually you don't need to explicitly interact with this system, but it is good to be aware that it is there, see this section below for more details.","title":"Data-blocks"},{"location":"modules/advanced/python_scripting/api_summary/#unique-data-block-names","text":"Per type of data all the data-blocks need to have a unique name . This is enforced automatically by Blender when a data-block is created by appending a number to make the name unique. For example: >>> bpy . data . meshes . new ( 'my object' ) bpy . data . meshes [ 'my object' ] >>> bpy . data . meshes . new ( 'my object' ) bpy . data . meshes [ 'my object.001' ] >>> bpy . data . meshes . new ( 'my object' ) bpy . data . meshes [ 'my object.002' ] This usually isn't an issue, but just something to be aware of when working with referencing objects by name, as the name of a data-block you created might actually be something different than you expect.","title":"Unique data-block names"},{"location":"modules/advanced/python_scripting/api_summary/#objects-and-object-data","text":"When we use the word Object in these pages we mean one of the object types that can be present in a 3D scene, e.g. camera, mesh, light, etc. Such objects are of type bpy.types.Object and all have general properties related to their presence in the 3D scene. For example, their name, 3D transformation, visibility flags, parent, etc. But a Light object needs to specify different properties than, say, a Camera object and these per-type properties are stored as object data . The object data can be accessed through the data attribute of an Object: # Both lights and cameras are Objects >>> type ( bpy . data . objects [ 'Light' ]) < class ' bpy_types . Object '> >>> type ( bpy . data . objects [ 'Camera' ]) < class ' bpy_types . Object '> # But their object data are of different types >>> type ( bpy . data . objects [ 'Camera' ] . data ) < class ' bpy . types . Camera '> >>> type ( bpy . data . objects [ 'Light' ] . data ) < class ' bpy . types . PointLight '> # And have different attributes, relevant to that type >>> dir ( bpy . data . objects [ 'Camera' ] . data ) [ ... , 'angle' , ... , 'clip_start' , ... , 'dof' , ... ] >>> dir ( bpy . data . objects [ 'Light' ] . data ) [ ... , 'color' , ... , 'distance' , 'energy' , ... , 'falloff_type' , ... ] Sometimes you want to iterate over all objects in a scene, but only perform some operation on a specific type of object. You can use the type attribute for checking an object's type: >>> bpy . data . objects [ 'Camera' ] . type 'CAMERA' >>> bpy . data . objects [ 'Light' ] . type 'LIGHT'","title":"Objects and object data"},{"location":"modules/advanced/python_scripting/api_summary/#native-blender-data-structures","text":"When working with the Python API will you frequently use internal Blender types that appear similar to regular Python types, like lists and dictionaries. However, the Blender types are not real native Python types and behave differently in certain aspects. For example, the different collections of scene elements (such as objects or meshes) that are available under bpy.data are of type bpy_prop_collection . This type is a combination of a Python list and a dictionary, sometimes called an ordered dictionary, as it allows indexing by both array position and key: >>> type ( bpy . data . objects ) < class ' bpy_prop_collection '> # Some of its methods match those of native Python data types >>> dir ( bpy . data . objects ) [ '__bool__' , '__contains__' , '__delattr__' , '__delitem__' , '__doc__' , '__doc__' , '__getattribute__' , '__getitem__' , '__iter__' , '__len__' , '__module__' , '__setattr__' , '__setitem__' , '__slots__' , 'bl_rna' , 'find' , 'foreach_get' , 'foreach_set' , 'get' , 'items' , 'keys' , 'new' , 'remove' , 'rna_type' , 'tag' , 'values' ] # Index by position >>> bpy . data . objects [ 0 ] bpy . data . objects [ 'Camera' ] # Index by key >>> bpy . data . objects [ 'Camera' ] bpy . data . objects [ 'Camera' ] # (key, value) pairs >>> bpy . data . objects . items () [( 'Camera' , bpy . data . objects [ 'Camera' ]), ( 'Cube' , bpy . data . objects [ 'Cube' ]), ( 'Light' , bpy . data . objects [ 'Light' ])] Note that the position of an item in the collection, and hence its index, can change during a Blender session.","title":"Native Blender data structures"},{"location":"modules/advanced/python_scripting/api_summary/#inspecting-values","text":"One of the more annoying aspects when working in the Blender Python Console inspecting these kinds of values is that the elements in a bpy_prop_collection (or other Blender types) aren't printed by default, this in contrast to a regular Python dictionary. You need to, for example, cast to a list or call its values() method: # Regular Python dict, prints both keys and values >>> d = dict ( a = 1 , b = 2 , c = 3 ) >>> d { 'a' : 1 , 'b' : 2 , 'c' : 3 } # No items printed >>> bpy . data . objects < bpy_collection [ 3 ], BlendDataObjects > # values() returns a list, so gets printed in detail >>> type ( bpy . data . objects . values ()) < class ' list '> >>> bpy . data . objects . values () [ bpy . data . objects [ 'Camera' ], bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Light' ]] # Difference in list() result: >>> list ( d ) [ 'a' , 'b' , 'c' ] # Returns dict *keys* >>> list ( bpy . data . objects ) [ bpy . data . objects [ 'Camera' ], bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Light' ]] # Returns collection *values* The choice for not printing the values inside a bpy_prop_collection is (most likely) that in many cases the collection will contain large numbers of objects, so printing them all would not be too useful, or might even make the UI non-responsive for a short time.","title":"Inspecting values"},{"location":"modules/advanced/python_scripting/api_summary/#data-organization","text":"In certain cases Blender uses a more elaborate data structure in cases where you might except low-level values, like lists. For example, the set of vertices that make up a mesh are only accessible as a collection of MeshVertex objects: >>> m bpy . data . meshes [ 'Cube' ] >>> type ( m . vertices ) < class ' bpy_prop_collection '> >>> len ( m . vertices ) 8 >>> m . vertices [ 0 ] bpy . data . meshes [ 'Cube' ] . vertices [ 0 ] >>> type ( m . vertices [ 0 ]) < class ' bpy . types . MeshVertex '> >>> dir ( m . vertices [ 0 ]) [ '__doc__' , '__module__' , '__slots__' , 'bevel_weight' , 'bl_rna' , 'co' , 'groups' , 'hide' , 'index' , 'normal' , 'rna_type' , 'select' , 'undeformed_co' ] # Vertex coordinate (object space) >>> m . vertices [ 0 ] . co Vector (( 1.0 , 1.0 , 1.0 )) # Vertex normal >>> m . vertices [ 0 ] . normal Vector (( 0.5773491859436035 , 0.5773491859436035 , 0.5773491859436035 )) The reason for this is that there's several types of data associated with a single vertex, which are all centralized in a MeshVertex object. In short, Blender uses a so-called array-of-structs design. The alternative design choice would have been to have separate arrays for vertex coordinates, vertex normals, etc (which would be a struct-of-arrays design).","title":"Data organization"},{"location":"modules/advanced/python_scripting/api_summary/#vertices-and-matrices","text":"The example above also shows that even a vertex coordinate is not accessed as a low-level Python data type, like a tuple, but by the Vector type (which is in the mathutils module). This has the advantage of providing many useful methods for operating on vector values: >>> v = m . vertices [ 0 ] . normal >>> v Vector (( 0.5773491859436035 , 0.5773491859436035 , 0.5773491859436035 )) >>> v . length 0.999998137353116 # Return a new vector that's orthogonal >>> w = v . orthogonal () >>> w Vector (( 0.5773491859436035 , 0.5773491859436035 , - 1.154698371887207 )) # Dot product (should be zero as v and w are orthogonal) >>> v . dot ( w ) 0.0 # Note: v*w is element-wise product, not dot product! >>> v * w Vector (( 0.3333320915699005 , 0.3333320915699005 , - 0.666664183139801 )) # Cross product between two vectors >>> v . cross ( w ) Vector (( - 0.9999963045120239 , 0.9999963045120239 , 0.0 )) # Swizzling (returning vector elements in a different order) >>> w Vector (( 0.5773491859436035 , 0.5773491859436035 , - 1.154698371887207 )) >>> w . zxy Vector (( - 1.154698371887207 , 0.5773491859436035 , 0.5773491859436035 )) The builtin mathutils module contains many useful data types and methods for working with 3D data, including vectors and matrices, but also different methods for working with transformations (like quaternion) and colors spaces. # Transformation matrix for an object with uniform scale 2 and # translation in Z of 3. These values will match with the Transform UI area >>> o bpy . data . objects [ 'Cube' ] >>> o . matrix_world Matrix ((( 2.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 2.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 2.0 , 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # Create a rotation matrix >>> m = Matrix . Rotation ( radians ( 90.0 ), 4 , 'X' ) >>> m Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 7.549790126404332e-08 , - 1.0 , 0.0 ), ( 0.0 , 1.0 , 7.549790126404332e-08 , 0.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) >>> v = Vector (( 1 , 2 , 3 )) # Transform the vector using the matrix. Note the different outcomes # depending on the multiplication order. >>> m @ v Vector (( 1.0 , - 2.999999761581421 , 2.000000238418579 )) >>> v @ m Vector (( 1.0 , 3.000000238418579 , - 1.999999761581421 )) # Also, a 3-vector is assumed to have a fourth element equal to *one* when # multiplying with a matrix: >>> m = Matrix . Translation (( 4 , 5 , 6 )) >>> m Matrix ((( 1.0 , 0.0 , 0.0 , 4.0 ), ( 0.0 , 1.0 , 0.0 , 5.0 ), ( 0.0 , 0.0 , 1.0 , 6.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) >>> m @ Vector (( 1 , 2 , 3 )) Vector (( 5.0 , 7.0 , 9.0 )) >>> m @ Vector (( 1 , 2 , 3 , 0 )) Vector (( 1.0 , 2.0 , 3.0 , 0.0 ))","title":"Vertices and matrices"},{"location":"modules/advanced/python_scripting/api_summary/#selections","text":"In a lot of cases you want to operate on a set of objects. You can access (read only) the current selection with bpy.context.selected_objects : >>> bpy . context . selected_objects [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Plane' ]] Changing the current selection can be done in several ways. Control over selection state per object can be controlled with the select_get() and select_set() methods: >>> bpy . context . selected_objects [] >>> bpy . data . objects [ 'Camera' ] . select_get () False >>> bpy . data . objects [ 'Camera' ] . select_set ( True ) >>> bpy . context . selected_objects [ bpy . data . objects [ 'Camera' ]] The full selection set can also be changed: # Select all visible objects >>> bpy . ops . object . select_all ( action = 'SELECT' ) # Deselect all objects >>> bpy . ops . object . select_all ( action = 'DESELECT' ) # Toggle the selection state for each object >>> bpy . ops . object . select_all ( action = 'TOGGLE' ) Note that the default mode for bpy.ops.object.select_all() when not specified is TOGGLE . Also note that the selection methods above operate only on objects that are currently visible objects in the scene (in terms of the outliner eye icon), just like for the selection hotkeys (like A ) in the 3D viewport.","title":"Selections"},{"location":"modules/advanced/python_scripting/api_summary/#often-used-values-and-operations","text":"","title":"Often used values and operations"},{"location":"modules/advanced/python_scripting/api_summary/#scene","text":"Current scene: bpy.context.scene (read-only)","title":"Scene"},{"location":"modules/advanced/python_scripting/api_summary/#objects","text":"Active object: bpy.context.active_object (read-only) Selected objects: bpy.context.selected_objects (read-only) Delete selected objects: bpy.ops.object.delete()","title":"Objects"},{"location":"modules/advanced/python_scripting/api_summary/#camera","text":"Active camera object: Scene.camera (this is the camera object , not camera object data ) Type: Camera.type (\"PERSP\", \"ORTHO\", ...) Focal length: Camera.lens (in mm) Clipping distances: Camera.clip_start , Camera.clip_end","title":"Camera"},{"location":"modules/advanced/python_scripting/api_summary/#render-settings","text":"Image resolution: Width: Scene.render.settings.resolution_x Height: Scene.render.settings.resolution_y Percentage: Scene.render.settings.resolution_percentage Output file: Scene.render.filepath Image output type: Scene.render.image_settings.file_format (\"PNG\", \"JPEG\", ...) Number of samples per pixel (Cycles): Scene.cycles.samples","title":"Render settings"},{"location":"modules/advanced/python_scripting/api_summary/#animation","text":"Current frame Scene.frame_current Frame range: Scene.frame_start , Scene.frame_end Frame rate: Scene.render.fps","title":"Animation"},{"location":"modules/advanced/python_scripting/api_summary/#object-transformations","text":"The matrix_world attribute of an Object contains the object-to-world transform that places the object in the 3D scene: >>> o = bpy . context . active_object >>> o bpy . data . objects [ 'Cube' ] >>> o . matrix_world Matrix ((( 1.3376139402389526 , 0.0 , 0.0 , 0.3065159320831299 ), ( 0.0 , 1.3376139402389526 , 0.0 , 2.2441697120666504 ), ( 0.0 , 0.0 , 1.3376139402389526 , 1.2577730417251587 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) Comparing this matrix with the values set in the Transform panel, you can see the location is stored in the right-most column of the matrix and the scaling along the diagonal. If there was a rotation set on this object some of these values would not be as recognizable anymore. The location, rotation and scale values can also be inspected and set separately: >>> o . location Vector (( 0.3065159320831299 , 2.2441697120666504 , 1.2577730417251587 )) >>> o . rotation_euler Euler (( 0.0 , 0.0 , 0.0 ), 'XYZ' ) >>> o . scale Vector (( 1.3376139402389526 , 1.3376139402389526 , 1.3376139402389526 )) >>> o . location = ( 1 , 2 , 3 ) # Needs value in radians >>> o . rotation_euler . x = radians ( 45 ) >>> o . scale = ( 2 , 1 , 1 ) >>> o . matrix_world Matrix ((( 2.0 , 0.0 , 0.0 , 1.0 ), ( 0.0 , 0.7071067690849304 , - 0.7071067690849304 , 2.0 ), ( 0.0 , 0.7071067690849304 , 0.7071067690849304 , 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) See the section on parenting below for some subtle effects on transformations in cases object parenting is used.","title":"Object transformations"},{"location":"modules/advanced/python_scripting/api_summary/#geometry-coordinates","text":"Mesh geometry in Blender stores vertex coordinates (and other geometric information) in object-space coordinates. But a mesh (or object in general) will usually get transformed to a specific position, scaling and orientation in the scene. As described above the net transform from object-space to world-space coordinates, also called the object-to-world transform, is available through matrix_world . In cases where you need to have access to geometric data in world-space , say vertex coordinates, you need to apply the matrix_world transform manually. For example, given the cube transformed as shown above, with vertex 7 selected (visible bottom-left in the image below): >>> o bpy . data . objects [ 'Cube' ] >>> m = o . data >>> o . matrix_world Matrix ((( 1.3376139402389526 , 0.0 , 0.0 , 0.3065159320831299 ), ( 0.0 , 1.3376139402389526 , 0.0 , 2.2441697120666504 ), ( 0.0 , 0.0 , 1.3376139402389526 , 1.2577730417251587 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # The object-space coordinate of this vertex >>> m . vertices [ 7 ] . co Vector (( - 1.0 , - 1.0 , - 1.0 )) # The world-space coordinate of this vertex, which matches # what the Transform UI shows. Note the Global display mode # select in the UI, if we select Local if will show (-1, -1, -1). >>> o . matrix_world @ m . vertices [ 7 ] . co Vector (( - 1.0310980081558228 , 0.9065557718276978 , - 0.07984089851379395 ))","title":"Geometry coordinates"},{"location":"modules/advanced/python_scripting/api_summary/#api-quirks","text":"Working with the Blender Python API has some peculiarities compared to your average Python scripting. These have to do with the way the API is structured, but also how it interacts with the Blender internals. The API manual contains a lengthy page on some gotchas, but here we list some of the common ones.","title":"API quirks"},{"location":"modules/advanced/python_scripting/api_summary/#object-modes","text":"An object is always in one of several modes. These modes are the same ones you work with in the UI: Object mode, Edit mode, etc. The current mode for an object can be retrieved through the mode property: >>> o = bpy . data . objects [ 'Cube' ] >>> o . mode 'OBJECT' # <enter edit mode with TAB> >>> o . mode 'EDIT' Depending on the current mode of a mesh object certain data might not be up-to-date or even unavailable when accessing it through the Python API , this is especially true when an object is in Edit Mode. This is because the edit mode uses its own copy of the data to let you edit, which is synced with the underlying mesh data when going in and out of edit mode. See here for the relevant section in the API docs. An example continuing with the Cube mesh above: >>> o . mode 'OBJECT' >>> m = o . data >>> m bpy . data . meshes [ 'Cube' ] # Check UV map data >>> len ( m . uv_layers [ 0 ] . data ) 24 # <enter edit mode with TAB> >>> o . mode 'EDIT' # UV map data now empty... >>> len ( m . uv_layers [ 0 ] . data ) 0 In most cases when working on low-level data such as mesh geometry you want the object to be in object mode (or use the bmesh module when you need the object be in edit mode). It's usually a good idea to add a check at the top of your script to verify the current mode is what you expect: o = bpy . context . active_object if o . mode != 'OBJECT' : raise ValueError ( 'Active object needs to be in object mode!' ) There are alternatives for still allowing a mesh to be in edit-mode when accessing its data from a script, see the API docs for details.","title":"Object modes"},{"location":"modules/advanced/python_scripting/api_summary/#interrupting-long-running-scripts","text":"During script development you might get in a situation where your code is stuck in a loop, or takes much longer than you like. Interrupting a running script can usually be done by pressing Ctrl-C in the terminal console window : >>> while True : ... pass ... # Uh oh, execution stuck in a loop and the UI will now have become unresponsive # Pressing Ctrl-C in the terminal console window interrupts script execution, # as it raises a KeyboardInterrupt Traceback ( most recent call last ): File \"<blender_console>\" , line 2 , in < module > KeyboardInterrupt","title":"Interrupting (long-running) scripts"},{"location":"modules/advanced/python_scripting/api_summary/#interaction-with-the-undo-system","text":"When you undo certain operations Blender might re-create certain data, which might cause existing references to the original data to become invalid. This can be especially noticeable when working interactively in the Python Console. For example, with a cube object as active object in the 3D viewport: # The Cube is the active object >>> bpy . context . active_object bpy . data . objects [ 'Cube' ] # Save a reference to it >>> o = bpy . context . active_object # <Grab the object in the 3D viewport and move it somewhere else> # Object reference still valid >>> o bpy . data . objects [ 'Cube' ] # <Undo the object translation in the 3D viewport> # Object reference has now become invalid >>> o < bpy_struct , Object invalid > # Reason: object referenced under name 'Cube' has changed >>> bpy . data . objects [ 'Cube' ] == o False >>> id ( o ) 140543077302976 >>> id ( bpy . data . objects [ 'Cube' ]) 140543077308608 # Will need to reacquire active object, or consistently use bpy.data.objects['Cube'] >>> o = bpy . context . active_object >>> o bpy . data . objects [ 'Cube' ]","title":"Interaction with the Undo system"},{"location":"modules/advanced/python_scripting/api_summary/#operators","text":"A special class of important API routines are the so-called operators . These are usually higher-level operations, such as adding a new cube mesh, deleting the current set of selected objects or running a file importer. As noted above many parts of the Blender UI are set up with Python scripts and in a lot of cases the operations you perform in the UI through menu actions or shortcut keys will simply call the relevant operator from Python to do the actual work. The Info area will show most operators as they get execute, but you can also check when the Python Tooltips are enabled (see above ) what API call is made for a certain UI element. For example, adding a plane mesh through the Add menu will call the operator bpy.ops.mesh.primitive_plane_add() , as the tooltip shows: You can simply call the operator directly from Python to add a plane in exactly the same way as with the menu option: >>> bpy . data . objects . values () [] >>> bpy . ops . mesh . primitive_plane_add () { 'FINISHED' } # A plane mesh is now added to the scene >>> bpy . data . objects . values () [ bpy . data . objects [ 'Plane' ]] Many of the operators take parameters, to influence the results. For example, with bpy.ops.mesh.primitive_plane_add() you can set the initial size and location of the plane (see the API docs for all the parameters): >>> bpy . ops . mesh . primitive_plane_add ( size = 3 , location = ( 1 , 2 , 3 )) { 'FINISHED' } Info Note that operator parameters can only be passed using keyword arguments .","title":"Operators"},{"location":"modules/advanced/python_scripting/api_summary/#operator-context","text":"This is all very nice and powerful, but operators have a few inherent properties that can make them tricky to work with. An operator's execution crucially depends on the context in which it is called, where it gets most of the data it needs. As shown above simple parameter values can usually be passed, but values like the objects to operate on are retrieved implicitly. For example, to join a set of mesh objects into a single one you can call the operator bpy.ops.object.join() . But the current context needs to be correctly set for the operator to work: # We have no objects selected >>> bpy . context . selected_objects [] >>> bpy . ops . object . join () Warning : Active object is not a selected mesh { 'CANCELLED' } # After selecting 3 objects >>> bpy . context . selected_objects [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Cube.001' ], bpy . data . objects [ 'Cube.002' ]] # Now it works >>> bpy . ops . object . join () { 'FINISHED' } As can be seen above an operator only returns a value indicating the execution status. When calling the operator in the Python Console as above some extra info is printed. But when calling operators from scripts the status return value is all you have to go on, as the extra message isn't printed when the script is executed. And in some cases the reason an operator fails can be quite unclear: >>> bpy . context . selected_objects [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Camera' ]] >>> bpy . ops . mesh . intersect_boolean () Traceback ( most recent call last ): File \"<blender_console>\" , line 1 , in < module > File \"/usr/share/blender/2.92/scripts/modules/bpy/ops.py\" , line 132 , in __call__ ret = _op_call ( self . idname_py (), None , kw ) RuntimeError : Operator bpy . ops . mesh . intersect_boolean . poll () failed , context is incorrect This merely shows that the so-called poll function failed. The poll function is used by operators to determine if they can execute in the current context, by checking certain preconditions on things like the selected object(s), the type of data or an object mode. In this case the bpy.ops.mesh.intersect_boolean() operator doesn't perform a boolean intersection on multiple meshes, but only on the faces of a single object in edit mode, but you can't tell from the error message (nor does the documentation make that clear): To actually perform a boolean intersection on two objects from a Python script requires us to do what we would be do in the UI: add a Boolean modifier on one of the objects and set its parameters. We could take advantage of the Python Tooltips to see which operator we need: This would suggest that using bpy.ops.modifier_add(type='BOOLEAN') would be what we need, but then setting the required parameters on the modifier (i.e. the object to subtract) would become tricky. So for a boolean operation, and setting object modifiers in general, there's an easier way: >>> o = bpy . data . objects [ 'Cube' ] # Add a modifier on the object and set its parameters >>> mod = o . modifiers . new ( name = 'boolmod' , type = 'BOOLEAN' ) >>> mod . object = bpy . data . objects [ 'Cube.001' ] >>> mod . operation = 'DIFFERENCE' # At this point the modifier is all set up. We hide # the object we subtract to make the boolean result visible. >>> bpy . data . objects [ 'Cube.001' ] . hide_viewport = True Unfortunately, certain operations can only be performed by calling operators. So there's a good chance that you will need to use them at some point when doing Python scripting. Hopefully this section gives some clues as how to work with them. See this section for more details on all the above subtleties and issues relating to working with operators. The bpy.ops documentation also contains useful information on operators, including how to override an operator's implicit context with values you set yourself.","title":"Operator context"},{"location":"modules/advanced/python_scripting/api_summary/#meshes","text":"One of the more common scene data types to work with from Python are 3D meshes. Meshes in Blender can contain polygons of an arbitrary number of vertices (so-called N-gons), can contain wire edges and support extra layers of data, such as vertex colors and UV coordinates. We go into a fair amount of detail on how to create and access mesh data, in several ways. As usual, the Blender API docs on the Mesh type contain many more details, but we feel the discussion below is a good summary to get you started for many use cases.","title":"Meshes"},{"location":"modules/advanced/python_scripting/api_summary/#creating-a-mesh-high-level","text":"As shown earlier the Mesh.from_pydata(vertices, edges, faces) method allows a simple and high-level way of creating a mesh. This method doesn't offer full control over the created mesh and isn't very fast for large meshes, but it can be good enough in a lot of cases. It takes three lists of values, or actually, any Python iterable that matches the expected form: vertices: a sequence of float triples, e.g. [(1.0, 2.0, 3.0), (4, 5, 6), ...] edges: a sequence of integer pairs (vertex indices), that define edges by. If [] is passed edges are inferred from polygons faces: a sequence of one or more polygons, each defined as a sequence of 3 or more vertex indices. E.g. [(0, 1, 2), (1, 2, 3, 4), ...] Note The choice of how the mesh data is passed might incur an overhead in memory usage and processing time, especially when regular Python data structures, like lists, are used. An alternative would be to pass NumPy arrays. For the examples below we assume that no explicit list of edges is passed. Edges will then be created implicitly based on the polygons specified, which is usually what is preferred. We discuss explicitly specifying edges below . An example of creating a simple mesh: # Create a mesh consisting of 3 polygons using 6 vertices vertices = [ ( 0 , 0 , 0 ), ( 2 , 0 , 0 ), ( 2 , 2 , 0.2 ), ( 0 , 2 , 0.2 ), ( 1 , 3 , 1 ), ( 1 , - 1 , - 1 ), ] polygons = [ ( 0 , 1 , 2 , 3 ), # Quad ( 4 , 3 , 2 ), # Triangle ( 0 , 5 , 1 ) # Triangle ] m = bpy . data . meshes . new ( name = 'my mesh' ) m . from_pydata ( vertices , [], polygons ) At this point we have created a new Mesh Python object, which corresponds to Object Data of type Mesh. Object Data cannot be directly added to a scene, but needs to be referenced by a 3D Object: # Create an object referencing the mesh data o = bpy . data . objects . new ( name = 'my mesh' , object_data = m ) # Add the object to the scene bpy . context . scene . collection . objects . link ( o ) The resulting mesh and outliner entry looks like this:","title":"Creating a mesh (high-level)"},{"location":"modules/advanced/python_scripting/api_summary/#careful-invalid-data","text":"Note that it is possible to set up a mesh with invalid/inconsistent data when setting the underlying arrays manually, as is the case here. This can cause weird behaviour or even crashes. For example: # 3 vertices vertices = [ ( 0 , 0 , 0 ), ( 1 , 1 , 1 ), ( - 1 , 2 , - 1 ) ] # Invalid vertex index 3 used! polygons = [ ( 0 , 1 , 2 , 3 ) ] m = bpy . data . meshes . new ( name = 'my invalid mesh' ) m . from_pydata ( vertices , [], polygons ) o = bpy . data . objects . new ( name = 'my invalid mesh' , object_data = m ) bpy . context . scene . collection . objects . link ( o ) When executing the above code a new mesh is added to the scene, but it will show as a triangle in the 3D viewport, instead of a quad. And even though that doesn't appear to be unreasonable behaviour in this case Blender will crash if we subsequently enter edit mode on the mesh! So the lesson here is to be careful when specifying geometry using these low-level API calls. This actually applies to all parts of the Blender Python API in general. In this case, to make sure a created mesh has valid data we can use the validate() method on a Mesh . This will check the mesh data and remove any invalid values, e.g. by deleting the polygon using non-existent vertex index 3 above. This might not result in a mesh that matches what you want based on the data, but at least you can detect this situation and handle it without Blender crashing. The validate() method has two issues to be aware of: The method returns True in case the mesh does not validate, i.e. when it has issues. More specifically, it returns True when changes were made to the mesh data to remove invalid values. It will only report on the specific issues found when called with validate(verbose=True) and then will only output to the console. But it is still a good idea to always validate a mesh when creating it manually: ... m = bpy . data . meshes . new ( name = 'my invalid mesh' ) m . from_pydata ( vertices , [], polygons ) if m . validate ( verbose = True ): print ( 'Mesh had issues and has been altered! See console output for details' ) In the example of the invalid mesh data above this results in these message being printed in the console output: ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:351 BKE_mesh_validate_arrays: Edge 0: v2 index out of range, 3 ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:351 BKE_mesh_validate_arrays: Edge 3: v2 index out of range, 3 ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:605 BKE_mesh_validate_arrays: Loop 3 has invalid vert reference (3) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 0 is unused. ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 1 is unused. ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 2 is unused. ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:782 BKE_mesh_validate_arrays: Loop 3 is unused. After validate() returns we can see in this case that invalid data was indeed removed: >>> vertices = [ ( 0 , 0 , 0 ), ( 1 , 1 , 1 ), ( - 1 , 2 , - 1 ) ] >>> polygons = [ ( 0 , 1 , 2 , 3 ) ] >>> m = bpy . data . meshes . new ( name = 'my invalid mesh' ) >>> m . from_pydata ( vertices , [], polygons ) >>> len ( m . polygons ) 1 >>> len ( m . edges ) 4 >>> len ( m . vertices ) 3 >>> m . validate () True >>> len ( m . polygons ) 0 >>> len ( m . edges ) 2 >>> len ( m . vertices ) 3","title":"Careful: invalid data"},{"location":"modules/advanced/python_scripting/api_summary/#creating-a-mesh-low-level","text":"A second, and more flexible, way of creating a mesh is using low-level calls for setting the necessary data arrays directly on a Mesh object. This is especially useful in combination with NumPy arrays, as this allows the creation of large meshes with relatively high performance and low memory overhead. Meshes in Blender are stored using 4 arrays, as attributes of the bpy.types.Mesh type: vertices : vertex locations, each specified by 3 floats loops : contains the vertex indices used for defining polygons of a mesh, each polygon as a sequence of indices in the vertices array polygons : defines the start index of each polygon as an index in loops , plus the length of each polygon in number of vertices edges : defines the edges of the mesh, using two vertex indices per edge So to create a mesh at this level we need to set up the necessary values for these arrays. Here, we create the same mesh as in the previous section, using NumPy arrays for storing the data. # Vertices (8): x1 y1 z1 x2 y2 z2 ... vertices = numpy . array ([ 0 , 0 , 0 , 2 , 0 , 0 , 2 , 2 , 0.2 , 0 , 2 , 0.2 , 1 , 3 , 1 , 1 , - 1 , - 1 , 0 , - 2 , - 1 , 2 , - 2 , - 1 ], dtype = numpy . float32 ) # # Polygons, defined in loops # # List of vertex indices of all loops combined vertex_index = numpy . array ([ 0 , 1 , 2 , 3 , # Quad 4 , 3 , 2 , # Triangle 0 , 5 , 1 # Triangle ], dtype = numpy . int32 ) # For each polygon the start of its indices in vertex_index loop_start = numpy . array ([ 0 , 4 , 7 ], dtype = numpy . int32 ) # Length of each polygon in number of vertices loop_total = numpy . array ([ 4 , 3 , 3 ], dtype = numpy . int32 ) We additionally also specify texture coordinates and vertex colors. This is something that is not possible with the high-level from_pydata() API shown above. Note that we need to specify these values per vertex per polygon loop . # Texture coordinates per vertex per polygon loop uv_coordinates = numpy . array ([ 0 , 0 , 1 , 0 , 1 , 1 , 0 , 1 , # Quad 0.5 , 1 , 0 , 0 , 1 , 0 , # Triangle 0 , 1 , 0.5 , 0 , 1 , 1 # Triangle ], dtype = numpy . float32 ) # Vertex color (RGBA) per vertex per polygon loop vertex_colors = numpy . array ([ 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 1 , 0 , 1 , 0 , 1 , 0 , 0 , 1 , 1 , ], dtype = numpy . float32 ) Next, we create a new mesh using the above arrays: num_vertices = vertices . shape [ 0 ] // 3 num_vertex_indices = vertex_index . shape [ 0 ] num_loops = loop_start . shape [ 0 ] m = bpy . data . meshes . new ( name = 'my detailed mesh' ) # Vertices m . vertices . add ( num_vertices ) m . vertices . foreach_set ( 'co' , vertices ) # Polygons m . loops . add ( num_vertex_indices ) m . loops . foreach_set ( 'vertex_index' , vertex_index ) m . polygons . add ( num_loops ) m . polygons . foreach_set ( 'loop_start' , loop_start ) m . polygons . foreach_set ( 'loop_total' , loop_total ) # Create UV coordinate layer and set values uv_layer = m . uv_layers . new ( name = 'default' ) uv_layer . data . foreach_set ( 'uv' , uv_coordinates ) # Create vertex color layer and set values vcol_layer = m . vertex_colors . new () vcol_layer . data . foreach_set ( 'color' , vertex_colors ) # Done, update mesh object m . update () # Validate mesh if m . validate ( verbose = True ): print ( 'Mesh data did not validate!' ) # Create an object referencing the mesh data o = bpy . data . objects . new ( name = 'my detailed mesh' , object_data = m ) # Add the object to the scene bpy . context . scene . collection . objects . link ( o ) Note Passing a multi-dimensional NumPy array directly to foreach_set() will not work: >>> vertices = numpy . array ([ ... ( 0 , 0 , 0 ), ( 2 , 0 , 0 ), ( 2 , 2 , 0.2 ), ( 0 , 2 , 0.2 ), ... ( 1 , 3 , 1 ), ( 1 , - 1 , - 1 ), ( 0 , - 2 , - 1 ), ( 2 , - 2 , - 1 ) ... ], 'float32' ) >>> vertices . shape ( 8 , 3 ) >>> m = bpy . data . meshes . new ( name = 'my detailed mesh' ) >>> m . vertices . foreach_set ( 'co' , vertices ) Traceback ( most recent call last ): File \"<blender_console>\" , line 1 , in < module > RuntimeError : internal error setting the array However, passing a flattened array does work: >>> m . vertices . foreach_set ( 'co' , vertices . flatten ()) >>> [ v . co for v in mesh . vertices ] [ Vector (( 0.0 , 0.0 , 0.0 )), Vector (( 2.0 , 0.0 , 0.0 )), Vector (( 2.0 , 2.0 , 0.20000000298023224 )), Vector (( 0.0 , 2.0 , 0.20000000298023224 )), Vector (( 1.0 , 3.0 , 1.0 )), Vector (( 1.0 , - 1.0 , - 1.0 )), Vector (( 0.0 , - 2.0 , - 1.0 )), Vector (( 2.0 , - 2.0 , - 1.0 ))]","title":"Creating a mesh (low-level)"},{"location":"modules/advanced/python_scripting/api_summary/#specifying-edges-when-creating-a-mesh","text":"In most cases we want to create a mesh consisting of only polygons and in that case don't need to specify edges. For certain mesh objects it can be of interest to also be able to specify edges explicitly, or even to create a mesh that consists only of vertices and edges between them. Edges can be used to add line segments that are not part of polygons. We build upon the example mesh we created above by adding a set of 3 edges: # Create a mesh consisting of 3 polygons using 8 vertices, with 3 extra edges # that are not part of the polygons vertices = [ ( 0 , 0 , 0 ), ( 2 , 0 , 0 ), ( 2 , 2 , 0.2 ), ( 0 , 2 , 0.2 ), ( 1 , 3 , 1 ), ( 1 , - 1 , - 1 ), ( 0 , - 2 , - 1 ), ( 2 , - 2 , - 1 ) ] edges = [ ( 5 , 6 ), ( 6 , 7 ), ( 5 , 7 ) ] polygons = [ ( 0 , 1 , 2 , 3 ), # Quad ( 4 , 3 , 2 ), # Triangle ( 0 , 5 , 1 ) # Triangle ] m = bpy . data . meshes . new ( name = 'my mesh with edges' ) m . from_pydata ( vertices , edges , polygons ) o = bpy . data . objects . new ( name = 'my mesh with edges' , object_data = m ) bpy . context . scene . collection . objects . link ( o ) The resulting mesh and outliner entry looks like this: Note that even though we specified only 3 edges explicitly the polygons in the mesh implicitly define 8 more. These are the edges making up those polygons, with shared edges being present only once. In total this results in 11 edges in the mesh: >>> len ( m . edges ) 11 For the second, low-level, method of mesh creation edges are handled slightly different. Edges can be set explicitly by using Mesh.edges : # Vertices (8): x1 y1 z1 x2 y2 z2 ... vertices = numpy . array ([ 0 , 0 , 0 , 2 , 0 , 0 , 2 , 2 , 0.2 , 0 , 2 , 0.2 , 1 , 3 , 1 , 1 , - 1 , - 1 , 0 , - 2 , - 1 , 2 , - 2 , - 1 ], dtype = numpy . float32 ) # Extra edges (3) not defined implicitly by polygons edges = numpy . array ([ 5 , 6 , 6 , 7 , 5 , 7 ], dtype = numpy . int32 ) # # Polygons, defined in loops # # List of vertex indices of all loops combined vertex_index = numpy . array ([ 0 , 1 , 2 , 3 , # Quad 4 , 3 , 2 , # Triangle 0 , 5 , 1 # Triangle ], dtype = numpy . int32 ) # For each polygon the start of its indices in vertex_index loop_start = numpy . array ([ 0 , 4 , 7 ], dtype = numpy . int32 ) # Length of each polygon in number of vertices loop_total = numpy . array ([ 4 , 3 , 3 ], dtype = numpy . int32 ) num_vertices = vertices . shape [ 0 ] // 3 num_edges = edges . shape [ 0 ] // 2 num_vertex_indices = vertex_index . shape [ 0 ] num_loops = loop_start . shape [ 0 ] m = bpy . data . meshes . new ( name = 'detailed mesh with edges' ) # Vertices m . vertices . add ( num_vertices ) m . vertices . foreach_set ( 'co' , vertices ) # Edges m . edges . add ( num_edges ) m . edges . foreach_set ( 'vertices' , edges ) # Polygons m . loops . add ( num_vertex_indices ) m . loops . foreach_set ( 'vertex_index' , vertex_index ) m . polygons . add ( num_loops ) m . polygons . foreach_set ( 'loop_start' , loop_start ) m . polygons . foreach_set ( 'loop_total' , loop_total ) # Done, update mesh object m . update () # Validate mesh if m . validate ( verbose = True ): print ( 'Mesh data did not validate!' ) Here, we only specify the extra edges and not the polygon edges. But when we try to validate the mesh errors will be reported: ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (0, 1) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (1, 2) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (2, 3) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 0 needs missing edge (3, 0) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 1 needs missing edge (4, 3) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 1 needs missing edge (3, 2) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 1 needs missing edge (2, 4) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 2 needs missing edge (0, 5) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 2 needs missing edge (5, 1) ERROR (bke.mesh): ../source/blender/blenkernel/intern/mesh_validate.c:628 BKE_mesh_validate_arrays: Poly 2 needs missing edge (1, 0) So the polygon edges, which we did not specify, are being reported. In this case the validate() method will correct this and add the missing edges. But having errors reported for regular polygon edges makes it harder to detect any other issues with the mesh data. So the Mesh.update() method provides the option calc_edges . By default this option is False , but when set to True all edges in the mesh will be recalculated to be consistent with the available vertex indices, polygons and extra edges set. ... # Done, update mesh object and recalculate edges m . update ( calc_edges = True ) Validation now succeeds: >>> m . validate ( verbose = True ) False","title":"Specifying edges when creating a mesh"},{"location":"modules/advanced/python_scripting/api_summary/#accessing-mesh-data-object-mode","text":"Inspecting or using mesh data is straightforward. Here we use one of the meshes created with the low-level methods above and retrieve some of its data. Note that Blender provides a few values derived from the original arrays, such as loop_indices and vertices per polygon, which can be useful for certain operations. m = bpy . data . meshes [ 'my detailed mesh' ] len ( m . vertices ) => 8 len ( m . polygons ) => 3 # 2 triangles + 1 quad = 2*3 + 1*4 = 10 len ( m . loops ) => 10 # 8 implicit edges (for 2 triangles and 1 quad), shared edges only listed once len ( m . edges ) => 8 m . vertices [ 7 ] . co => Vector (( 2.0 , - 2.0 , - 1.0 )) # Coordinate m . vertices [ 7 ] . normal => Vector (( 0.6 .. , - 0.6 .. , - 0.3 .. )) # Normal m . vertices [ 7 ] . select => True # Selected (edit mode) m . polygons [ 2 ] . index => 2 # Useful in 'for p in m.polygons' m . polygons [ 2 ] . loop_start => 7 # First index in loops array m . polygons [ 2 ] . loop_total => 3 # Number of vertices in loop m . polygons [ 2 ] . loop_indices => [ 7 , 8 , 9 ] # Indices in m.loops m . loops [ 7 ] . vertex_index => 0 m . loops [ 8 ] . vertex_index => 5 m . loops [ 9 ] . vertex_index => 1 m . polygons [ 2 ] . vertices => [ 0 , 5 , 1 ] # Actual vertex indices m . polygons [ 2 ] . select => True # Selected (edit mode) m . polygons [ 2 ] . use_smooth => False # Smooth shading enabled # These are automatically computed m . polygons [ 2 ] . area => 1.4142135381698608 m . polygons [ 2 ] . normal => Vector (( 0.0 , - 0.707 ... , 0.707 ... )) m . polygons [ 2 ] . center => Vector (( 1.0 , - 0.333 ... , - 0.333 ... )) m . edges [ 0 ] . vertices => [ 2 , 3 ] # (bpy_prop_array)","title":"Accessing mesh data (object mode)"},{"location":"modules/advanced/python_scripting/api_summary/#vertex-colors","text":"A mesh can have multiple sets of vertex colors. Each set has a name and for each vertex the associated color (but see below). By default meshes created in Blender do not have a vertex color layer. >>> m bpy . data . meshes [ 'Cube' ] >>> type ( m . vertex_colors ) < class ' bpy_prop_collection '> # Create a new vertex color layer >>> vcol_layer = m . vertex_colors . new ( name = 'My vertex colors' ) >>> vcol_layer bpy . data . meshes [ 'Cube' ] . vertex_colors [ \"My vertex colors\" ] >>> len ( m . vertex_colors ) 1 # Name shown under Object Data -> Vertex Colors >>> vcol_layer . name 'My vertex colors' The vertex colors themselves are accessed through the data member: >>> type ( vcol_layer . data ) < class ' bpy_prop_collection '> >>> len ( vcol_layer . data ) 24 >>> type ( vcol_layer . data [ 0 ] . color ) < class ' bpy_prop_array '> >>> list ( vcol_layer . data [ 0 ] . color ) [ 1.0 , 1.0 , 1.0 , 1.0 ] >>> len ( m . polygons ) 6 >>> len ( m . vertices ) 8 >>> len ( m . loops ) 24 One thing to notice here is that the vertex color array has 24 entries. But the Cube object only has 8 vertices and 6 polygons. The reason the higher number of vertex colors is that Blender stores separate vertex colors per polygon . So the Cube has 6 polygons, each defined using 4 vertices, hence 6*4=24 vertex colors in total (which is the same number as the length of the loops array). This is more flexible than what most 3D file formats allow, which usually only store one color per vertex. During import Blender will duplicate those colors to set the same color for a vertex in all polygons in which it is used. An example of how to take advantage of the added flexibilit is that we can set a random color per cube face by setting each of the 4 vertex colors of a face to the same color: for i in range ( 6 ): r = random () g = random () b = random () for j in range ( 4 ): vcol_layer . data [ 4 * i + j ] . color = ( r , g , b , 1 ) A slightly more Blender-like (and robust) way to write the above code would be to take advantage of the polygon loop indices: for p in m . polygons : r = random () g = random () b = random () for i in p . loop_indices : vcol_layer . data [ i ] . color = ( r , g , b , 1 )","title":"Vertex colors"},{"location":"modules/advanced/python_scripting/api_summary/#uv-coordinates","text":"UV coordinates follow the same setup as vertex colors, but instead store a 2-tuple of floats per vertex per polygon. Note that just like for vertex colors UV coordinates are also specified per vertex per polygon . Meshes created in Blender will already have a UV map called UVMap : >>> m bpy . data . meshes [ 'Cube' ] >>> len ( m . uv_layers ) 1 >>> m . uv_layers [ 0 ] . name 'UVMap' The actual UV values are once again stored under the data member: >>> uv_map = m . uv_layers [ 0 ] >>> uv_map bpy . data . meshes [ 'Cube' ] . uv_layers [ \"UVMap\" ] >>> type ( uv_map . data ) < class ' bpy_prop_collection '> >>> len ( uv_map . data ) 24 >>> type ( uv_map . data [ 0 ]) < class ' bpy . types . MeshUVLoop '> >>> uv_map . data [ 0 ] . uv Vector (( 0.375 , 0.0 )) In general, UV maps are either set through importing or edited within Blender using the UV Editor, although there can be valid reasons for wanting to control them through the Python API.","title":"UV coordinates"},{"location":"modules/advanced/python_scripting/api_summary/#bmesh","text":"There is another method in Blender for creating meshes and accessing their data: the so-called BMesh, which is implemented by the bmesh module and its BMesh class. BMesh is especially interesting when you want to perform more complex geometric operations on an existing mesh, or build up a mesh polygon-by-polygon instead of providing the full mesh in one go as a set of arrays as shown above. Here, we only give a brief overview of BMesh and refer to the API docs for all the details. The differences of BMesh compared to working with the native mesh data structure we showed above: A BMesh holds extra data on mesh connectivity, like the neighbours of a vertex, which can be easily queried for geometric editing. The trade-off is that a BMesh will use more memory to store all this extra data, but that is usually only a limiting factor for very large meshes. It is somewhat slower to create a (large) mesh using a BMesh, as each mesh element (vertex, edge, polygon) takes a Python call to create, plus needs extra calls and Python values to set up. A BMesh cannot be used directly in a scene, it first needs to be converted or copied back to a Mesh (and so mesh data is present twice in memory at some point in time) A large set of high- and low-level geometric operations, such as merging vertices within a given distance, face splitting, edge collapsing or generating a convex hull, is provided in bpy.ops and bmesh.utils . These operations would be tedious and error prone to script manually. Here's a (verbose) example of create a BMesh from scratch that holds a single triangle and edge: import bmesh bm = bmesh . new () # Create 3 vertices v1 = bm . verts . new (( 0 , 0 , 0 )) v2 = bm . verts . new (( 1 , 0 , 1 )) v3 = bm . verts . new (( 0 , 1 , 1 )) v4 = bm . verts . new (( 1 , 1 , 1 )) # Add a triangle bm . faces . new (( v1 , v2 , v3 )) # Add a line edge bm . edges . new (( v3 , v4 )) # Done setting up the BMesh, now copy geometry to a regular Mesh m = bpy . data . meshes . new ( 'mesh' ) bm . to_mesh ( m ) # Release BMesh data, bm will no longer be usable bm . free () # Add regular Mesh as object o = bpy . data . objects . new ( 'mesh' , m ) bpy . context . scene . collection . objects . link ( o ) A BMesh can also be created from an existing Mesh , edited and then copied back to the Mesh : o = bpy . context . active_object m = o . data # Create a new BMesh and copy geometry from the Mesh bm = bmesh . new () bm . from_mesh ( m ) # Edit some geometry bm . verts . ensure_lookup_table () bm . verts [ 4 ] . co . x += 3.14 bm . faces . ensure_lookup_table () bm . faces . remove ( bm . faces [ 0 ]) # Copy back to Mesh bm . to_mesh ( m ) bm . free () If a Mesh is currently in edit mode you can still create a BMesh from it, edit that and the copy the changes back, while keeping the Mesh in edit mode: o = bpy . context . active_object m = o . data assert m . mode == 'EDIT' bm = bmesh . new () # Note the different call, i.e. NOT from_mesh() bm . from_edit_mesh ( m ) # <edit BMesh> # Update edit-mesh of Mesh bm . update_edit_mesh ( m ) bm . free () This can be useful when you're working in edit mode on a mesh and also want to run a script on it that uses BMesh, but don't want to switch in and out of edit-mode to run the script. Note that there are some things to watch out for in synchronizing BMesh state to a Mesh . Some examples of the geometric queries that you can do on a BMesh (see docs for more): bm . verts [ i ] . co # Vertex coordinate as mathutils.Vector bm . verts [ i ] . normal # Vertex normal bm . verts [ i ] . is_boundary # True if vertex is at the mesh boundary bm . verts [ i ] . is_wire # True if vertex is not connected to any faces bm . verts [ i ] . link_edges # Sequence of edges connected to this vertex bm . verts [ i ] . link_faces # Sequence of faces connected to this vertex bm . edges [ i ] . calc_length () # Length of the edge bm . edges [ i ] . is_boundary # True if edge is boundary of a face bm . edges [ i ] . is_wire # True if edge is not connected to any faces bm . edges [ i ] . is_manifold # True if edge is manifold (used in at most 2 faces) v = bm . edges [ i ] . verts [ 0 ] # Get one vertex of this edge bm . edges [ i ] . other_vert ( v ) # Get the other vertex bm . edges [ i ] . link_faces # Sequence of faces connected to this edge bm . faces [ i ] . calc_area () # Face area bm . faces [ i ] . calc_center_median () # Median center bm . faces [ i ] . edges # Sequence of edges defining this face bm . faces [ i ] . verts # Sequence of vertices defining this face bm . faces [ i ] . normal # Face normal","title":"BMesh"},{"location":"modules/advanced/python_scripting/api_summary/#materials","text":"As shown in one of the introductory exercises it is possible to use Python to create a node-based shader. In most cases using the node-based editor in the UI is the preferred option due to its interactivity, but for certain cases it can be interesting to use Python. The general workflow for this is to create the necessary shader nodes, connected them through links as needed and then set the material on the relevant mesh. # Create a new material mat = bpy . data . materials . new ( \"my material\" ) # Enable shader nodes on the material mat . use_nodes = True # Remove the default nodes nodes = mat . node_tree . nodes nodes . clear () # Add a Principled BSDF shader node and set its base color shader = nodes . new ( type = 'ShaderNodeBsdfPrincipled' ) shader . location = 0 , 300 shader . inputs [ 'Base Color' ] . default_value = ( 1 , 0 , 0 , 1 ) # Add a Material Output node node_output = nodes . new ( type = 'ShaderNodeOutputMaterial' ) node_output . location = 400 , 300 # Add a link between the nodes links = nodes . links links . new ( shader . outputs [ 'BSDF' ], node_output . inputs [ 'Surface' ]) # Add material to the mesh's material slots mesh . materials . append ( mat ) A node's inputs and outputs can be referenced by name. This can then be used to set values on inputs, or connect outputs to inputs, as shown. For example, for the Principled BSDF node above: >>> shader . inputs . keys () [ 'Base Color' , 'Subsurface' , 'Subsurface Radius' , 'Subsurface Color' , 'Metallic' , 'Specular' , 'Specular Tint' , 'Roughness' , 'Anisotropic' , 'Anisotropic Rotation' , 'Sheen' , 'Sheen Tint' , 'Clearcoat' , 'Clearcoat Roughness' , 'IOR' , 'Transmission' , 'Transmission Roughness' , 'Emission' , 'Emission Strength' , 'Alpha' , 'Normal' , 'Clearcoat Normal' , 'Tangent' ] >>> shader . outputs . keys () [ 'BSDF' ] The location attributes set above are not strictly needed if you're not going to work on the shader network in the Shader Editor in the UI. But they help to make the node network layout somewhat visually pleasing.","title":"Materials"},{"location":"modules/advanced/python_scripting/api_summary/#material-slots","text":"The last line in the Python code above adds the created material to the mesh's material slots. An object can have multiple materials assigned to it and each assigned material uses a so-called material slot. Each polygon in a mesh can only use a single material, by specifying the material index (i.e. slot) to use for that polygon. This allows different parts of a mesh to use different shaders. By default all faces in a mesh will reference material slot 0. But here's an example of a cube mesh that uses 3 different materials: Inspecting the underlying material data: # Get the mesh, as the material is linked to the mesh by default >>> o = bpy . data . objects [ 'Cube' ] >>> m = o . data # The material slots used >>> list ( m . materials ) [ bpy . data . materials [ 'red' ], bpy . data . materials [ 'black-white checkered' ], bpy . data . materials [ 'voronoi' ]] # Polygon -> slot index >>> m . polygons [ 0 ] . material_index 2 >>> m . polygons [ 1 ] . material_index 0 >>> m . polygons [ 2 ] . material_index 0 >>> m . polygons [ 3 ] . material_index 0 >>> m . polygons [ 4 ] . material_index 1 >>> m . polygons [ 5 ] . material_index 0 Material indices can be set per polygon, or set as an array in one go: # Material slot index for a single polygon m . polygons [ 0 ] . material_index = 0 # Set all polygon material indices face_materials = [ 0 , 1 , 2 , 2 , 1 , 0 ] m . polygons . foreach_set ( 'material_index' , face_materials ) # Force an update of the mesh, needed in this case m . update ()","title":"Material slots"},{"location":"modules/advanced/python_scripting/api_summary/#custom-properties","text":"Sometimes it can useful to be able to control certain values that you use in a script from the UI. The most flexible, but also most complex, approach would be write an add-on . However, in quite a few cases there's a simpler alternative if all you need to control are simple Python values, like an int, float, string or list. From Python you can set custom properties on pretty much any Blender Python data block (see here for more details) and then access those values from the UI: >>> o bpy . data . objects [ 'Cube' ] >>> o [ 'My prop' ] = 123.4 >>> o [ 'My 2nd prop' ] = ( 1 , 1 , 0.5 ) This works, of course, both ways: adding or editing a value from the UI will update the value(s) available through Python. You can then use these values in a script, for example to control a number of objects to create, set a 3D coordinate, etc. See here for more details and examples.","title":"Custom properties"},{"location":"modules/advanced/python_scripting/api_summary/#into-the-deep-end","text":"Here we go deeper into some more exotic topics, but which can be of interest with more advanced Python scripting and complex scene setups.","title":"Into the deep end..."},{"location":"modules/advanced/python_scripting/api_summary/#data-block-users-and-garbage-collection","text":"Blender uses a system based on reference-counting to decide when data-blocks have become unused and can get purged. In the short video below we show some of the details of this scheme: The video shows the Orphan Data outliner mode, but there are several modes that can be used to get detailed insight into the current state of Blender internals: The Blender File mode gives a high-level overview of a file's contents, including some of the more implicit data block types, such as Workspaces. The Data API mode provides an even more detailed view. It is actually a great way to inspect all the gory details of Blender's internal data structures. It will show all data-blocks by type and their attributes. Some attributes can be even be edited in this outliner mode. The Orphan Data mode shows data blocks that do not have any users and which will not be saved (unless they are marked to have a fake user). Some of the data-blocks you see here might not have been created by you, but are used by Blender internally, for example the Brushes. Although the video only focused on materials, the way data-block lifetime is managed using the user counts is general to all types of data-blocks in Blender. But there are subtle differences in whether a data-block is really deleted or just has a link to it removed: Whenever the term \"unlink\" is used it means that a link to that data-block is removed and its user count decreased, but the data-block itself will still be in memory. An example of this is clicking the X next to a mesh's material in the Material Properties. If the UI uses the term \"delete\" it means the data-block is deleted immediately from memory. Any data-blocks linked from the deleted data-block will have their users count decreased. An example of this is deleting a Camera object in the 3D view: the Camera object's data-block is deleted from memory, but the Camera object data data-block (containing the actual camera settings) is still in memory, which you can check in the Orphan Data mode of the outliner. The usage count of data-blocks can also be queried from Python: # Two cube meshes using the same material >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Cube' ], bpy . data . objects [ 'Cube.001' ]] >>> bpy . data . materials [ 'Material' ] . users 2 # Add a new material, set one of the cubes to use it >>> bpy . data . materials [ 'Material' ] . users 1 >>> bpy . data . materials [ 'Material.001' ] . users 1 # <Delete Cube.001 object in the UI> # Hmmm, still has a user? >>> bpy . data . materials [ 'Material.001' ] . users 1 # The reason is we deleted the Cube.001 *object*, but # the Cube.001 *mesh* is still alive (as its usage count # was merely decremented) and it still references the material >>> bpy . data . objects [ 'Cube.001' ] Traceback ( most recent call last ): File \"<blender_console>\" , line 1 , in < module > KeyError : 'bpy_prop_collection[key]: key \"Cube.001\" not found' >>> bpy . data . meshes [ 'Cube.001' ] bpy . data . meshes [ 'Cube.001' ] >>> bpy . data . meshes [ 'Cube.001' ] . users 0 >>> bpy . data . meshes [ 'Cube.001' ] . materials . values () [ bpy . data . materials [ 'Material' ]] The use_fake_user attribute of a data block controls whether a Fake user is set, similar to the checkbox in the UI. Warning In most cases you probably don't want to manually delete data blocks from a file and only use the normal UI operations for that. But it is possible for cases that need it. Truly purging a data block from Python can be done with the relevant remove() method, e.g. >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Cube' ]] >>> o = bpy . context . active_object >>> o bpy . data . objects [ 'Cube' ] >>> m = o . data >>> m bpy . data . meshes [ 'Cube' ] # Remove the Mesh data-block from the file >>> bpy . data . meshes . remove ( m ) >>> bpy . data . meshes . values () [] >>> bpy . data . objects . values () [] Note that in the case of deleting object data (in this case a Mesh) any Objects referencing that object data also get removed ! A second thing to note is the above code does not actually update the current Blender file on disk. That only happens on an explicit save action (e.g. through the File menu or using the relevant operator from Python).","title":"Data-block users and garbage collection"},{"location":"modules/advanced/python_scripting/api_summary/#a-note-on-bpydata-bpydataobjects","text":"We have been using bpy.data.objects in most examples above to access objects in the scene. This is actually not completely clean, as bpy.data.objects holds all objects in the Blender file . Usually, the distinction doesn't matter as you only have one scene, but a Blender file can hold multiple scenes, each with their own set of objects: # A file with two scenes, each with their own set of objects >>> bpy . data . scenes . values () [ bpy . data . scenes [ 'Scene' ], bpy . data . scenes [ 'Scene.001' ]] # Current scene >>> bpy . context . scene bpy . data . scenes [ 'Scene' ] # And its objects >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Bottom cube' ], bpy . data . objects [ 'Top Cube' ]] # <Select different scene> # Different current scene >>> bpy . context . scene bpy . data . scenes [ 'Scene.001' ] # And its objects >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Bottom cube.001' ], bpy . data . objects [ 'Top Cube.001' ]] # All objects in the file >>> bpy . data . objects . values () [ bpy . data . objects [ 'Bottom cube' ], bpy . data . objects [ 'Bottom cube.001' ], bpy . data . objects [ 'Top Cube' ], bpy . data . objects [ 'Top Cube.001' ]] Although objects can also be shared between scenes: # Two scenes >>> bpy . data . scenes . values () [ bpy . data . scenes [ 'Scene' ], bpy . data . scenes [ 'Scene.001' ]] # First scene, cubes are local to scene, torus is shared between scenes >>> bpy . context . scene bpy . data . scenes [ 'Scene' ] >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Torus' ], bpy . data . objects [ 'Bottom cube' ], bpy . data . objects [ 'Top Cube' ]] # Second scene, different cubes, torus is shared >>> bpy . context . scene bpy . data . scenes [ 'Scene.001' ] >>> bpy . context . scene . objects . values () [ bpy . data . objects [ 'Bottom cube.001' ], bpy . data . objects [ 'Top Cube.001' ], bpy . data . objects [ 'Torus' ]] The point here is that bpy.data.objects , and every other attribute under bpy.data , holds values of the complete Blender file . Per-scene values are available through attributes of a Scene object, e.g. bpy.context.scene.objects . For certain use cases this distinction matters.","title":"A note on bpy.data, bpy.data.objects, ..."},{"location":"modules/advanced/python_scripting/api_summary/#parenting","text":"An object's parent can be queried or set simply through its parent attribute, which needs to reference another Object (or None ). But when parenting is involved the use of transformation matrices becomes somewhat more complex. Suppose we have two cubes above each other, the top cube transformed to Z=5 and the bottom cube to Z=2: Using the 3D viewport we'll now parent the bottom cube to the top cube ( LMB click bottom cube, Shift-LMB click top cube, Ctrl-P , select Object ) and inspect the values in Python: >>> bpy . data . objects [ 'Bottom cube' ] . parent bpy . data . objects [ 'Top cube' ] # The bottom cube is still located in the scene at Z=2, # even after parenting, as is expected >>> bpy . data . objects [ 'Bottom cube' ] . matrix_world Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 2.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) If an object has a parent its matrix_local attribute will contain the transformation relative to its parent , while matrix_world will contain the resulting net object-to-world transformation. If no parent is set then matrix_local is equal to matrix_world . Let's check the bottom cube's local matrix value: # Correct, it is indeed -3 in Z relative to its parent >>> bpy . data . objects [ 'Bottom cube' ] . matrix_local Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , - 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) As already shown above the parent attribute can be used to inspect and control the parenting relationship: >>> bpy . data . objects [ 'Top cube' ] . parent # None >>> bpy . data . objects [ 'Bottom cube' ] . parent bpy . data . objects [ 'Top cube' ] # Remove parent >>> bpy . data . objects [ 'Bottom cube' ] . parent = None At this point the two cubes are no longer parented and are at Z=2 (\"Bottom cube\") and Z=5 (\"Top cube\") in the scene. But when we restore the parenting relationship from Python something funny happens 1 : # Set parent back to what it was >>> bpy . data . objects [ 'Bottom cube' ] . parent = bpy . data . objects [ 'Top cube' ] The reason for the different position of the cube called \"Bottom cube\" (which is now on top) is that when using the UI to set up a parenting relationship it does more than just setting the parent attribute of the child object. There's also something called the parent-inverse matrix. Let's inspect it and the other matrix transforms we've already seen for the current (unexpected) scene: # Identity matrix, i.e. no transform >>> bpy . data . objects [ 'Bottom cube' ] . matrix_parent_inverse Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 0.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # Hmmm, this places the \"Bottom cube\" 2 in Z *above* its parent at Z=5... >>> bpy . data . objects [ 'Bottom cube' ] . matrix_local Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 2.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # ... so it indeed ends up at Z=7 as we saw (above \"Top cube\") >>> bpy . data . objects [ 'Bottom cube' ] . matrix_world Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 7.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) So what happened here? Apparently the matrix_local matrix changed from its value of Z=-3 as we saw earlier. The answer is that when you set up a parenting relationship using the UI the parent-inverse matrix is set to the inverse of the current parent transformation (as the name suggests) while matrix_local is updated to inverse(parent.matrix_world) @ to_become_child.matrix_world . If we clear the parent value from Python and redo the parenting in the UI we can see this in the resulting transform matrices: >>> bpy . data . objects [ 'Bottom cube' ] . parent = None # <parent \"Bottom cube\" to \"Top cube\" in the UI> # Was identity, is now indeed the inverse of transforming +5 in Z >>> bpy . data . objects [ 'Bottom cube' ] . matrix_parent_inverse Matrix ((( 1.0 , - 0.0 , 0.0 , - 0.0 ), ( - 0.0 , 1.0 , - 0.0 , 0.0 ), ( 0.0 , - 0.0 , 1.0 , - 5.0 ), ( - 0.0 , 0.0 , - 0.0 , 1.0 ))) # Was Z=2, is now 2-5 >>> bpy . data . objects [ 'Bottom cube' ] . matrix_local Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , - 3.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) # Was Z=7 >>> bpy . data . objects [ 'Bottom cube' ] . matrix_world Matrix ((( 1.0 , 0.0 , 0.0 , 0.0 ), ( 0.0 , 1.0 , 0.0 , 0.0 ), ( 0.0 , 0.0 , 1.0 , 2.0 ), ( 0.0 , 0.0 , 0.0 , 1.0 ))) The reason for this behaviour is that when doing parenting in the 3D viewport you usually do not want the object that you are setting as the child to move. So the parenting matrices are adjusted accordingly when the parenting relationship is set up. But when we simply set parent from Python the matrix_local value is used as is, causing our bottom cube to suddenly move up, as it is used as the transform relative to its parent, while it actually would need a different value to stay in place. There's actually quite a bit more going on with all the different parenting options available from the UI. See this page for more details. The same thing happens when setting the parent in the UI using Object Properties > Relations > Parent \u21a9","title":"Parenting"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/","text":"Python scripting for Blender - A case study \u00b6 A scientific visualisation with Blender 1. Introduction & goals \u00b6 1.1 What we will visualise: a proto-planetary disk \u00b6 A proto-planetary disk is a disk-like structure around a newly born star. This disk is filled with dust (solid-state particles with a diameter in the order of 1 micrometer) and gas. In the course of time this dust and gas can coallesce into planets. In this case-study we will look at a model (called MCMax) of the dust in such a disk. The model calculates the temperature and density of the dust in the disk, taking the radiation and gravity of the star into account. Using the temperature and density the code can then calculate the light radiation coming from the disk as if observed with a telescope using ray-tracing. The calculations of MCMax is done iteratively and using Monte Carlo techniques. Packages of photons are emitted by the star in random directions and their wavelength sampled from the radiation distribution of the star (by default a blackbody). Using the absorption, scattering and emission properties used for the dust grains in the disk, the scattering, absorption and re-emission of the photons are calculated throughout the disk. This is used to calculate a temperature structure in the disk. This temperature is then used to adapt the starting density structure of the disk after which a new pass is done by tracking a next set of photons and adapting the density subsequenty. This is repeated until convergence is reached. The code uses a two dimentional grid in the radial and theta direction. The disk is assumed to be cylindrically symmetric around the polar axis. The grid cell size is lowered in regions where the density becomes high. 1.2 How will we visualise such a proto-planetary disk \u00b6 We would like to create a 3D model of the disk at constant density and display the temperature as colors on the surface of the model (see sketch in Fig. X). We could use this to make nice renders and animations to show the temperature structure of the disk. For this we need to pre-process the data from the model to get the spatial coordinates of the disk at a constant density. These coordinates then need to be converted into vertices, edges and faces before creating the geometry in Blender. We will then add the temperatures to the faces using vertex coloring by adding the needed shaders to the model. We will start by exploring and pre-processing the data in the next section. Figure X: Sketch of the Blender model we want to make. Indicate cutout surfaces and disk surface. Also indicate spherical and cartesian coordinates. 2. Exploring the example data \u00b6 2.1 How the model data is structured \u00b6 An example output file of modeling code MCMax is shown below. # Format number 5 # NR, NT, NGRAINS, NGRAINS2 100 100 1 1 # Spherical radius grid [cm] (middle of cell) 7479900216981.22 7479900572789.07 [...] # Theta grid [rad, from pole] (middle of cell) 9.233559849414326E-003 2.365344804038962E-002 [...] # Density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] # Temperature array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1933.54960366819 1917.22966277529 [...] # Composition array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.00000000000000 1.00000000000000 [...] # Gas density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-048 1.001753516582521E-048 [...] # Density0 array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] The file is structured in a way the scientist thought best at the time using the tools at hand. For us it is important to notice the NR and NT , which stands for number of radial and theta points respectively (NGRAINS is related to the number of different type of dust grains in the disk and we will not work with this for now). Further, the output file then lists the radius points and after that the theta points. Subsequently temperature and density values are listed by iterating over the radius and then the theta indices. The units of all the values in the MCMax output are: R[cm], Theta[radians], Density[gr/cm^3], Temperature[K]. We can make a function to read in the output file of the MCMax code like this: def readInMCMaxFile ( filepath ): denstemp_file = open ( filepath , \"r\" ) # Header information on first 3 lines header = [ denstemp_file . readline () for i in range ( 3 )] # One line contains grid information Nrad , Ntheta , nGrains , nGrains2 = [ int ( i ) for i in denstemp_file . readline () . split ()] denstemp_file . readline () # Non-data line # Read in radius grid R = [ float ( denstemp_file . readline ()) / AU for i in range ( Nrad )] denstemp_file . readline () # Non-data line # Read in theta grid Th = [ float ( denstemp_file . readline ()) / ( 2 * math . pi ) * 360 for i in range ( Ntheta )] denstemp_file . readline () # Non-data line # Read in density rho = [ [ float ( denstemp_file . readline ()) * scale_density for j in range ( Ntheta )] for i in range ( Nrad )] denstemp_file . readline () # Non-data line # Read in temperature temp = [ [ float ( denstemp_file . readline ()) for j in range ( Ntheta )] for i in range ( Nrad )] denstemp_file . readline () # Non-data line denstemp_file . close () return Nrad , Ntheta , R , Th , rho , temp Here we convert theta from radians to degrees and the radius from cm to astronomical units (AU, one times the distance between the Sun and Earth). We now have the data in lists and we are ready to process them to values we can use in Blender. 2.2 Pre-processing the data \u00b6 Converting the coordinates \u00b6 The data from the MCMax code is in spherical coordinates, while the system in Blender works with cartesian coordinates. The theta in the output is defined as the angle with the z-axis. We define phi as the angle from the x-axis. In this way we can convert from spherical coordinates to cartesian: def getCartCoord ( R , th , ph ): x = math . sin ( ph / 360 * 2 * math . pi ) * math . sin ( th / 360 * 2 * math . pi ) * R y = math . cos ( ph / 360 * 2 * math . pi ) * math . sin ( th / 360 * 2 * math . pi ) * R z = math . cos ( th / 360 * 2 * math . pi ) * R return x , y , z Figure X: Definition of coordinates. Exercise 2.1: Inspecting the data Make a plot from the datsa .... Making isosurfaces for density and other parameters \u00b6 Creating vertices and edges \u00b6 Making faces using fill_holes() \u00b6 Creating vertex colors for the temperature data \u00b6","title":"<span style=\"color:#00abe9\">Python scripting for Blender - A case study</span>"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#python-scripting-for-blender-a-case-study","text":"A scientific visualisation with Blender","title":"Python scripting for Blender - A case study"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#1-introduction-goals","text":"","title":"1. Introduction &amp; goals"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#11-what-we-will-visualise-a-proto-planetary-disk","text":"A proto-planetary disk is a disk-like structure around a newly born star. This disk is filled with dust (solid-state particles with a diameter in the order of 1 micrometer) and gas. In the course of time this dust and gas can coallesce into planets. In this case-study we will look at a model (called MCMax) of the dust in such a disk. The model calculates the temperature and density of the dust in the disk, taking the radiation and gravity of the star into account. Using the temperature and density the code can then calculate the light radiation coming from the disk as if observed with a telescope using ray-tracing. The calculations of MCMax is done iteratively and using Monte Carlo techniques. Packages of photons are emitted by the star in random directions and their wavelength sampled from the radiation distribution of the star (by default a blackbody). Using the absorption, scattering and emission properties used for the dust grains in the disk, the scattering, absorption and re-emission of the photons are calculated throughout the disk. This is used to calculate a temperature structure in the disk. This temperature is then used to adapt the starting density structure of the disk after which a new pass is done by tracking a next set of photons and adapting the density subsequenty. This is repeated until convergence is reached. The code uses a two dimentional grid in the radial and theta direction. The disk is assumed to be cylindrically symmetric around the polar axis. The grid cell size is lowered in regions where the density becomes high.","title":"1.1 What we will visualise: a proto-planetary disk"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#12-how-will-we-visualise-such-a-proto-planetary-disk","text":"We would like to create a 3D model of the disk at constant density and display the temperature as colors on the surface of the model (see sketch in Fig. X). We could use this to make nice renders and animations to show the temperature structure of the disk. For this we need to pre-process the data from the model to get the spatial coordinates of the disk at a constant density. These coordinates then need to be converted into vertices, edges and faces before creating the geometry in Blender. We will then add the temperatures to the faces using vertex coloring by adding the needed shaders to the model. We will start by exploring and pre-processing the data in the next section. Figure X: Sketch of the Blender model we want to make. Indicate cutout surfaces and disk surface. Also indicate spherical and cartesian coordinates.","title":"1.2 How will we visualise such a proto-planetary disk"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#2-exploring-the-example-data","text":"","title":"2. Exploring the example data"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#21-how-the-model-data-is-structured","text":"An example output file of modeling code MCMax is shown below. # Format number 5 # NR, NT, NGRAINS, NGRAINS2 100 100 1 1 # Spherical radius grid [cm] (middle of cell) 7479900216981.22 7479900572789.07 [...] # Theta grid [rad, from pole] (middle of cell) 9.233559849414326E-003 2.365344804038962E-002 [...] # Density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] # Temperature array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1933.54960366819 1917.22966277529 [...] # Composition array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.00000000000000 1.00000000000000 [...] # Gas density array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-048 1.001753516582521E-048 [...] # Density0 array (for ir=0,nr-1 do for it=0,nt-1 do ...) 1.001753516582521E-050 1.001753516582521E-050 [...] The file is structured in a way the scientist thought best at the time using the tools at hand. For us it is important to notice the NR and NT , which stands for number of radial and theta points respectively (NGRAINS is related to the number of different type of dust grains in the disk and we will not work with this for now). Further, the output file then lists the radius points and after that the theta points. Subsequently temperature and density values are listed by iterating over the radius and then the theta indices. The units of all the values in the MCMax output are: R[cm], Theta[radians], Density[gr/cm^3], Temperature[K]. We can make a function to read in the output file of the MCMax code like this: def readInMCMaxFile ( filepath ): denstemp_file = open ( filepath , \"r\" ) # Header information on first 3 lines header = [ denstemp_file . readline () for i in range ( 3 )] # One line contains grid information Nrad , Ntheta , nGrains , nGrains2 = [ int ( i ) for i in denstemp_file . readline () . split ()] denstemp_file . readline () # Non-data line # Read in radius grid R = [ float ( denstemp_file . readline ()) / AU for i in range ( Nrad )] denstemp_file . readline () # Non-data line # Read in theta grid Th = [ float ( denstemp_file . readline ()) / ( 2 * math . pi ) * 360 for i in range ( Ntheta )] denstemp_file . readline () # Non-data line # Read in density rho = [ [ float ( denstemp_file . readline ()) * scale_density for j in range ( Ntheta )] for i in range ( Nrad )] denstemp_file . readline () # Non-data line # Read in temperature temp = [ [ float ( denstemp_file . readline ()) for j in range ( Ntheta )] for i in range ( Nrad )] denstemp_file . readline () # Non-data line denstemp_file . close () return Nrad , Ntheta , R , Th , rho , temp Here we convert theta from radians to degrees and the radius from cm to astronomical units (AU, one times the distance between the Sun and Earth). We now have the data in lists and we are ready to process them to values we can use in Blender.","title":"2.1 How the model data is structured"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_protoplanetary_disk_scientific_model_in_Blender/#22-pre-processing-the-data","text":"","title":"2.2 Pre-processing the data"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/","text":"Python scripting for Blender - extra topics \u00b6 1. The Blender context and python scripting \u00b6 1.1 Access the Blender context \u00b6 User context: Based on what is selected by the user bpy.context.object 2 Using and making operators \u00b6 Adding an operator through classes: import bpy class SimpleOperator ( bpy . types . Operator ): bl_idname = \"object.simple_operator\" # USED IN bpy.ops.object bl_label = \"Tool Name\" # USED BY OPERATOR SEARCH (spacebar, F3) def execute ( self , context ): print ( \"Hello World\" ) return { 'FINISHED' } bpy . utils . register_class ( SimpleOperator ) Misc Blender items \u00b6 Adding a background \u00b6 Go to World Properties Click on the circle next to 'Color' and choose 'Image Texture' Change 'Repeat' into 'Clip' Click on the circle next to 'Vector' - 'default' and set it to 'Window' See also: https://henryegloff.com/how-to-render-a-background-image-in-blender-2-8-using-the-document-world-settings/","title":"<span style=\"color:#00abe9\">Python scripting for Blender - extra topics</span>"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/#python-scripting-for-blender-extra-topics","text":"","title":"Python scripting for Blender - extra topics"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/#1-the-blender-context-and-python-scripting","text":"","title":"1. The Blender context and python scripting"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/#11-access-the-blender-context","text":"User context: Based on what is selected by the user bpy.context.object","title":"1.1 Access the Blender context"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/#2-using-and-making-operators","text":"Adding an operator through classes: import bpy class SimpleOperator ( bpy . types . Operator ): bl_idname = \"object.simple_operator\" # USED IN bpy.ops.object bl_label = \"Tool Name\" # USED BY OPERATOR SEARCH (spacebar, F3) def execute ( self , context ): print ( \"Hello World\" ) return { 'FINISHED' } bpy . utils . register_class ( SimpleOperator )","title":"2 Using and making operators"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/#misc-blender-items","text":"","title":"Misc Blender items"},{"location":"modules/advanced/python_scripting/extra_and_answers/Tutorial_something_more/#adding-a-background","text":"Go to World Properties Click on the circle next to 'Color' and choose 'Image Texture' Change 'Repeat' into 'Clip' Click on the circle next to 'Vector' - 'default' and set it to 'Window' See also: https://henryegloff.com/how-to-render-a-background-image-in-blender-2-8-using-the-document-world-settings/","title":"Adding a background"},{"location":"modules/advanced/python_scripting/extra_and_answers/answers/","text":"Exercise 1: starting Blender from the console \u00b6 Find the Blender executable on the machine you are working on. Open Blender through the console. Delete the cube in the default project of Blender, what output is shown in the console? Exercise 2: running a script and rendering from the console \u00b6 Write an external script that removes the Cube object that is part of the default scene [^1] Then, from the command line and without opening the Blender GUI execute this script and render the first frame. Let it output a PNG image file in the directory of the blender file. Was the cube indeed removed from the rendered image? Extra question: is the cube removed from the blender file? Answer: import bpy bpy . data . objects [ 'Cube' ] . select_set ( True ) bpy . ops . object . delete () # OR: bpy.data.objects.remove(bpy.data.objects[\"Cube\"]) blender -b test.blend -o .//render_ -F PNG -P test.py -f 1 Exercise 3: a filled disc from scratch \u00b6 In the text above we created a triangle, now as an exercise let's create a spherical disk. First create a ring of vertices, then create edges and a face. Answer: import bpy import math X = [ math . sin ( a ) for a in [ p / 360 * 2 * math . pi for p in range ( 360 )]] Y = [ math . cos ( a ) for a in [ p / 360 * 2 * math . pi for p in range ( 360 )]] verts = [( x , y , 0 ) for x , y in zip ( X , Y )] edges = [( iv , iv + 1 ) for iv in range ( len ( verts ) - 1 )] faces = [ range ( len ( verts ))] mesh = bpy . data . meshes . new ( \"disk_mesh\" ) ob = bpy . data . objects . new ( \"disk\" , mesh ) mesh . from_pydata ( verts , edges , faces ) bpy . context . collection . objects . link ( ob ) Exercise 4: making triangles and make a vertex color layer \u00b6 Let's take the triangle we made in section 4.1, but let's add another triangle to it, attached to the first. The code would look like this: import bpy # Create a new mesh ob_name = \"triangle\" mesh = bpy . data . meshes . new ( ob_name + \"_mesh\" ) # Create a new object with the mesh ob = bpy . data . objects . new ( ob_name , mesh ) # Define some geometry verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) , ( 0 , 3 , 2 ) ] edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ), ( 1 , 3 ), ( 3 , 2 ) ] # These are indices pointing to elements in the list verts faces = [ ( 0 , 1 , 2 ), ( 1 , 3 , 2 ) ] # These are indices pointing to elements in the list verts # Add it to the mesh mesh . from_pydata ( verts , edges , faces ) # Link the object to the first collection bpy . data . collections [ 0 ] . objects . link ( ob ) Now make a vertex color layer for your triangles. Then inspect how many entries are in color_layer = mesh.vertex_colors['vert_colors'] . Why are they the same or different from the total number of vertices in the mesh? Answer: vertex_colors_name = \"vert_colors\" mesh . vertex_colors . new ( name = vertex_colors_name ) color_layer = mesh . vertex_colors [ vertex_colors_name ] >>> len ( color_layer . data ) 6 Exercise 5: coloring your triangles \u00b6 Let's take the two connected triangles of exercise 4. We will color them in two different ways, using vertex coloring and Python scripting. a) Make the first triangle (face (0,1,2)) green and the second (face (1,3,2)) red. b) Now color vertex (0,0,0) and (0,3,2) red and (0,2,0) and (0,1,2) green to make it look like in Fig.4. Answer: if exercise == \"a\" : vert_colors = [ [ 0 , 1 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 1 , 0 , 0 , 1 ], [ 1 , 0 , 0 , 1 ] , [ 1 , 0 , 0 , 1 ] ] else : vert_colors = [ [ 1 , 0 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 1 , 0 , 0 , 1 ] ] for poly in mesh . polygons : for vert_i_poly , vert_i_mesh in enumerate ( poly . vertices ): #loop_indices: vert_i_loop = poly . loop_indices [ vert_i_poly ] if exercise == \"a\" : color_layer . data [ vert_i_loop ] . color = vert_colors [ vert_i_loop ] #rgb else : color_layer . data [ vert_i_loop ] . color = vert_colors [ vert_i_mesh ] print ( poly , vert_i_poly , vert_i_mesh )","title":"Answers"},{"location":"modules/advanced/python_scripting/extra_and_answers/answers/#exercise-1-starting-blender-from-the-console","text":"Find the Blender executable on the machine you are working on. Open Blender through the console. Delete the cube in the default project of Blender, what output is shown in the console?","title":"Exercise 1: starting Blender from the console"},{"location":"modules/advanced/python_scripting/extra_and_answers/answers/#exercise-2-running-a-script-and-rendering-from-the-console","text":"Write an external script that removes the Cube object that is part of the default scene [^1] Then, from the command line and without opening the Blender GUI execute this script and render the first frame. Let it output a PNG image file in the directory of the blender file. Was the cube indeed removed from the rendered image? Extra question: is the cube removed from the blender file? Answer: import bpy bpy . data . objects [ 'Cube' ] . select_set ( True ) bpy . ops . object . delete () # OR: bpy.data.objects.remove(bpy.data.objects[\"Cube\"]) blender -b test.blend -o .//render_ -F PNG -P test.py -f 1","title":"Exercise 2: running a script and rendering from the console"},{"location":"modules/advanced/python_scripting/extra_and_answers/answers/#exercise-3-a-filled-disc-from-scratch","text":"In the text above we created a triangle, now as an exercise let's create a spherical disk. First create a ring of vertices, then create edges and a face. Answer: import bpy import math X = [ math . sin ( a ) for a in [ p / 360 * 2 * math . pi for p in range ( 360 )]] Y = [ math . cos ( a ) for a in [ p / 360 * 2 * math . pi for p in range ( 360 )]] verts = [( x , y , 0 ) for x , y in zip ( X , Y )] edges = [( iv , iv + 1 ) for iv in range ( len ( verts ) - 1 )] faces = [ range ( len ( verts ))] mesh = bpy . data . meshes . new ( \"disk_mesh\" ) ob = bpy . data . objects . new ( \"disk\" , mesh ) mesh . from_pydata ( verts , edges , faces ) bpy . context . collection . objects . link ( ob )","title":"Exercise 3: a filled disc from scratch"},{"location":"modules/advanced/python_scripting/extra_and_answers/answers/#exercise-4-making-triangles-and-make-a-vertex-color-layer","text":"Let's take the triangle we made in section 4.1, but let's add another triangle to it, attached to the first. The code would look like this: import bpy # Create a new mesh ob_name = \"triangle\" mesh = bpy . data . meshes . new ( ob_name + \"_mesh\" ) # Create a new object with the mesh ob = bpy . data . objects . new ( ob_name , mesh ) # Define some geometry verts = [ ( 0 , 0 , 0 ), ( 0 , 2 , 0 ), ( 0 , 1 , 2 ) , ( 0 , 3 , 2 ) ] edges = [ ( 0 , 1 ), ( 1 , 2 ), ( 2 , 0 ), ( 1 , 3 ), ( 3 , 2 ) ] # These are indices pointing to elements in the list verts faces = [ ( 0 , 1 , 2 ), ( 1 , 3 , 2 ) ] # These are indices pointing to elements in the list verts # Add it to the mesh mesh . from_pydata ( verts , edges , faces ) # Link the object to the first collection bpy . data . collections [ 0 ] . objects . link ( ob ) Now make a vertex color layer for your triangles. Then inspect how many entries are in color_layer = mesh.vertex_colors['vert_colors'] . Why are they the same or different from the total number of vertices in the mesh? Answer: vertex_colors_name = \"vert_colors\" mesh . vertex_colors . new ( name = vertex_colors_name ) color_layer = mesh . vertex_colors [ vertex_colors_name ] >>> len ( color_layer . data ) 6","title":"Exercise 4: making triangles and make a vertex color layer"},{"location":"modules/advanced/python_scripting/extra_and_answers/answers/#exercise-5-coloring-your-triangles","text":"Let's take the two connected triangles of exercise 4. We will color them in two different ways, using vertex coloring and Python scripting. a) Make the first triangle (face (0,1,2)) green and the second (face (1,3,2)) red. b) Now color vertex (0,0,0) and (0,3,2) red and (0,2,0) and (0,1,2) green to make it look like in Fig.4. Answer: if exercise == \"a\" : vert_colors = [ [ 0 , 1 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 1 , 0 , 0 , 1 ], [ 1 , 0 , 0 , 1 ] , [ 1 , 0 , 0 , 1 ] ] else : vert_colors = [ [ 1 , 0 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 0 , 1 , 0 , 1 ], [ 1 , 0 , 0 , 1 ] ] for poly in mesh . polygons : for vert_i_poly , vert_i_mesh in enumerate ( poly . vertices ): #loop_indices: vert_i_loop = poly . loop_indices [ vert_i_poly ] if exercise == \"a\" : color_layer . data [ vert_i_loop ] . color = vert_colors [ vert_i_loop ] #rgb else : color_layer . data [ vert_i_loop ] . color = vert_colors [ vert_i_mesh ] print ( poly , vert_i_poly , vert_i_mesh )","title":"Exercise 5: coloring your triangles"},{"location":"modules/advanced/python_scripting/old/","text":"Introduction \u00b6 In this course you will learn the basics of the Python API in Blender. You will learn how the API is structured and eventually start making some simple geometry with code. Another important part of the course is that you will work on a visualisation based on your own research or other endeavours. Course setup \u00b6 Let us briefly explain how we think you can get the most out of this course. This tutorial is set-up in such a way that you should work through it by yourself. This tutorial contains theory, exercises and links to instructional videos for you to watch. Read and watch the materials first and then do the exercises. Also try to reproduce all the steps and theory explained in this tutorial and in the videos yourself. When done, follow with the last project exercise at the end of the tutorial. You can ask questions in our Discord channel if you get stuck. During course times we also organize webinars during which you can present you project and ask for feedback. See the course website on how to join our Discord and how to register for the webinars. Blender version \u00b6 Blender as a software package is always in development, with new features and bug fixes in every release throughout the year. This also means that there might be small differences in the version of Blender you're using compared to these course notes. Here, we assume Blender 2.83 LTS About \u00b6 SURF (collaborative organisation for compute in Dutch education and research) offers courses on several topics within the PRACE Partnership . This website accompanies courses from the Visualisation team focused on using Blender , the free and open source 3D creation suite, for scientific goals. This course is organized as part of PRACE Training Centre activities. Questions and/or remarks on this course can be sent to training@surfsara.nl .","title":"Index"},{"location":"modules/advanced/python_scripting/old/#introduction","text":"In this course you will learn the basics of the Python API in Blender. You will learn how the API is structured and eventually start making some simple geometry with code. Another important part of the course is that you will work on a visualisation based on your own research or other endeavours.","title":"Introduction"},{"location":"modules/advanced/python_scripting/old/#course-setup","text":"Let us briefly explain how we think you can get the most out of this course. This tutorial is set-up in such a way that you should work through it by yourself. This tutorial contains theory, exercises and links to instructional videos for you to watch. Read and watch the materials first and then do the exercises. Also try to reproduce all the steps and theory explained in this tutorial and in the videos yourself. When done, follow with the last project exercise at the end of the tutorial. You can ask questions in our Discord channel if you get stuck. During course times we also organize webinars during which you can present you project and ask for feedback. See the course website on how to join our Discord and how to register for the webinars.","title":"Course setup"},{"location":"modules/advanced/python_scripting/old/#blender-version","text":"Blender as a software package is always in development, with new features and bug fixes in every release throughout the year. This also means that there might be small differences in the version of Blender you're using compared to these course notes. Here, we assume Blender 2.83 LTS","title":"Blender version"},{"location":"modules/advanced/python_scripting/old/#about","text":"SURF (collaborative organisation for compute in Dutch education and research) offers courses on several topics within the PRACE Partnership . This website accompanies courses from the Visualisation team focused on using Blender , the free and open source 3D creation suite, for scientific goals. This course is organized as part of PRACE Training Centre activities. Questions and/or remarks on this course can be sent to training@surfsara.nl .","title":"About"},{"location":"modules/advanced/python_scripting/old/contact/","text":"Contact & information \u00b6 What Where Course page https://surfsara-visualization.github.io/blendercourses Discord server https://discord.gg/mVjYzbm","title":"Contact & information"},{"location":"modules/advanced/python_scripting/old/contact/#contact-information","text":"What Where Course page https://surfsara-visualization.github.io/blendercourses Discord server https://discord.gg/mVjYzbm","title":"Contact &amp; information"},{"location":"modules/advanced/python_scripting/old/examples_exercises/","text":"Exercise X: making a cube from scratch \u00b6 If you blender -b test.blend -o .//render_ -F PNG -f 1","title":"Examples exercises"},{"location":"modules/advanced/python_scripting/old/examples_exercises/#exercise-x-making-a-cube-from-scratch","text":"If you blender -b test.blend -o .//render_ -F PNG -f 1","title":"Exercise X: making a cube from scratch"},{"location":"overview/about/","text":"About \u00b6 We are members of the High-Performance Computing & Visualization (HPCV) group at SURF , and are based in Amsterdam. SURF is a cooperative association of Dutch educational and research institutions in which the members combine their strengths to acquire or develop digital services, and to encourage knowledge sharing through continuous innovation. Within the HPCV group we support users of the Dutch National compute infrastructure with visualization expertise and software development, on topics such as data visualization, remote visualization, 3D modeling and rendering and use of eXtended Reality (XR) for research and education. Part of our jobs is to provide courses on topics related to visualization in HPC. This Blender course was created for the PRACE Training Center and first provided (in-person) in 2018. Paul Melis \u00b6 Paul Melis has an MSc in Computer Science from the University of Twente in The Netherlands and worked on topics in scientific visualization and VR at the University of Groningen and University of Amsterdam before joining SURFsara in 2009. At SURF he is involved in several activities related to visualization, including realizing visualization projects for end-users, teaching courses and providing user support for visualization tasks on our HPC systems. As part of the SURF innovation portfolio he leads a project on the use of extended reality (XR) for research and education. He likes to use Blender for all things 3D, but also works with Unity, ParaView and sometimes develops a bit of code in Python or C++. Casper van Leeuwen \u00b6 Casper has a MSc in Computer Science from Delft University of Technology where he graduated on the topic of medical visualization. He has been at SURFsara since 2014. He mainly works on web-based 2D/3D visualization, including Jupyter Notebooks and loves to work on Blender projects when the goal is make something look aesthetic! Besides that he also knows his way around Unity and Unreal Engine. Ben de Vries \u00b6 Ben de Vries has a PhD in Astrophysics from KU Leuven. He joined SURF in 2019. He focuses on 2D/3D visualization projects using Blender, Unity and general 3D programming.","title":"About"},{"location":"overview/about/#about","text":"We are members of the High-Performance Computing & Visualization (HPCV) group at SURF , and are based in Amsterdam. SURF is a cooperative association of Dutch educational and research institutions in which the members combine their strengths to acquire or develop digital services, and to encourage knowledge sharing through continuous innovation. Within the HPCV group we support users of the Dutch National compute infrastructure with visualization expertise and software development, on topics such as data visualization, remote visualization, 3D modeling and rendering and use of eXtended Reality (XR) for research and education. Part of our jobs is to provide courses on topics related to visualization in HPC. This Blender course was created for the PRACE Training Center and first provided (in-person) in 2018.","title":"About"},{"location":"overview/about/#paul-melis","text":"Paul Melis has an MSc in Computer Science from the University of Twente in The Netherlands and worked on topics in scientific visualization and VR at the University of Groningen and University of Amsterdam before joining SURFsara in 2009. At SURF he is involved in several activities related to visualization, including realizing visualization projects for end-users, teaching courses and providing user support for visualization tasks on our HPC systems. As part of the SURF innovation portfolio he leads a project on the use of extended reality (XR) for research and education. He likes to use Blender for all things 3D, but also works with Unity, ParaView and sometimes develops a bit of code in Python or C++.","title":"Paul Melis"},{"location":"overview/about/#casper-van-leeuwen","text":"Casper has a MSc in Computer Science from Delft University of Technology where he graduated on the topic of medical visualization. He has been at SURFsara since 2014. He mainly works on web-based 2D/3D visualization, including Jupyter Notebooks and loves to work on Blender projects when the goal is make something look aesthetic! Besides that he also knows his way around Unity and Unreal Engine.","title":"Casper van Leeuwen"},{"location":"overview/about/#ben-de-vries","text":"Ben de Vries has a PhD in Astrophysics from KU Leuven. He joined SURF in 2019. He focuses on 2D/3D visualization projects using Blender, Unity and general 3D programming.","title":"Ben de Vries"},{"location":"overview/conventions/","text":"Text conventions \u00b6 The conventions on these pages follow those used in the official Blender documentation as much as possible: Keyboard and mouse actions, menu names, literal text to enter, etc are shown in monospaced bold, e.g. X or Shift-MMB LMB = left mouse button, MMB = middle mouse button, RMB = right mouse button, Wheel = scrolling the mouse wheel Menu actions are shown as View > Cameras > Set Active Object as Camera The keyboard and mouse shortcuts for object selection, editing, view interaction, etc. work mostly the same in all Blender editors. So G to grab, X to delete, LMB to select, Shift-MMB to translate, Wheel to zoom, etc. You can hover with the mouse over pretty much any UI element to get a tooltip with a short description","title":"Text conventions"},{"location":"overview/conventions/#text-conventions","text":"The conventions on these pages follow those used in the official Blender documentation as much as possible: Keyboard and mouse actions, menu names, literal text to enter, etc are shown in monospaced bold, e.g. X or Shift-MMB LMB = left mouse button, MMB = middle mouse button, RMB = right mouse button, Wheel = scrolling the mouse wheel Menu actions are shown as View > Cameras > Set Active Object as Camera The keyboard and mouse shortcuts for object selection, editing, view interaction, etc. work mostly the same in all Blender editors. So G to grab, X to delete, LMB to select, Shift-MMB to translate, Wheel to zoom, etc. You can hover with the mouse over pretty much any UI element to get a tooltip with a short description","title":"Text conventions"},{"location":"overview/introduction.advanced/","text":"Introduction \u00b6 Welcome to the course Advanced Topics in Scientific Visualization with Blender ! This course is provided by SURF through the PRACE Training Center . We have been providing an introductory Blender course since 2018, usually twice a year, and always enjoy teaching it in-person. At the beginning of 2020 we added an advanced Blender course, in response to demand for further and more detailed course material. Due to COVID-19 we have decided to turn both these courses into fully online versions, based on positive experiences with the first advanced Blender course we provided online in 2020. While we know what works for certain aspects, others are still a bit more experimental, including the course setup . We will ask for feedback on this in the online sessions, but if you have remarks then please let us know. Course level & context \u00b6 This is our advanced Blender course, where we assume participants already have basic knowledge of Blender, preferably by following our basics course. We assume participants are familiar with the Blender user interface, basic functionality and concepts like the 3D scene, cameras, lights, materials and some basic mesh editing and animation. This course is aimed at scientists and researchers of all levels. We don't make many assumptions on use cases for Blender, but do assume the context to be an academic setting. So we won't go into creating visual effects for putting a massive CGI tornado in your backyard that scoops up your neighbours. But if you happen to write a tornado simulation for your research we will be more than happy to see how we can use Blender to make attractive visuals of the data. This doesn't mean that we only assume to apply Blender to existing scientific data. Sometimes certain concepts are best explained by creating a 3D scene, say to produce a nice looking cover image for your PhD thesis, or to illustrate or visualize a certain concept. From previous editions of the course we know many participants bring their own data and want to apply Blender to it. We encourage you to do that as well, as it will also help in providing some focus to your use of Blender. Blender version \u00b6 We currently use Blender 2.92 for this course and the materials provided. Blender as a software package is a fast moving target, usually with lots of shiny new features and bug fixes in each release. This is great, of course, but with each release usually also a lot of small tweaks and improvements are made, especially in the user interface and workflow. When the next LTS (Long-Term Support) release comes out we will update the course material where needed to provide a longer period of correct materials, as the LTS version of Blender should remain unchanged regarding UI and features for roughly 2 years. Warning Specifically for Linux users that use their Linux distribution's package of Blender: Sometimes the distro package gets built with slightly different versions of software libraries, compared to the official Blender distribution. This is known to sometimes cause different behaviour or even bugs, for example in the handling of video files by the FFmpeg library. In case you find strange issues or bugs with your distro's Blender you might want to try downloading the official Blender binaries to see if that fixes those issues. Issues with course materials \u00b6 We try to keep this course up to date to match the specific version mentioned above. But we might have missed small things. If so, please let us know through Github by reporting an issue. If you don't have a Github account, or would rather not create one, then telling us through Discord is fine as well. Prerequisites \u00b6 You will need: A system (PC or laptop) to work on. This can be a Linux, macOS or Windows system. Blender 2.92 installed on the above system. You can download it from here , or you can use your system package manager to install it. Warning It is not recommended to use a different Blender version for this course, due to possible mismatches in the user interface and functionality with the course material. Please test the Blender installation before the course starts using the instructions sent by e-mail. This will tell you if Blender is working correctly and can save you (and us) time fixing any system-related issues during the course period. Recommended: Using a 3-button mouse is preferred, as not all Blender functionality is easily used through a laptop trackpad","title":"Introduction"},{"location":"overview/introduction.advanced/#introduction","text":"Welcome to the course Advanced Topics in Scientific Visualization with Blender ! This course is provided by SURF through the PRACE Training Center . We have been providing an introductory Blender course since 2018, usually twice a year, and always enjoy teaching it in-person. At the beginning of 2020 we added an advanced Blender course, in response to demand for further and more detailed course material. Due to COVID-19 we have decided to turn both these courses into fully online versions, based on positive experiences with the first advanced Blender course we provided online in 2020. While we know what works for certain aspects, others are still a bit more experimental, including the course setup . We will ask for feedback on this in the online sessions, but if you have remarks then please let us know.","title":"Introduction"},{"location":"overview/introduction.advanced/#course-level-context","text":"This is our advanced Blender course, where we assume participants already have basic knowledge of Blender, preferably by following our basics course. We assume participants are familiar with the Blender user interface, basic functionality and concepts like the 3D scene, cameras, lights, materials and some basic mesh editing and animation. This course is aimed at scientists and researchers of all levels. We don't make many assumptions on use cases for Blender, but do assume the context to be an academic setting. So we won't go into creating visual effects for putting a massive CGI tornado in your backyard that scoops up your neighbours. But if you happen to write a tornado simulation for your research we will be more than happy to see how we can use Blender to make attractive visuals of the data. This doesn't mean that we only assume to apply Blender to existing scientific data. Sometimes certain concepts are best explained by creating a 3D scene, say to produce a nice looking cover image for your PhD thesis, or to illustrate or visualize a certain concept. From previous editions of the course we know many participants bring their own data and want to apply Blender to it. We encourage you to do that as well, as it will also help in providing some focus to your use of Blender.","title":"Course level &amp; context"},{"location":"overview/introduction.advanced/#blender-version","text":"We currently use Blender 2.92 for this course and the materials provided. Blender as a software package is a fast moving target, usually with lots of shiny new features and bug fixes in each release. This is great, of course, but with each release usually also a lot of small tweaks and improvements are made, especially in the user interface and workflow. When the next LTS (Long-Term Support) release comes out we will update the course material where needed to provide a longer period of correct materials, as the LTS version of Blender should remain unchanged regarding UI and features for roughly 2 years. Warning Specifically for Linux users that use their Linux distribution's package of Blender: Sometimes the distro package gets built with slightly different versions of software libraries, compared to the official Blender distribution. This is known to sometimes cause different behaviour or even bugs, for example in the handling of video files by the FFmpeg library. In case you find strange issues or bugs with your distro's Blender you might want to try downloading the official Blender binaries to see if that fixes those issues.","title":"Blender version"},{"location":"overview/introduction.advanced/#issues-with-course-materials","text":"We try to keep this course up to date to match the specific version mentioned above. But we might have missed small things. If so, please let us know through Github by reporting an issue. If you don't have a Github account, or would rather not create one, then telling us through Discord is fine as well.","title":"Issues with course materials"},{"location":"overview/introduction.advanced/#prerequisites","text":"You will need: A system (PC or laptop) to work on. This can be a Linux, macOS or Windows system. Blender 2.92 installed on the above system. You can download it from here , or you can use your system package manager to install it. Warning It is not recommended to use a different Blender version for this course, due to possible mismatches in the user interface and functionality with the course material. Please test the Blender installation before the course starts using the instructions sent by e-mail. This will tell you if Blender is working correctly and can save you (and us) time fixing any system-related issues during the course period. Recommended: Using a 3-button mouse is preferred, as not all Blender functionality is easily used through a laptop trackpad","title":"Prerequisites"},{"location":"overview/schedule.advanced/","text":"Schedule \u00b6 Date When What Where Purpose Tue 25/5 10:00 - 11:30 First online session Discord Introduction, get everyone started Tue 1/6 10:00 - 11:30 Second online session Discord Q&A, feedback Tue 8/6 10:00 - 11:30 Final online session Discord Ending the course, show results, gather feedback","title":"Schedule"},{"location":"overview/schedule.advanced/#schedule","text":"Date When What Where Purpose Tue 25/5 10:00 - 11:30 First online session Discord Introduction, get everyone started Tue 1/6 10:00 - 11:30 Second online session Discord Q&A, feedback Tue 8/6 10:00 - 11:30 Final online session Discord Ending the course, show results, gather feedback","title":"Schedule"},{"location":"overview/setup.advanced/","text":"Course setup \u00b6 We use a combination of different media within the course, but the basis is for you to follow the training in your own pace over a period of two weeks. The online material consists of: Videos that introduce new concepts and features within Blender. Slides (also presented as part of the videos) for explanations. These are basically the presentations we would normally do plenary. Exercises for you to explore new topics and to train your skills We have scheduled a few short plenary online sessions in the course period to provide general feedback and/or guidance. Support \u00b6 Detailed interaction and support during the course period is provided through our Discord server. Here you can ask questions by chat, upload an image or (if needed) start a video session or share your screen with one of us . In the section Advanced Blender Course there are two channels available: #chat-support : this is a (shared) text channel for interacting via chat #plenary-sessions : this is a voice/video channel in which we host the online sessions For one-on-one contact, including the option for screen sharing, right-click on one of our names as shown above. We will be active on Discord during office hours (CET time zone) and will try to also be on-line outside of those hours, all on a best-effort basis. Data files \u00b6 Most of the exercises require you to load a Blender scene file that we provide. These files can be found at https://edu.nl/hrvbe . It is best to download the full content of the share to your local system using the Download button in the upper-right. This share contains: data - Blender files (and other data) for the assignments, with a subdirectory per chapter slides - The slides (in PDF) XXX are there any? walkthroughs - Some of the files used in the presentations cheat-sheat-2.9.pdf - A 2-page cheat sheet with often used operations and their short cuts Time investment \u00b6 It is hard to give a general indication of the expected time investment needed for the course. It depends partially on your own goals and ambitions for the main task: visualizing your own data in the way you see fit. In terms of topics the Advanced materials and Animation chapters are relatively straightforward and can probably be completed in a day. In contrast, Python scripting in Blender is a very extensive topic and can end up taking a lot of time if you want to work with the more complex parts of the API.","title":"Course setup"},{"location":"overview/setup.advanced/#course-setup","text":"We use a combination of different media within the course, but the basis is for you to follow the training in your own pace over a period of two weeks. The online material consists of: Videos that introduce new concepts and features within Blender. Slides (also presented as part of the videos) for explanations. These are basically the presentations we would normally do plenary. Exercises for you to explore new topics and to train your skills We have scheduled a few short plenary online sessions in the course period to provide general feedback and/or guidance.","title":"Course setup"},{"location":"overview/setup.advanced/#support","text":"Detailed interaction and support during the course period is provided through our Discord server. Here you can ask questions by chat, upload an image or (if needed) start a video session or share your screen with one of us . In the section Advanced Blender Course there are two channels available: #chat-support : this is a (shared) text channel for interacting via chat #plenary-sessions : this is a voice/video channel in which we host the online sessions For one-on-one contact, including the option for screen sharing, right-click on one of our names as shown above. We will be active on Discord during office hours (CET time zone) and will try to also be on-line outside of those hours, all on a best-effort basis.","title":"Support"},{"location":"overview/setup.advanced/#data-files","text":"Most of the exercises require you to load a Blender scene file that we provide. These files can be found at https://edu.nl/hrvbe . It is best to download the full content of the share to your local system using the Download button in the upper-right. This share contains: data - Blender files (and other data) for the assignments, with a subdirectory per chapter slides - The slides (in PDF) XXX are there any? walkthroughs - Some of the files used in the presentations cheat-sheat-2.9.pdf - A 2-page cheat sheet with often used operations and their short cuts","title":"Data files"},{"location":"overview/setup.advanced/#time-investment","text":"It is hard to give a general indication of the expected time investment needed for the course. It depends partially on your own goals and ambitions for the main task: visualizing your own data in the way you see fit. In terms of topics the Advanced materials and Animation chapters are relatively straightforward and can probably be completed in a day. In contrast, Python scripting in Blender is a very extensive topic and can end up taking a lot of time if you want to work with the more complex parts of the API.","title":"Time investment"},{"location":"references/cheat_sheet/","text":"Cheat sheet \u00b6 With this course we provide a 2-page cheat sheet that lists basic and often-used operations and their shortcut keys. It also includes a summarize of major interface elements. The cheat sheet can be found here as a double-sided PDF, which can easily be printed.","title":"Cheat sheet"},{"location":"references/cheat_sheet/#cheat-sheet","text":"With this course we provide a 2-page cheat sheet that lists basic and often-used operations and their shortcut keys. It also includes a summarize of major interface elements. The cheat sheet can be found here as a double-sided PDF, which can easily be printed.","title":"Cheat sheet"},{"location":"references/community/","text":"Community resources \u00b6 On blenderartists.org lots of Blender users and artists are hanging out. There you can ask questions or feedback, show off your work or check out the vast amount of knowledge, tips and Blender renderings in the forums. BlenderNation gathers information on different topics and includes video tutorials, blog posts on art created with Blender and a lot more. The Blender subreddit contains many different posts, ranging from simple questions to artists show off their amazing work. Well-known artists and gurus working with Blender are: Andrew Price ( twitter ) aka \"Blender Guru\" provides many cool tutorials on https://www.blenderguru.com/ and his YouTube channel . Glex Alexandrov ( twitter and twitter ) aka \"Creative shrimp\" has some very creative and inspirational tutorials on his YouTube channel . Ian Hubert ( YouTube and twitter ), famous for his Lazy tutorials (very efficient 1 minute tutorials), has videos on advanced green screen techniques and VFX in Blender. Simon Thommes ( twitter and YouTube ) is a materials wizard, he is able to create complex geometry out of one cube or sphere with just the Shader editor. Steve Lund has some great Blender tutorials on his YouTube channel . Zach Reinhardt has some great modeling, texturing and VFX tutorials on his YouTube channel Peter France was the Blender artist at the Corridor Crew which just started his own YouTube channel with some instructive tutorials. YanSculpts does not fit this course material perse but it goes to show how versatile Blender can be, this artist creates some amazing sculptures in Blender of which he shows the process on his YouTube channel . Jan van den Hemel shares many tips and tricks through Twitter, both on Blender usage as well as making a scene look a certain way","title":"Community resources"},{"location":"references/community/#community-resources","text":"On blenderartists.org lots of Blender users and artists are hanging out. There you can ask questions or feedback, show off your work or check out the vast amount of knowledge, tips and Blender renderings in the forums. BlenderNation gathers information on different topics and includes video tutorials, blog posts on art created with Blender and a lot more. The Blender subreddit contains many different posts, ranging from simple questions to artists show off their amazing work. Well-known artists and gurus working with Blender are: Andrew Price ( twitter ) aka \"Blender Guru\" provides many cool tutorials on https://www.blenderguru.com/ and his YouTube channel . Glex Alexandrov ( twitter and twitter ) aka \"Creative shrimp\" has some very creative and inspirational tutorials on his YouTube channel . Ian Hubert ( YouTube and twitter ), famous for his Lazy tutorials (very efficient 1 minute tutorials), has videos on advanced green screen techniques and VFX in Blender. Simon Thommes ( twitter and YouTube ) is a materials wizard, he is able to create complex geometry out of one cube or sphere with just the Shader editor. Steve Lund has some great Blender tutorials on his YouTube channel . Zach Reinhardt has some great modeling, texturing and VFX tutorials on his YouTube channel Peter France was the Blender artist at the Corridor Crew which just started his own YouTube channel with some instructive tutorials. YanSculpts does not fit this course material perse but it goes to show how versatile Blender can be, this artist creates some amazing sculptures in Blender of which he shows the process on his YouTube channel . Jan van den Hemel shares many tips and tricks through Twitter, both on Blender usage as well as making a scene look a certain way","title":"Community resources"},{"location":"references/interface/","text":"User Interface elements \u00b6 * By default the status bar at the bottom only shows the Blender version number. You can add extra statistics, such as the number of 3D objects in the scene and memory usage in the preferences. Use the application menu Edit > Preferences , select the Interface tab, in the Editors > Status Bar section and check all marks ( Scene Statistics , System Memory , Video Memory ). Editor type menu \u00b6 The yellow highlight indicates often used ones for this course","title":"User Interface elements"},{"location":"references/interface/#user-interface-elements","text":"* By default the status bar at the bottom only shows the Blender version number. You can add extra statistics, such as the number of 3D objects in the scene and memory usage in the preferences. Use the application menu Edit > Preferences , select the Interface tab, in the Editors > Status Bar section and check all marks ( Scene Statistics , System Memory , Video Memory ).","title":"User Interface elements"},{"location":"references/interface/#editor-type-menu","text":"The yellow highlight indicates often used ones for this course","title":"Editor type menu"},{"location":"references/official/","text":"Official sources \u00b6 The official home for Blender is blender.org The Blender Reference Manual can be found here . The documentation on the Python API here . Official demo files showing off lots of cool features and scenes can be found here . If you are interested in following recent development of new features in Blender then the Blender Today Live channel on YouTube is a good resource. On Twitter you can follow @Blender for official Blender news or @BlenderDev for more in-depth development information. The hashtag to use for Blender is #b3d .","title":"Official sources"},{"location":"references/official/#official-sources","text":"The official home for Blender is blender.org The Blender Reference Manual can be found here . The documentation on the Python API here . Official demo files showing off lots of cool features and scenes can be found here . If you are interested in following recent development of new features in Blender then the Blender Today Live channel on YouTube is a good resource. On Twitter you can follow @Blender for official Blender news or @BlenderDev for more in-depth development information. The hashtag to use for Blender is #b3d .","title":"Official sources"},{"location":"references/scene/","text":"Scene resources (3D models, materials, textures) \u00b6 Here we list a number of online resources for 3D models, textures, shaders, etc. In general certain 3D models might be free for download, while others might only be available paid (usually for a small amount). Usually, the nicer the 3D model the higher the cost. Also, different licenses are used for the models and these will describe how you can use the models and any attribution you might need to give when using it. 3D Models \u00b6 Turbosquid is one of the oldest 3D model websites and provides models in all sort of topics, some free, some paid. Sketchfab hosts a large collection of 3D models from many different categories. Many 3D models are textured and some are even animated. 3D Model Haven distributes freely usable 3D models, many of them textured. It is not as extensive as other websites, but the upside is that all models can be freely used. CGTrader also hosts many 3D models, some of them free, some paid There's a section on BlenderNation where Blender models are shared. Again, some of these might be free, others will involve some payment. BlenderMarket contains a section with 3D models Textures and images \u00b6 Texture Haven provides textures to be used in materials and shaders. All textures available are free. CC0 Textures has many high-quality textures BlenderMarket has a section with shaders, materials and textures . HDRI Haven is similar to Texture Haven, but contains many freely available HDRI 360 images that can be used for realistic environment lighting in Blender BlenderKit \u00b6 BlenderKit is an online repository of materials, 3D models and a few other things. The nice thing is that it is integrated within Blender through an add-on that is included (but not activated) by default. Detailed instructions on activating and using the add-on can be found in this chapter of the Blender manual. When the add-on is enabled it provides some extra elements in the Blender interface for searching, say a material or 3D model, by name, which can then be easily used in a Blender scene: Note that many of the assets in BlenderKit are free, but some are only available by buying a subscription. The add-on has quite a few options and performs certain operations that you would otherwise do manually or maybe not use at all. As such, it can set up the scene in more exotic ways, for example by linking to another Blender file. Also, the materials provided by BlenderKit can use pretty complex shader graphs, involving multiple layers of textures, or advanced node setups. Warning When applying a BlenderKit material on your own object the rendering might not look like the material preview in all cases. Especially use of displaced materials involves specific settings for the Cycles renderer and use of subdivision on the object. Warning Textures from BlenderKit are by default stored in a separate directory on your system ( ~/blenderkit_data on Linux). There is an option to pack the textures within the Blender file, making it larger in size but also completely independent of any external files, which is useful if you want to transfer the Blender file to a different system. The option for packing files is File > External Data > Pack All into .blend .","title":"Scene resources (3D models, materials, textures)"},{"location":"references/scene/#scene-resources-3d-models-materials-textures","text":"Here we list a number of online resources for 3D models, textures, shaders, etc. In general certain 3D models might be free for download, while others might only be available paid (usually for a small amount). Usually, the nicer the 3D model the higher the cost. Also, different licenses are used for the models and these will describe how you can use the models and any attribution you might need to give when using it.","title":"Scene resources (3D models, materials, textures)"},{"location":"references/scene/#3d-models","text":"Turbosquid is one of the oldest 3D model websites and provides models in all sort of topics, some free, some paid. Sketchfab hosts a large collection of 3D models from many different categories. Many 3D models are textured and some are even animated. 3D Model Haven distributes freely usable 3D models, many of them textured. It is not as extensive as other websites, but the upside is that all models can be freely used. CGTrader also hosts many 3D models, some of them free, some paid There's a section on BlenderNation where Blender models are shared. Again, some of these might be free, others will involve some payment. BlenderMarket contains a section with 3D models","title":"3D Models"},{"location":"references/scene/#textures-and-images","text":"Texture Haven provides textures to be used in materials and shaders. All textures available are free. CC0 Textures has many high-quality textures BlenderMarket has a section with shaders, materials and textures . HDRI Haven is similar to Texture Haven, but contains many freely available HDRI 360 images that can be used for realistic environment lighting in Blender","title":"Textures and images"},{"location":"references/scene/#blenderkit","text":"BlenderKit is an online repository of materials, 3D models and a few other things. The nice thing is that it is integrated within Blender through an add-on that is included (but not activated) by default. Detailed instructions on activating and using the add-on can be found in this chapter of the Blender manual. When the add-on is enabled it provides some extra elements in the Blender interface for searching, say a material or 3D model, by name, which can then be easily used in a Blender scene: Note that many of the assets in BlenderKit are free, but some are only available by buying a subscription. The add-on has quite a few options and performs certain operations that you would otherwise do manually or maybe not use at all. As such, it can set up the scene in more exotic ways, for example by linking to another Blender file. Also, the materials provided by BlenderKit can use pretty complex shader graphs, involving multiple layers of textures, or advanced node setups. Warning When applying a BlenderKit material on your own object the rendering might not look like the material preview in all cases. Especially use of displaced materials involves specific settings for the Cycles renderer and use of subdivision on the object. Warning Textures from BlenderKit are by default stored in a separate directory on your system ( ~/blenderkit_data on Linux). There is an option to pack the textures within the Blender file, making it larger in size but also completely independent of any external files, which is useful if you want to transfer the Blender file to a different system. The option for packing files is File > External Data > Pack All into .blend .","title":"BlenderKit"}]}